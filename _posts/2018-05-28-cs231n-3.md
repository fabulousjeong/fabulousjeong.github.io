---
title: cs231n 번역 3 Optimization - Stochastic Gradient Descent
category: cs231n
excerpt: |
 첫 번째 구성 요소 (스코어 함수 매핑)를 더 깊에 살펴, 선형 매핑보다 훨씬 복잡한 함수(신경망, 컨볼루션 신경망)로 확장할 것이다. 로스 함수와 최적화과정은 상대적으로 거의 동일하다.  


feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=765"
image: "https://picsum.photos/2560/600/?image=765"
comment: true
---


#### Introduction
이전 섹션에서 이미지 분류 작업에 두 가지 주요 요소를 소개했다.

1. 이미지 픽셀을 클래스 스코어에 매핑 하는 (파라미터) 스코어 함수 (예 : 선형 함수)
2. 구한 스코어가 트레이닝 데이터의 실제 레이블과 얼마나 잘 일치했는지를 측정 하는 로스 함수. 이러함 함수를 만드는 다양한 방법이 있다. (예 : Softmax / SVM).

구체적으로 선형 함수는 다음과 같으며 $f(x_i, W) = W x_i$, SVM은 아래와 같은 형태로 표현된다. 

$$L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + 1) \right] + \alpha R(W)$$

이전 섹션에서 파라미터 $W$가 샘플 $x_i$에 대해 적절한 예측을 할때, 즉 실제 레이블 $y_i$와 일치 할때 로스 값은 작아진다. 지금부터는 마지막 남은 과정인 최적화(optimization)에 대해 설명한다. 최적화는 로스함수의 결과가 가장 낮는 파라미터 세트 $W$를 찾는 과정이다.   

Foreshadowing: 위 세 가지 핵심 구성 요소의 상호 작용을 완전히 이해한 다음, 첫 번째 구성 요소 (스코어 함수 매핑)를 더 깊에 살펴, 선형 매핑보다 훨씬 복잡한 함수(신경망, 컨볼루션 신경망)로 확장할 것이다. 로스 함수와 최적화과정은 상대적으로 거의 동일하다. 

##### Visualizing the loss function
일반적으로 로스 함수는 매우 고차원 공간에서 정의되므로 (예 : CIFAR-10에서는 총 30,730개의 매개 변수(선형 분류기 가중치 행렬의 크기가 [10 x 3073])에 대해 정의 됨), 시각화 하는데 어려움이 있다. 그러나 선(1 차원) 또는 평면 (2 차원)을 따라 고차원 공간을 절단하여 표현함으로써 직관적으로 이해 할 수 있다. 예를 들어, 임의의 웨이트 행렬 $W$(공간 상의 한 점에 해당)을 선택하고, 특정 방향으로 조금씩 이동시키며 손실 함수 값을 기록한다. 무작위 이동방향 $W_1$을 설정한 다음, 각기 다른 $a$에 따른 로스 값($L(W + a W_1)$)를 계산 할 수 있다. 아래 그림에서 x축은 a값을 나타내며, y축은 로스 값이다. 위와 같은 방식으로 2차원 평면($L(W + a W_1 + b W_2)$)으로 확장 할 수 있다. 여기서 a와 b는 각각 x, y축의 값이며, 로스 값은 색으로 표현된다.   

![](../assets/imgs/cs231n/3_loss.png "loss" "width:600px;float:center;padding-left:10px;")

따른 로스 값. 중간, 오른쪽 : 2 차원 로스 평면, 파란색 = 낮은 로스값, 빨간색 = 높은 로스값. 여러 샘플에 대한 로스는 각 샘플에 대한 로스 평면의 평균이므로, 오른쪽의 부드러운 보울 (bowl) 형태는 가운데와 같은 각진 piecewise-linear 보울의 평균과 같은 형태다. 



아래 식을 통해 손실 함수의 piecewise-linear 선형 구조를 설명 할 수 있다. 

$$L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + 1) \right]$$

각 샘플에 대한 로스는 선형함수$W$의 함으로 표현된다. 더욱이 $W$의 행($w_j$)는 종종 양수 값(잘못된 레이블 예측을 했을 때)을 가진다. 이를 보다 구체적으로 이해하기 위해, 세 개의 1 차원 포인트와 세 개의 클래스로 구성된 간단한 데이터 집합을 생각해보자. 정규화가 없는 전체 SVM 로스는 아래와 같다. 

\begin{align} L_0 = & \max(0, w_1^Tx_0 - w_0^Tx_0 + 1) + \max(0, w_2^Tx_0 - w_0^Tx_0 + 1) \\\\ L_1 = & \max(0, w_0^Tx_1 - w_1^Tx_1 + 1) + \max(0, w_2^Tx_1 - w_1^Tx_1 + 1) \\\\ L_2 = & \max(0, w_0^Tx_2 - w_2^Tx_2 + 1) + \max(0, w_1^Tx_2 - w_2^Tx_2 + 1) \\\\ L = & (L_0 + L_1 + L_2)/3 \end{align}



위 예는 1차원이므로 $x_i$와 $w_j$는 벡터가 아닌 숫자다. 

![](http://cs231n.github.io/assets/svmbowl.png "svmbowl" "width:600px;float:center;padding-left:10px;")

1차원으로 표현한 데이터 로스 그림. x축은 단일 웨이트 매트릭스 값이며, y 축은 로스를 나타낸다. 데이터 로스은 여러 항의 합이며, 각 항은 특정 웨이트와 독립적이거나 0의 임계값을 갖는 선형 함수다. Cifar 10에서 전체 SVM 데이터 로스는 이 모양의 30,730 차원 버전이다.



위 그림을 보면 SVM 비용 함수가 그릇 형태를 띄고 있으므로  컨벡스(convex) 함수라고 짐작 할 수 있다. 이러한 유형의 함수를 효율적으로 최소화하는 다양한 방법이 있으며, Stanford의 컨벡스 최적화 강의에도 소개하고 있다. 스코어 함수($f$)를 신경망으로 표현하면, 비용함수는 복잡해지며, 조금 더 울퉁붕퉁한 형태를 가지므로 더이상 컨벡스(convex)함수가 아니게 된다. 

Non-differentiable loss functions.. $max$ 함수와 같은 함수로 인해 손실 함수의 꼬임(kink)현상이 발생하며, 이러한 꼬임현상으로 gradient 가 정의 되지 않는다. 따라서 손실 함수를 미분 할 수 없다. 하지함 subgradient는 여전히 수행 가능하며 따라서 일반적으로 대신 사용된다. 이 강의에서는 subgradient 와 gradient 라는 용어를 동일한 의미로 사용한다.

##### Optimization
반복적으로 로스 함수를 통해  파라미터 웨이트 세트 W의 품질을 정량화한다. 최적화의 목표는 로스 함수를 최소화하는 W를 찾는 것이다. 이제 로스 함수를 최적화하기 위한 목표를 부여하고 차근차근 알아 볼 것이다. 지금 다루는 내용은 컨벡스 예제(SVM 손실)를 다루므로 다소 이상하게 보일 수 있지만, 뉴럴네트워크를 최적화하는 목표에 알맞음을 유의하자. 이러한 문제에는 Convex Optimization 방법을 바로 도입할 수 없다. 

###### Strategy #1: A first very bad idea solution: Random search

주어진 파라미터 집합 W가 얼마나 좋은지는 로스 함수를 통해 매우 간단히 확인 할 수 있으므로, 머리에 떠오르 첫 번째 (매우 나쁜) 아이디어는 단순히 여러 가지 임의의 웨이트 매트릭스를 넣어 보고 가장 잘 작동하는 것을 찾는 것이다. 이 절차는 아래과 같다.

```python
# assume X_train is the data where each column is an example (e.g. 3073 x 50,000)
# assume Y_train are the labels (e.g. 1D array of 50,000)
# assume the function L evaluates the loss function

bestloss = float("inf") # Python assigns the highest possible float value
for num in xrange(1000):
  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters
  loss = L(X_train, Y_train, W) # get the loss over the entire training set
  if loss < bestloss: # keep track of the best solution
    bestloss = loss
    bestW = W
  print 'in attempt %d the loss was %f, best %f' % (num, loss, bestloss)

# prints:
# in attempt 0 the loss was 9.401632, best 9.401632
# in attempt 1 the loss was 8.959668, best 8.959668
# in attempt 2 the loss was 9.044034, best 8.959668
# in attempt 3 the loss was 9.278948, best 8.959668
# in attempt 4 the loss was 8.857370, best 8.857370
# in attempt 5 the loss was 8.943151, best 8.857370
# in attempt 6 the loss was 8.605604, best 8.605604
# ... (trunctated: continues for 1000 lines)
```

위 코드에서 몇 가지 **임의(np.random.randn)**의 웨이트 벡터 **W**를 시도했으며, 그 중 일부는 다른 것보다 잘 동작하는 것을 비교 할 수 있다. 위 방법으로 찾은 최상의 웨이트 W를 취하여 테스트 세트를 테스트 해 볼 수 있다.

``` python
# Assume X_test is [3073 x 10000], Y_test [10000 x 1]
scores = Wbest.dot(Xte_cols) # 10 x 10000, the class scores for all test examples
# find the index with max score in each column (the predicted class)
Yte_predict = np.argmax(scores, axis = 0)
# and calculate accuracy (fraction of predictions that are correct)
np.mean(Yte_predict == Yte)
# returns 0.1555
```

최적의 W를 사용하면 약 15.5 % 의 정확도를 얻을 수 있다 . 클래스에 대한 무작위 예측이 10 %라는 점을 감안할 때, 위 무작위 검색 솔루션의 결과는 그리 좋지 않다!

**Core idea: iterative refinement.** 물론 위 방법이 더 낫다는 것은 알 수 있다. 핵심 아이디어는 최상의 웨이트 세트 W 를 찾는 것이 매우 어렵거나 불가능한 문제 (특히 복잡한 뉴럴 네트워크 전체의 웨이트인 W를 포함 하면 )이지만, 웨이트 W 의 특정 세트를 약간 더 잘 정제하는 것은 덜 어렵지 않다. 즉, 앞으로의 접근 방식은 임의의 W 로 시작한 다음 반복적으로 수정하여 매번 조금씩 개선하는 것이다.

*우리 전략은 임의의 W로 시작하여 시간이 지남에 따라 반복적으로 개선하여 로스 값을 줄이는 것이다.*

**Blindfolded hiker analogy.** 앞으로 도움이 될 수있는 비유 중 하나는 안대를 하고 앞이 안보이는 채로 언덕이 많은 지형에서 아래로 하이킹을 하는 것이다. CIFAR-10의 예에서 W 의 크기 는 10 x 3073 이므로 언덕은 30,730개이며, 언덕의 모든 지점에서 특정 로스 값(지형의 높이)을 얻는다.

###### Strategy #2: Random Local Search

생각할 수있는 첫 번째 전략은 한 발을 임의의 방향으로 디딘 다음 내리막인 경우에만 걸음을 내딛는 것이다. 구체적으로, 무작위 W에서 시작하여, 랜덤한 방향 $\delta W$, 를 더하여 $W + \delta W$에서의 로스를 구한 다음 이것이 $W$에서의 로스 보다 작은 경우 업데이트 한다. 이 방법의 코드는 다음과 같다.

```python
W = np.random.randn(10, 3073) * 0.001 # generate random starting W
bestloss = float("inf")
for i in xrange(1000):
  step_size = 0.0001
  Wtry = W + np.random.randn(10, 3073) * step_size
  loss = L(Xtr_cols, Ytr, Wtry)
  if loss < bestloss:
    W = Wtry
    bestloss = loss
  print 'iter %d loss is %f' % (i, bestloss)
```

이전과 동일한 로스 함수 반복 횟수(1000)를 사용했을 때, 이 방법은 테스트 세트에 대해 21.4 % 의  분류 정확도를 달성했다. 이것은 기존 보다 더 좋지만 여전히 낭비적이고 많은 계산량을 요구한다. 

###### Strategy #3: Following the Gradient
이전 섹션에서 weight-space에서 더 적은 로스 값이 되도록 웨이트 벡터를 향상시킬 방향을 찾는 것을 시도했다. 사실 내려갈 방향에 대해 무작위 검색 할 필요없이, 수학적인 방법으로 가장 좋은(적어도 같은 스텝에서 가장 가파르게 내려가는) 방향을 찾을 수 있다. 이 방향은 로스 함수의 Gradient와 관련있다. 하이킹에 비유하면 이 접근법은 발 아래의 언덕 경사를 느끼며, 가장 가파른 방향으로 내려 가는 것과 같다. 

1차원 함수에서 기울기는 특정 지점에서 함수의 순간 변화율이다. 벡터를 사용하여 함수에 대한 기울기를 일반화한다. 또한 Gradient는 입력의 각 차원에 대한 기울기 벡터(derivatives 이라고도 함 )와 같다. 1 차원 함수의 미분은 다음과 같다.

$$\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}$$

대상 함수가 벡터를 사용하는 경우 derivatives를 partial derivatives라 부르며, Gradient는 각 차원에서 partial derivatives다.

##### Computing the gradient

그라디언트를 계산하는 방법은 두 가지가 있다. 하나는 느리고 근사치를 계산하지만, 쉬운 방법 (수치 그라디언트:numerical gradient)이고, 다른 하나는 빠르고 정확하지만, 오류가 발생하기 쉬우며 미적분이 필요한 방법(해석 그라디언트:analytic gradient)이다. 둘 방법 모두 살펴 보자.

###### Computing the gradientnumerically with finite differences

위에 주어진 수식을 통해 그라디언트를 수치적으로 계산할 수 있다. 다음은 함수 f와 벡터 x를 사용하여  x에서  f의 그라디언트를 구하는 함수다. 

``` python
def eval_numerical_gradient(f, x):
  """ 
  a naive implementation of numerical gradient of f at x 
  - f should be a function that takes a single argument
  - x is the point (numpy array) to evaluate the gradient at
  """ 

  fx = f(x) # evaluate function value at original point
  grad = np.zeros(x.shape)
  h = 0.00001

  # iterate over all indexes in x
  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
  while not it.finished:

    # evaluate function at x+h
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # increment by h
    fxh = f(x) # evalute f(x + h)
    x[ix] = old_value # restore to previous value (very important!)

    # compute the partial derivative
    grad[ix] = (fxh - fx) / h # the slope
    it.iternext() # step to next dimension

  return grad
```

위에 주어진 그라디언트 공식에 따라 모든 차원(x의 모든 인덱스)에 대해 반복적으로 편차 h 에 의해 함수 값이 얼마나 많이 변경되었는지 확인하여 로스 함수의 부분 도함수를 구한다. 변수 grad는 결국 전체 그라디언트와 같다. 

**Practical considerations.**  수학 공식에서 기울기는 h 가 0의 극한일 때 정의 되지만, 실제로는 매우 작은 값 (예 에서처럼 1e-5)을 사용하는 것으로 충분 하다는 점에 유의하자. 이상적으로는 컴퓨팅 연산시 문제를 일으키지 않는 가장 작은 수를 사용 할 것이다. 또한 실제로는 **중심 차분 공식(centered difference formula**: $[f(x+h) - f(x-h)] / 2 h$)을 사용하여 수치 그래디언트를 계산하는 것이 더 효과적이다. 자세한 내용은 wiki를 참조하자.



위에서 주어진 함수를 사용하여 모든 점과 함수에 대한 그래디언트를 계산할 수 있다. 아래와 같이 웨이트 매트릭스 공간의 임의의 지점에서 CIFAR-10 로스 함수에 대한 그래디언트를 계산할 수 있다.

```python
# to use the generic code above we want a function that takes a single argument
# (the weights in our case) so we close over X_train and Y_train
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # random weight vector
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # get the gradient
```

그라디언트는 모든 차원에서 로스 함수의 기울기를 알려주며 아래와 같이 반복문을 통해 값을 업데이트 할 수 있다. 

``` python
loss_original = CIFAR10_loss_fun(W) # the original loss
print 'original loss: %f' % (loss_original, )

# lets see the effect of multiple step sizes
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # new position in the weight space
  loss_new = CIFAR10_loss_fun(W_new)
  print 'for step size %f new loss: %f' % (step_size, loss_new)

# prints:
# original loss: 2.200718
# for step size 1.000000e-10 new loss: 2.200652
# for step size 1.000000e-09 new loss: 2.200057
# for step size 1.000000e-08 new loss: 2.194116
# for step size 1.000000e-07 new loss: 2.135493
# for step size 1.000000e-06 new loss: 1.647802
# for step size 1.000000e-05 new loss: 2.844355
# for step size 1.000000e-04 new loss: 25.558142
# for step size 1.000000e-03 new loss: 254.086573
# for step size 1.000000e-02 new loss: 2539.370888
# for step size 1.000000e-01 new loss: 25392.214036
```

**Update in negative gradient direction.** 로스 함수가 증가하지 않고 감소하기를 원하기 때문에, 위 코드에서 W_new를 구할때 그라디언트 df의 음의 방향으로 업데이트하였다. 

**Effect of step size.** 그라디언트는 함수의 가파르게 증가하는 방향을 알려주지만, 이 방향에서 우리가 얼마나 멀리 가야하는지를 알려주지는 않는다. 다음 과정에서 살펴 보겠지만, 스텝 사이즈( 학습 속도:  learning rate 라고도 함)는 뉴럴 네트워크를 훈련 할 때 가장 중요한 (그리고 골치 아픈) 하이퍼 파라미터 설정 중 하나가 될 것이다. 안대를 하고 언덕을 내려가는 비유에서, 우리 발 아래의 언덕이 어떤 방향으로 기울어 진 것을 느끼지만, 얼마나 크게 발걸음을 뗄지는 불확실하다. 조심스럽게 발을 내딛으면 정확하지만 아주 작은 진전을 기대할 수 있다 (이것은 작은 스텝 사이즈를 갖는 것에 해당한다). 반대로, 우리는 빠르게 내려 가기위해 큰 스텝 사이즈로 내딛을 수 있지만, 이것은 효과가 없을 수 있다. 위의 코드 예제에서 볼 수 있듯이, 더 큰 사이즈를 취할때 로스가 증가하는 "overstep"이 발생할 수도 있다. 

![](http://cs231n.github.io/assets/stepsize.jpg "stepsize" "width:600px;float:center;padding-left:10px;")
스텝사이즈의 시각화. 특정 지점 W에서 시작하여 로스 함수의 가장 가파른 감소 방향을 알려주는 기울기 (또는 흰색 화살표)를 구한다. 작은 스텝은 일관성 있지만 느린 진행으로 이어질 가능성이 있다. 큰 스텝은 더 빨리 움직이지만  더 위험하다. 스텝 사이즈가 극단적으로 클 경우 오버 슈트하여 로스를 악화시킨다. 스텝 사이즈는 조심스럽게 조정해야하는 가장 중요한 하이퍼 매개 변수 중 하나다. 

**A problem of efficiency.**  수치 그라디언트를 구하는 과정은 파라미터 수에 선형적 복잡도를 가진다. 이 예에서는 총 30730 개의 매개 변수가 있었으므로 그라디언트를 구하고 한개 파라미터 업데이트를 수행하기 위해 로스 함수를 총 30,731 회 계산해야했다. 최근 신경망은 수천만 개의 파라미터를 가질 수 있기 때문에 이 문제는 더욱 심각해진다. 당연히 이 전략은 확장가능하지 않으며 더 나은 방법이 필요하다. 

###### Computing the gradient analytically with Calculus
위의 수치 그라디언트는 매우 간단한 계산 과정을 보이지만, 계산량이 매우 크며, 근사치(매우 작은 h를 사용한다 하더라도, h가 0의 극한인 경우가 그라디언트의 정의이므로)를 구할 뿐이다.  그라디언트를 계산하는 두 번째 방법은 분석적으로 미적분을 사용하는 것이다. 그래서 매우 빠르게 계산할 수있는 그라디언트(근사치 없음)에 대한 직접적인 수식을 유도한다. 그러나 수치 그라디언트와 달리 구현 시 더 오류가 날 수 있다. 실제 일반적으로 분석 그라디언트를 계산한 다음 이를 수치 그라디언트와 비교하여 구현의 정확성을 확인한다. 이를 그라디언트 검사(gradient check.)라고 한다. 

단일 데이터 포인트에 대한 SVM 로스 함수의 예를 보자. 

$$L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]$$

웨이트에 대해 함수를 미분 할 수 있다. 예를 들어, $w_{y_i}$의 그라디언트를 취하면 다음과 같다. 

$$\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) \right) x_i$$

여기서 $1$은 indicator함수로 내부 조건이 참이면 1을 아닌 경우 0을 반환한다.  식이 다소 어려워 보이지만, 코드상 구현은 간단하다. 마진을 충족시키지 못하는 클래스에 대해 $x_i$를 그라디언트로 삼으면 된다. 위 그라디언트는 $W$의 참인 클래스 $y_i$ 행($w_{y_i}$)에 대한 것임을 주의 하자. 다른 행($j \neq y_i$)에 대한 그라디언트는 아래와 같다. 

 $$\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i$$

그라디언트 대한 표현식을 확장하여 표현식 간단화 한 다음 이를 그라디언트를 업데이트에 사용한다.  

##### Gradient Descent

이제는 로스 함수의 그라디언트를 계산할 수 있으므로 그라디언트를 반복적으로 계산 한 다음 매개 변수 업데이트를 수행하는 절차인 *그라디언트 하강(Gradient Descent)* 를 수행할 수 있다. 그 **기본** 버전은 다음과 같다. :

``` python
# Vanilla Gradient Descent

while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # perform parameter update

```

이 간단한 반복문은 모든 신경망 라이브러리의 핵심이다. 최적화를 수행하는 다른 방법 (예 : LBFGS)이 있지만 Gradient Descent는 현재 Neural Network의 로스함수를 최적화하는 가장 보편적으로 확립 된 방법이다. 수업 전반에 걸쳐 이 반복문의 세부사항(예 : 업데이트 방정식의 세부 사항)에 대한 몇 가지 부가적인 방법이 다뤄지겠지만, 그라디언트를 따르는 핵심 아이디어는 동일하다. 

**Mini-batch gradient descent.** 대규모 애플리케이션(예 : ILSVRC 챌린지)에서 트레이닝 데이터는 수백만 가지의 샘플을 가질 수 있다. 따라서 싱글 파라미터 업데이트를 수행하기 위해 전체 트레이닝 세트에서 전체 로스 함수를 계산하는 것은 소모적인 일처럼 보인다. 이 문제를 해결하기위한 가장 보편적인 방법은 트레이닝 데이터의 **배치(batch)**에 대한 그라디언트를 계산하는 것이다. 예를 들어, 현재 최신 ConvNets에서는 일반적으로 120만 개의 전체 트레이닝 세트로부터 256 샘플로 구성된 배치를 얻은 다음, 이 배치를 사용하여 파라미터 업데이트를 수행한다.

``` python
# Vanilla Minibatch Gradient Descent

while True:
  data_batch = sample_training_data(data, 256) # sample 256 examples
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # perform parameter update
```

이것이 잘 작동하는 이유는 트레이닝 데이터의 각 샘플들이 서로 관련 있기 때문이다. 이를 ILSVRC에있는 120 만개의 모든 이미지가 실제로 1000개의 고유한 이미지의 사본으로 구성(각 클래스는 각각 한 개 이미지의 1200개의 동일한 사본으로 구성)되는 극단적 인 경우를 생각해보자. 모든 1200개의 동일한 사본에 대한 그라디언트 계산 결과는 모두 같을 것이고, 120 만 개의 이미지 전체에 대한 데이터 로스의 평균 역시 작은 부분 집합에 대한 로스와 똑같을 것이다. 물론 실제로는 데이터 세트에 중복 이미지가 포함되지 않으며, 미니 배치의 그래디언트는 전체  그래디언트에 대한 근사 값을 가질 것이다. 

극단적으로 미니 배치가 단일 샘플 하나로만 구성될 수도 있다. 이러한 과정을 **Stochastic Gradient Descent (SGD)**(또는 on-line gradient descent)라 부른다. 사실 벡터화를 통한 코드 최적화로 인해 100 개의 샘플에 대한 그래디언트를 계산하는 것이 하나의 예제에 대한 그래디언트 보다 계산적으로 훨씬(100배) 효율적다고 볼 수 있다. 기술적으로는 그라디언트를 구하기 위해 한 번에 한 가지 샘플를 사용 할때 SGD라고 하지만, 미니 배치 그라디언트 디센트를 사용하는 경우에도 사람들은 종종 SGD라는 용어를 사용한다. (예 : "Minibatch Gradient Descent"에 대한 MGD 또는 "Batch gradient descent"는 라는 말은 거의 못 들어 봤을 것이다.). 사실 대부분의 경우 미니 배치가 사용된다고 가정한다. 미니 배치의 크기는 분명 하이퍼 파라미터지만 일반적으로 크로스 밸리데이션을 사용하지는 않는다.  보통 메모리 크기의 제약(있는 경우)을 따르거나 일부 값 (예 : 32, 64 또는 128)으로 설정한다. 많은 벡터화 연산 라이브러리는 입력이 2의 제곱의 크기를 가질때 더 빠르게 동작하기 때문에 실제로는 2의 거듭 제곱을 사용한다.

##### Summary

![](http://cs231n.github.io/assets/dataflow.jpeg "dataflow" "width:600px;float:center;padding-left:10px;")

information 플로우 요약. (x, y) 쌍의 고정된 데이터 세트가 주어진다. 웨이트는 무작위 숫자로 초기화 된 다음 업데이트 된다. 정방향 패스 중에 스코어 함수 f는 클래스 스코어를 계산한다. 로스 함수는 두 가지 구성 요소로 이루어져 있다. 데이터 로스는 스코어 f 와 레이블 y 간의 유사도를 계산한다. 정규화 로스는 웨이트만 입력 받는 함수다. 그라디언트 디센트 (Gradient Descent)를 통해 웨이트의 그라디언트를 계산하고(원하는 경우 데이터에 선택적으로), 이를 사용하여 웨이트 파라미터를 업데이트 한다.  


이 섹션에서, 

* 로스 함수의 고차원적 최적화를 통해 바닥(최소값)에 도달하는 방법을 다뤘다. 눈에 안대를 한 채 언덕을 내려가는 유추를 통해 이해하였으며, SVM 비용(cost) 함수가 piece-wise linear 및 그릇 형태임을 보았다.
* 반복적인 개선을 통해 로스 함수를 최적화하는 아이디어를 살펴봤다. 무작위로 초기화하여 로스가 최소화 될 때까지 반복적으로 업데이트 한다. 
* 함수의 그라디언트는 가장 가파른 변화 방향을 나타 냈으며, finite difference approximation (finite difference는 수치 그래디언트 계산에 사용 된 h 의 값)을 사용하여, 수치적으로 계산하는 간단하지만 비효율적 인 방법을 다뤘다.
* 파라미터 업데이트 시 스텝 사이즈(또는 학습 속도 )의 적절한 설정이 필요하며, 너무 낮으면 진행은 바르지만 느리게 수렴하낟. 반면 너무 크면 진행 속도는 빠르지만, 수렴하지 않을 위험이 더 크다. 적절한 값에 대해서는 다음 장에서 더 자세히 설명 할 것이다.
* 수치적 및 분석적 그라디언트 계산 간의 절충에 대해 논의했다 . 수치 그래디언트는 간단하지만 근사치를 계산하며, 계산 비용이 많이 듭니다. 분석 그라디언트는 정확하고 빠른 계산이 가능하지만, 수학을 사용하여 그라디언트를 유도해야하기 때문에 오류가 발생하기 쉽다. 따라서 실제로는 대부분 분석 그라디언트를 사용하고 그 결과를 수치 그라디언트와 비교하는 그라디언트 검사를 수행하여 이를 보완한다. 
* 반복문을 통해 반복적으로 그라디언트를 계산하고 파라미터 업데이트를 수행하는 그라데이션 디센트 알고리즘을 소개했다.

**Coming up:** 이 섹션의 핵심은 신경망을 설계, 훈련 및 이해하는 데 필요한 가장 중요한 기술인 웨이트과 관련하여 로스 함수의 그라디언트(기울기)를 계산할 수있는 능력(직관적으로 이해할 수있는 능력)이다. 다음 섹션에서는 체인 룰(**backpropagation** 이라고도 함)을 사용하여 분석적으로 기울기를 계산하는 데 익숙해질 것이다. 이 방법은 Convolutional Neural Networks를 포함한 모든 종류의 신경망에 대한 임의의 손실 함수를 효율적으로 최적화 할 수있게 해준다. 





