---
title: 03 Semantics and Factorization
category: ProbabilisticGraphicalModels
excerpt: |
  이 강의에서 다루는 내용과 밀접한 관계가 있는 베이지안 네트워크(Bayesian Network)에 대해 본격적으로 알아 보겠습니다.
feature_text: |
  ## [Coursera] Probabilistic Graphical Models
  Daphne Koller의 Probabilistic Graphical Models 강의 정리

  ref: [https://www.coursera.org/learn/probabilistic-graphical-models/home](https://www.coursera.org/learn/probabilistic-graphical-models/home "coursera")

feature_image: "http://netascholars.org/wp-content/uploads/imgs/index.php?w=700&src=http://netascholars.org/wp-content/uploads/2013/04/9780262258357-1024x512.jpg"
image: "http://netascholars.org/wp-content/uploads/imgs/index.php?w=700&src=http://netascholars.org/wp-content/uploads/2013/04/9780262258357-1024x512.jpg"
comment: true
---


### Bayesian Network

이 강의에서 다루는 내용과 밀접한 관계가 있는 베이지안 네트워크(Bayesian Network)에 대해 본격적으로 알아 보겠습니다.  먼저 베이지안 네트워크를 정의하고, 앞선 강의에서 배운 팩터(Factor)를 사용하여 베이지안 네트워크를 어떻게 구성하는지 알아 보겠습니다. 앞에서 많이 다뤘던 학생의 성적을 결정하는 "학생 예제"를 통해 알아보도록 하겠습니다. 

![](http://cfile30.uf.tistory.com/image/245E544A5881F046071A1D "Bayesian Network" "width:600px;height:300px;float:center;padding-left:10px;")

성적 G는 수업의 난이도(D)와 학생의 지능(I)에 의존성(Dependency)이 있습니다. 그리고 학생이 SAT를 봤다면 SAT 또한 하나의 변수로 볼 수 있고 이 값 또한 학생의 지능에 의존성이 있을 것입니다. 그리고 추천서는 학생의 성적에 의존성이 있습니다. 위 예에서는 성적을 제외한 나머지 변수들을 이진화(높음/낮음)하여 모델을 보다 간단하게 만들것입니다. 이것은 모델의 한 예이고 이러한 모델은 여러 방향으로 유연하게 구성 할 수 있습니다. 예를 들어 똑똑한 학생일 수록 더 어려운 과목을 듣는다고 하면 D와 I사이에는 하나의 엣지가 더 생길 것입니다. 하지만 이번 강의에서는 최대한 간단한 모델만을 다룰 것이므로 이러한 가정을 하지 않겠습니다. 위 그림에서 처럼 각 노드의 변수 값은 확률분포로 설정됩니다. 그리고 하위 노드는 상위 노드의 조건부 확률 분포(CPD: Conditional Probability Distribution)로 표현됩니다.

![](http://cfile2.uf.tistory.com/image/2765FC3B5881FAB42B8159 "CPD" "width:600px;height:300px;float:center;padding-left:10px;")

 위 예는 5개의 노드가 있고 5개의 CPD가 있습니다.(가장 상위 노드는 조건이 전체 집합이므로 그냥 확률 분포로 표현됨) D를 예로 들면 과목이 쉬울 확률은 60%고 어려울 확률은 40%입니다. 학생의 지능 역시 과목의 난이도와 비슷한 방법으로 표현 됩니다. 학생의 성적은 CPD로 표현됩니다. 위 표와 같이 학생의 성적 G는 D,I의 조건부 확률 $P(G|I,D)$ 로 표현 됩니다. SAT 역시 상위 노드인 학생의 지능에 대한 조건부 확률  $P(S|I)$ 로 표현되고, 추천서 역시 성적에 대한 조건부 확률 $P(L|G)$ 로 표현됩니다. 

지금 부터는 위 베이지안 네트워크에 있는 5개 변수 전체에 대한 확률 분포가 어떻게 표현 되는지 살펴 보겠습니다. 이를 위해 여러 CPD를 통합하는데 사용되는 기본적인 방법 중 하나인 체인 룰에 대해 알아 보겠습니다. 전체 변수에 대한 확률 분포는 위와 같이 네트워크의 CPD의 곱을 통해 표현됩니다. 각 펙터는 범위(Scope)를 가지고 있고, 곱을 통해 범위가 중첩 되면서 최종적으로 ${D, I, G, S, L}$ 범위를 가지게 됩니다. 

체인 룰이 어떻게 사용 되는지 알아 보도록 하겠습니다. 먼저 $P(d^0, i^1, g^3, s^1, l^1)$의 확률을 구해 보겠습니다. 첫번째 확률인 $P(d^0)$는 0.6입니다. 그 다음 $P(i^1)$는 0.3입니다. 이제 조건부 확률인 $P(g^3|i^1,d^0)$를 구해보겠습니다. 위 표를 보면 0.02입니다. 그리고 $P(l^1|g^3)$는 0.01,  $P(s^1|i^1)$은 0.8이 될 것입니다. 따라서 $P(d^0, i^1, g^3, s^1, l^1)$은 $0.6*0.3*0.02*0.01*0.8$과 같습니다. 

![](http://cfile7.uf.tistory.com/image/2202EB3F5881FD6923A3BD "CPD" "width:600px;height:300px;float:center;padding-left:10px;")

정리하자면 위 베이지안 네트워크와 같은 그래프를 방향성 비순환 그래프 (Directed Acyclic Graph, DAG)라 부릅니다. 그래프 G의 각 노드는 변수 ($X_1, ..., X_n$)으로 표현됩니다. 체인 룰을 통한 베이지안 네트워크의 공통확률분포(Joint Distribution)는 그래프를 이루는 각 노드의 CPD간의 곱으로 표현 할 수 있습니다. 그래프와 체인 룰을 이용하여 간단히 학생의 성적을 결정하는 전체 변수의 공통확률분포를 표현 할 수 있었습니다. 이러한 표현법이 맞나는 것은 어떻게 입증 할 수 있을까요? 먼저 확률 분포는 0보다 크거나 같아야 합니다. CPD가 0보다 크거나 같으므로 위와 같은 CPD의 곱역시 당연히 0보다 크거나 같습니다. 

![](http://cfile28.uf.tistory.com/image/2607C1345882ACD30A6D5B "CPD" "width:600px;height:300px;float:center;padding-left:10px;")

그리고 정상적인 확률분포의 합은 1이므로 이것도 증명해보겠습니다. 약간 복잡하지만, 위의 예를 통해 알아 보겠습니다. 체인룰로 풀어 보면 가장 위의 식 처럼 각 노드의 CPD의 곱이 될 것입니다. 여기서 합 연산의 경우 다른 변수에 영향을 미치지 않는 다면 따로 수행할 수 있습니다. 예를 들어 L의 경우 마지막 항에만 변수가 있으므로 두번째 줄의 식처럼 L에 대해서만 따로 합연산을 수행 할 수 있습니다. CPD 역시 확률 분포이므로 합은 당연히 1이 되고 곱연산에서 소거 할 수 있겠죠.. S의 경우도 같은 방식으로 소거 해줍니다. 나머지 변수들 모두 이러한 방법으로 하나식 소거 할 수 있고 결국 1이 남게 됩니다. 이로써 체인룰로 구한 확률분포의 합이 1이라는 것을 증명했습니다. 

![](http://cfile21.uf.tistory.com/image/213A5C405882AEB503A7ED "CPD" "width:600px;height:100px;float:center;padding-left:10px;")

이제 한 가지 용어를 정의하도록 하겠습니다. 그래프 G내에 있는 변수 $X_1, ..., X_n$의 확률 분포 P를 각 변수의 CPD의 곱으로 표현 할 때  "G를 인수분해한다(P Factorizes over G)" 라고 표현합니다. 이는 P를 더 작은 요소들의 곱으로 표현하는 것을 뜻합니다.  

![](http://cfile21.uf.tistory.com/image/223542435882B1710285E3 "CPD" "width:600px;height:250px;float:center;padding-left:10px;")

끝으로 베이지안 네트워크의 한 가지 예를 더 보겠습니다. 위의 예는 유전학자들이 정의한 형액형의 유전학적 모델인데 베이지안 네트워크가 나오지 전에 구성하였지만, 베이지안 네트워크와 매우 비슷 합니다. 혈액형의 경우 6가지(AA, AB, AO, BO, BB, OO) 유적적 타입이 있고, 실제 발현 되는 타입은 AA, AO가 A로, BB, BO가 B로 발현되므로 4가지(A,B,AB,O)가 있습니다. 이렇듯 혈액형의 발현은 유전적 타입에 좌우되며, 자식의 유전적 타입은 부모의 염색체에서 각각 하나씩 받아 결정되므로, 부모 유전자 타입에 의존성이 있습니다. 따라서 베이지안 네트워크에 적합합니다. 그리고 이 네트워크는 오로지 1개 변수(혈액형)만 있으로 매우 간결하게 표현 됩니다.  