---
title: cs231n 번역 8 Putting it together Minimal Neural Network Case Study
excerpt: |
 이 섹션에서는 간단한 2차원 신경망의 구현에 대한 전체 과정을 살펴 보본다. 먼저 간단한 선형분류기를 구현 한 다음 이 코드를 2 layer 신경망으로 확장한다. 아래에서 다루겠지만, 이것은 매우 간단하며 변경되는 부분이 거의 없다  

feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=765"
image: "https://picsum.photos/2560/600/?image=765"
comment: true
---


##### Generating some data
선형 알고리즘으로 쉽게 분리 할 수 없는 분류 데이터 세트를 생성한다. 가장 좋은 예제는 다음과 같이 생성 할 수있는 나선형 데이터 세트다. 

```python
N = 100 # number of points per class
D = 2 # dimensionality
K = 3 # number of classes
X = np.zeros((N*K,D)) # data matrix (each row = single example)
y = np.zeros(N*K, dtype='uint8') # class labels
for j in xrange(K):
  ix = range(N*j,N*(j+1))
  r = np.linspace(0.0,1,N) # radius
  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta
  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
  y[ix] = j
# lets visualize the data:
plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)
plt.show()
```


![](http://cs231n.github.io/assets/eg/spiral_raw.png "spiral_raw" "width:600px;float:center;padding-left:10px;") 

선형 분리되지 않는 세 클래스(파란색, 빨간색, 노란색)로 구성된 간단한 나선형 데이터

 앞서 봤듯이  데이터 세트를 전처리하여 각 피처의 평균이 0 표준편차가 1이 되로록만든다. 하지만 위의  경우 피처는 이미 -1에서 1 사이의 괜찮은 범위에 있으므로 이 단계를 건너 뛴다. 
 
##### Training a Softmax Linear Classifier

###### Initialize the parameters

먼저 데이터 세트를 사용하여 Softmax 분류기를 학습 시킨다. 이전 절에서 보았듯이 Softmax 분류기는 선형 스코어함수를 가지고 있으며 크로스 엔트로피 로스를 사용합니다. 선형 분류기의 파라미터는 각 클래스에 대한 웨이트 행렬 W및 바이어스 벡터 b로 구성된다. 먼저 이러한 파라미터를 랜덤으로 초기화 한다. 

```python
# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))
```

D = 2 로 피쳐의 차원을 나타내며, K = 3 으로 클래스 수와 같다. 

###### Compute the class scores

이것은 선형 분류기므로 모든 클래스 스코어를 아래와 같은 단일 행렬 곱셈의 병렬 계산으로 간단하게 구할 수 있다.

```python
# compute class scores for a linear classifier
scores = np.dot(X, W) + b
```

이 예에서는 300 개의 2 차원 점이 있으므로이 곱셈 후에 스코어 배열( scores)의 크기는 [300 x 3]과 같다. 각 행은 3 개의 클래스(파란색, 빨간색, 노란색)에 해당하는 클래스 스코어를 내타낸다. 

###### Compute the loss

모델 구현에 필요한 두 번째 핵심 요소는 로스 함수다. 이것은 미분 가능한 목적함수로, 계산된 클래스 스코어의 불일치 정도를 표현한다. 직관적으로, 올바른 클래스가 다른 클래스보다 높은 점수를 가지기를 바란다. 이와 같은 경우 로스 값은 작어야하며, 그렇지 않으면 높아야합니다. 이러한 직관을 정량화하는 방법은 여러 가지가 있지만, 이 예에서는 Softmax 분류기와 관련된 크로스 엔트로피 손실을 사용한다. $f$는 하나의 샘플에 대한 클래스 점수 배열(예 : 여기서는 3 개의 숫자로 구성된 배열)이며, Softmax 분류기에서 해당 샘플의 로스값을 다음과 같이 계산한다. 

$$L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)$$

Softmax 분류기가 모든 샘플의 클래스 스코어 $f$를 각 클래스의 (비정규화 된) 로그 확률로 해석한다는 것을 알 수 있다. 정규화 되지 않은 스코어를 지수화 한다음, 정규화된 확률을 얻는다. 로그 내부 값은 올바른 클래스를 가질 정규화 된 확률이다. 이 표현식의 동작에 대해 알아보자. 로그 내부 값은 항상 0과 1 사이며, 올바른 클래스의 확률이 매우 작으면 (0에 가까울 때) 로스 값은 (양의) 무한대로 이동한다. 반대로 값이 1에 가깝다면 다음 식 $log(1) = 0$와 같이 0에 가까운 값을 가질 것이다. 따라서 표현식 $L_i$는 올바른 클래스에 대한 확률 값이 높다면 작은 값을 가질 것이고 그렇지 않다면 큰 값을 가진다. 
전체 Softmax 분류기 로스는 학습 데이터 및 정규화에 대한 평균 크로스 엔트로피 로스로 정의된다. 

$$L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \frac{1}{2} \lambda \sum_k\sum_l W_{k,l}^2 }_\text{regularization loss} \\\\$$

위에서 계산한 주어진 scores배열을 통해, 로스 값을 계산할 수 있다. 먼저, 확률을 구하는 간단한 방법살펴 보자.

```python
num_examples = X.shape[0]
# get unnormalized probabilities
exp_scores = np.exp(scores)
# normalize them for each example
probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)
```

이제 각 행에 클래스 확률이 포함 된 [300 x 3] 크기  probs배열 이 만들어 졌다. 특히, 정규화를 통해 각 행의 합은 1이 된다. 이제 각 샘플에서 올바른 클래스 값에 대한 로그 확률을 가져 올 수 ​​있다. 이는 위의 첫번째 식과 같다. 

```python
corect_logprobs = -np.log(probs[range(num_examples),y])
```

여기서 correct_logprobs 배열은 각 클래스가 올바로 할당 될 확률을 나타낸다. 이제 로그 확률들에 대한 평균과 정규화 로스를 고려한 전체 로스 표현식을 알아보자. 

```python
# compute the loss: average cross-entropy loss and regularization
data_loss = np.sum(corect_logprobs)/num_examples
reg_loss = 0.5*reg*np.sum(W*W)
loss = data_loss + reg_loss
```

이 코드에서, 정규화 파라미터 $\lambda$는 reg내부에 이으며, 0.5를 곱한 이유는 잠시 후 아래에서 알아본다. 처음 (임의의 파라미터) 얻을 수 있는 값은 loss = 1.1이다. 이는 np.log(1.0/3)이며, 랜덤으로 초기화 된 웨이트에서는 클래스에 올바르게 할당 될 확률이 1/3이기 때문이다. 이제 절대적 하한선인 loss = 0이 되도록 로스 값을 가능한 한 낮추고 싶다. 로스가 낮을수록 모든 샘플이 올바른 클래스에 할당될  확률이 높아진다. 

###### Computing the Analytic Gradient with Backpropagation

위과 같이 로스 값을 계산 할 수 있으며, 이제 그 값을 최소화할 차례다. 그래디언트 디센트를 사용 할 것이다. 즉, 위에서와 같이 무작위 파라미터로 초기화 한 다음 파라미터에 대한 로스 함수의 그라디언트를 계산하여 파라미터를 업데이트 함으로써 로스를 줄인다. 그전에 중간 변수 $q$를 소개한다. 이는 (정규화 된) 확률의 벡터로 아래와 같다. 
$$p_k = \frac{e^{f_k}}{ \sum_j e^{f_j} } \hspace{1in} L_i =-\log\left(p_{y_i}\right)$$
이제 로스 값 $L_i$를 줄이려면 $f$ 내부 스코어 값들이 어떻게 업데이트 되는지, 목적함수에 어떤 영향을 주는지를 알고 싶다. 다른 말로 그라디언트 $\partial L_i / \partial f_k$를 구하고 싶다. 로스 $L_i$는 $p$의 함수이며, $p$는 $f$로 구성되어 있다. 체인 룰을 이용하여 아래와 같이 그라디언트를 구할 수 있다. 
$$\frac{\partial L_i }{ \partial f_k } = p_k - \mathbb{1}(y_i = k)$$
얼마나 우아하고 단순한 표현식인가!! 우리가 계산 한 확률이 p = [0.2, 0.3, 0.5] 이며, 중간에 있는 확률 0.3을 가지는 클래스가 올바른 클래스라고 가정해보자. 위 미분식에 따라 스코어에 대한 그라디언트는 다음과 같다. df = [0.2, -0.7, 0.5]. 그라디언트의 해석을 생각해 보면, 이 결과가 매우 직관적이라는 것을 알 수 있다. 스코어 벡터의 첫 번째 요소 또는 마지막 요소(잘못된 클래스)를 증가 시키면 로스 값이 증가하에 되며, 당연히 로스값이 증가되는 것은 좋지 못한 일이다. 그러나 올바른 클래스의 스코어가 커지는 것은 로스가 작아지며, 따라서 -0.7의 그래디언트를 사용하여 올바른 클래스에 대한 스코어 값을 높이면, 당연하게도 로스값이 작아질 것이다. 

이 모든 것은 다음 코드에서 이뤄진다.  probs은 각 예제에 대한 모든 클래스의 확률(행)을 저장하고 있다는 것을 상기해보자. 그라디언트dscores는 다음과 같이 스코어로 부터 구할 수 있다. 

```python
dscores = probs
dscores[range(num_examples),y] -= 1
dscores /= num_examples
```

끝으로 목적함수와 scores = np.dot(X, W) + b를  scores에 대한 그라지언트(저장된 dscores) 를 통해 다음과 W와 b를 역 전파 할 수 있다 .

```python
dW = np.dot(X.T, dscores)
db = np.sum(dscores, axis=0, keepdims=True)
dW += reg*W # don't forget the regularization gradient
```

행렬 곱셈 연산을 통해 역전파 할 수 있으며, 또한 정규화에 대한 영향을 추가했다. 정규화 그래디언트를 보면 앞에서 상수 0.5를 사용했기 때문에  reg*W와 같이 매우 간단한 형식($\frac{d}{dw} ( \frac{1}{2} \lambda w^2) = \lambda w$)을 가진다. 

###### Performing a parameter update

이제 그라디언트를 통해 모든 파라미터가 로스 함수에 어떻게 영향을 미치는지 알게되었다. 이제 그래디언트의 반대 방향으로 파라미터를 업데이트 하여 로스를 줄인다. 

```python
# perform a parameter update
W += -step_size * dW
b += -step_size * db
```

###### Putting it all together: Training a Softmax Classifier

위 코드를 종합하면, 아래와 같은 Softmax 분류기를 Gradient descent를 통해 학습하는 전체 코드가 된다.

```python
#Train a Linear Classifier

# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in xrange(200):
  
  # evaluate class scores, [N x K]
  scores = np.dot(X, W) + b 
  
  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]
  
  # compute the loss: average cross-entropy loss and regularization
  corect_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(corect_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W)
  loss = data_loss + reg_loss
  if i % 10 == 0:
    print "iteration %d: loss %f" % (i, loss)
  
  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples
  
  # backpropate the gradient to the parameters (W,b)
  dW = np.dot(X.T, dscores)
  db = np.sum(dscores, axis=0, keepdims=True)
  
  dW += reg*W # regularization gradient
  
  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db
```  

위 코드를 실행하면 로스 값이 프린트 된다. 

```python
iteration 0: loss 1.096956
iteration 10: loss 0.917265
iteration 20: loss 0.851503
iteration 30: loss 0.822336
iteration 40: loss 0.807586
iteration 50: loss 0.799448
iteration 60: loss 0.794681
iteration 70: loss 0.791764
iteration 80: loss 0.789920
iteration 90: loss 0.788726
iteration 100: loss 0.787938
iteration 110: loss 0.787409
iteration 120: loss 0.787049
iteration 130: loss 0.786803
iteration 140: loss 0.786633
iteration 150: loss 0.786514
iteration 160: loss 0.786431
iteration 170: loss 0.786373
iteration 180: loss 0.786331
iteration 190: loss 0.786302
```

위 결과를 보면 약 190 회 반복 한 후에 어딘가로 수렴한 것을 알 수 있다. 다음과 같이 트레이닝 세트의 정확도를 평가할 수 있다.

```python
# evaluate training set accuracy
scores = np.dot(X, W) + b
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))
```

결과 적으로 49%가 프린트 된다. 별로 좋지는 않지만 생성 된 데이터 세트는 선형으로 분리 될 수 없다는 점을 고려하면 당연한 일이다. 또한 학습 된 분류 경계를 그려볼 수 있다. 

![](http://cs231n.github.io/assets/eg/spiral_linear.png "spiral_linear" "width:600px;float:center;padding-left:10px;") 

위와 같이 선형 분류기는 앞에서 생성한 간단한 나선형 데이터 세트를 학습하지 못한다. 

##### Training a Neural Network

위에서 다룬 선형 분류기는 분명히 이 데이터 세트에 적합하지 않으며, 우리는 이제 신경망을 사용하고자한다. 위 데이터에 대해서는 한개의 히든 레이어를 추가하는 것으로 충분하다. 우리는 이제 두 세트의 웨이트와 바이어스가 필요하다 (첫 번째 및 두 번째 레이어에 대한).

```python
# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))
```

스코어를 계산하기 위한 전방향 패스는 아래와 같이 변경된다.  


```python
# evaluate class scores with a 2-layer Neural Network
hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
scores = np.dot(hidden_layer, W2) + b2
```

이전과 달라진 부분은 코드의 한 줄을 추가하는 것 뿐이다. 여기서는 먼저 히든 레이어를 계산 한 다음 이 히든 레이어를 기반으로 스코어를 계산한다. 결정적으로, 여기서는 비선형성이 추가된다. 여기서는 0 대한 임계값을 가지는 ReLU를 활성화 함수로 사용하여 히든레이어에 비선형성을 추가하였다. 


나머지는 모두 동일하다. 이전과 똑같이 스코어에 따라 로스값을 계산하고 이전과 같이 스코어에 대한 그래디언트(dscores)를 얻는다. 하지만 당연히 역전파(backpropagate)에 대한 모델 파라미터 그라디언트로 형식은 바뀐다. 먼저 신경망의 두 번째 레이어에 대한 백프로퍼게이트는 아래와 같이 수행 할 수 있다. 여기서는 단지 위 Softmax 분류기 코드에서  X(원시 데이터)를  hidden_layer 변수로 대체한다. 

```python
# backpropate the gradient to the parameters
# first backprop into parameters W2 and b2
dW2 = np.dot(hidden_layer.T, dscores)
db2 = np.sum(dscores, axis=0, keepdims=True)
```

그러나 아직 해야할 일이 남아 있다.  hidden_layer다른 파라미터와 데이터의 함수 이기 때문에 이 변수에 대한 역 전파를 계속해야한다. 그라디언트는 다음과 같이 계산할 수 있다.

```python
dhidden = np.dot(dscores, W2.T)
```

이제 히든 레이어의 출력에대한 그라디언트를 구했다. 다음으로 ReLU 비선형성을 백프로퍼게이트해야한다. 이것은 ReLU의 역방향 패스는 사실상 스위치로 동작하므로 쉽게 구현할 수 있다. $r = max(0, x)$이므로 $\frac{dr}{dx} = 1(x > 0)$이 된다.  체인 룰을 사용하여, 순방향 패스 중 ReLU 유닛의 입력이 0보다 큰 경우에는 그라디언트가 그대로 통과 할 수 있지만 0보다 작은 그라디언트 값은 죽게 된다. 따라서 우리는 ReLU를 다음과 같이 단순히 백프로퍼게이트 할 수 있다.

```python
# backprop the ReLU non-linearity
dhidden[hidden_layer <= 0] = 0
```

이제 첫 번째 레이어에 대한 웨이트와 바이어스의 그라디언트를 구한다. 

```python
# finally into W,b
dW = np.dot(X.T, dhidden)
db = np.sum(dhidden, axis=0, keepdims=True)
```

이것으로 모두 끝났다!  dW,db,dW2,db2파라미터에 대한 그라디언트를 가지고 있으며 업데이트를 수행 할 수 있다. 나머지는 부분은 변경되지 않는다. 따라서 전체 코드는 선형분류기와 매우 유사하다.

```python
# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in xrange(10000):
  
  # evaluate class scores, [N x K]
  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
  scores = np.dot(hidden_layer, W2) + b2
  
  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]
  
  # compute the loss: average cross-entropy loss and regularization
  corect_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(corect_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)
  loss = data_loss + reg_loss
  if i % 1000 == 0:
    print "iteration %d: loss %f" % (i, loss)
  
  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples
  
  # backpropate the gradient to the parameters
  # first backprop into parameters W2 and b2
  dW2 = np.dot(hidden_layer.T, dscores)
  db2 = np.sum(dscores, axis=0, keepdims=True)
  # next backprop into hidden layer
  dhidden = np.dot(dscores, W2.T)
  # backprop the ReLU non-linearity
  dhidden[hidden_layer <= 0] = 0
  # finally into W,b
  dW = np.dot(X.T, dhidden)
  db = np.sum(dhidden, axis=0, keepdims=True)
  
  # add regularization gradient contribution
  dW2 += reg * W2
  dW += reg * W
  
  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db
  W2 += -step_size * dW2
  b2 += -step_size * db2
```

프린트 결과 

```python
iteration 0: loss 1.098744
iteration 1000: loss 0.294946
iteration 2000: loss 0.259301
iteration 3000: loss 0.248310
iteration 4000: loss 0.246170
iteration 5000: loss 0.245649
iteration 6000: loss 0.245491
iteration 7000: loss 0.245400
iteration 8000: loss 0.245335
iteration 9000: loss 0.245292
```

학습 정확도는 아래와 같이 출력 할 수 있다. 

```python
# evaluate training set accuracy
hidden_layer = np.maximum(0, np.dot(X, W) + b)
scores = np.dot(hidden_layer, W2) + b2
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))
```

98 %가 나왔다!!! 결정 경계를 시각화 할 수도 있다.

![](http://cs231n.github.io/assets/eg/spiral_net.png "spiral_net" "width:600px;float:center;padding-left:10px;") 

신경망 기반 분류기는 나선형 데이터 세트도 잘 학습한다. 

##### Summary

간단한 2D 데이터 세트를 사용하여, 선형 네트워크와 2 레이어 뉴럴 네트워크를 학습했다. 선형 분류기에서 뉴럴 네트워크로의 변경하는 데는 코드가 거의 바뀌지 않음을 알 수 있다.  스코어 함수는 형태를 바꾸는 1줄의 코드 추가와, 파라미터에 대한 백프로파게이션에서 변경이 있었다. 

- [HTML로 렌더링 된 IPython Notebook 코드](http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.html)를 보길 추천한다. 
- 또는 [ipynb 파일](http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.ipynb)을 다운로드하라. 
