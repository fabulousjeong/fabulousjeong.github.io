---
title: 18 Pairwise Markov Networks
category: ProbabilisticGraphicalModels
excerpt: |
  앞선 그래프이론의 개요에서 그래프 모델에는 방향성이 있는 유향 그래프와 방향성이 없는 그래프가 있다고 설명했습니다. 지금까지는 유향 그래프인 베이지안 네트워크를 다뤘습니다.   


feature_text: |
  ## [Coursera] Probabilistic Graphical Models
  Daphne Koller의 Probabilistic Graphical Models 강의 정리

  ref: [https://www.coursera.org/learn/probabilistic-graphical-models/home](https://www.coursera.org/learn/probabilistic-graphical-models/home "coursera")

feature_image: "https://picsum.photos/2560/600/?image=798"
image: "https://picsum.photos/2560/600/?image=798"
comment: true
---


##### Markov Networks

앞선 그래프이론의 개요에서 그래프 모델에는 방향성이 있는 유향 그래프와 방향성이 없는 그래프가 있다고 설명했습니다. 지금까지는 유향 그래프인 베이지안 네트워크를 다뤘습니다. 이번 강의에서는 방향성이 없는 그래프인  Markov networks에 대해 알아보겠습니다. 우선 가장 간단한 pairwise Markov networks를 먼저 살펴 본 다음 일반화 하겠습니다.   

![](http://cfile21.uf.tistory.com/image/2764413B58AD7AB72B81E6 "Markov networks" "width:600px;float:center;padding-left:10px;")

위 그림은 간단한 마르코프 네트워크를 표현합니다. 함께 쌍으로 공부하는 4명의 친구를 모델링했습니다. 위 그림에서 앨리스와 찰스, 밥과 데비는 서로 친하지 않아 같이 공부하지 않습니다. 당연히 서로에 대한 영향력은 없을 것입니다. 반면 함께 공부하는 두 학생은 서로 영향을 줍니다. 앨리스는 밥에게 영향을 주고 밥 역시 엘리스에게 영향을 줍니다. 화살표를 양쪽으로 그리는 대신 방향성이 없는 선으로 표현합니다. 부모-자식 관계가 아니므로 조건부 확률 분포로 표현 할 수 없습니다. 이제 이러한 영향력을 확률 분포로 어떻게 표현 할 수 있을까요?    

![](http://cfile6.uf.tistory.com/image/2136553B58AD7AB70AF596 "Markov networks" "width:600px;float:center;padding-left:10px;")

위 그래프와 같이 서로 미치는 영향력을 위 그림과 같이 factor를 사용하여 표현 할 수 있습니다. 여기서 factor는 0~1사이의 범위를 가지지 않습니다. 이때 이러한 함수를 관련성 함수(affinity functions) 또는 호환성 함수(compatibility functions)라 부릅니다. 또는 소프트 제약조건(soft constraints)이라 부르기도 합니다. 위 그림에서 숫자가 의미하는 바는 A와 B가 같이 과제를 수행했을 때의 행복도 입니다. A와 B 둘다 0일때 가장 그 값이 높으며, 그 다음으로 둘 다 1일때 값이 높습니다. 즉 A와 B는 서로 의견이 일치할 때 행복도가 높아 집니다. 이것은 A와 B에 대한 지역적(local)모델이며 다른 변수에 대해서도 비슷하게 모델링 할 수 있습니다. B와 C는 서로의 의견이 일치할때 행복도가 매우 높습니다. 반면 찰스(C)와 대비(D)는 서로 의견이 다를 때 논쟁하는 것에 더 행복함을 느낌니다. 그리고 A와 B는 의견이 일치할때 행복도가 높습니다. 전체 상태를 보기위해 factor를 곱하겠습니다.    

![](http://cfile27.uf.tistory.com/image/2669F93B58AD7AB83530B8 "Markov networks" "width:600px;float:center;padding-left:10px;")

그 결과는 위 표와 같습니다. 하지만 이것은 확률 분포가 아닙니다. 0~1사이의 값을 가지지도 않으며 그 합이 1인 것도 아닙니다. 확률 분포로 바굴려면 노말라이즈(normalize)해야 합니다. 위 표의 값을 모두 더한 후 그 값(Z)으로 P틸다를 나눠줍니다. 이러한 함수를 partition 함수라 부릅니다. 이제 값들은 노말라이즈 되었으며 확률 분포를 나타냅니다.  

![](http://cfile24.uf.tistory.com/image/232BA63B58AD7ABA15E608 "Markov networks" "width:600px;float:center;padding-left:10px;")

이제 A와 B사이의 local 행복도 $\phi_1$를 살펴보고 이들의 확률 분포와 어떻게 관련있는지 다루겠습니다. 위 그림을 보면 $\phi_1$에서 A와 B가 서로 같은 값을 가질 때 factor역시 높은 값을 가지는 것을 볼 수 있습니다. 하지만 확률 분포 표를 보면 그렇지 않습니다. A가 0이고 B가 1인 경우 가장 큰 확률을 가집니다. 그 이유는 위 그래프에서 A-D, B-C 관련성이 매우 크고 특히 D와 C가 다를때 값이 크기 때문입니다 반면 A-B는 서로 같을 때 상대적으로 큰 값을 가집니다. 따라서 전체 루프에서 모순이 생기며, 깨져야 하는데  이 때 가장 취약한(값이 작은)연결은 A-B입니다. 실제 위 표를 보면 $a^0, b^1, c^1, d^0$일때 매우 큰 값인 5,000,000을 가지는 것을 볼 수 있습니다. $a^0, b^0$ 혹은 $a^1, b^1$에 비해 상대적으로 큰 값을 가지는 것을 알 수 있습니다. 따라서 $P_\Phi(A,B)$는 로컬 행복도인 $\phi_1$보다 전체 확률 분포에 더 영향을 많이 받습니다. 여기에 대한 심화 내용은 코스의 뒷부분에서 더 자세히 다루겠습니다.   

##### Pairwise Markov Networks

![](http://cfile23.uf.tistory.com/image/245D903B58AD7ABB2DE774 "Pairwise Markov networks" "width:600px;float:center;padding-left:10px;")

pairwise Markov networks는 여러 노드로 구성된 무향 그래프입니다. 그리고 관련성이 있는 두 노드($X_i, X_j$)를 간선으로 연결하였으며 관련성은 factor(potential) $\phi_{ij}$로 표현합니다. 

![](http://cfile24.uf.tistory.com/image/2737763B58AD7ABC1DC4B0 "Pairwise Markov networks" "width:600px;float:center;padding-left:10px;")

위 그림은 조금 더 복잡한 격자구조의 pairwise Markov networks입니다. 

![](http://cfile29.uf.tistory.com/image/2571693B58AD7ABC05C913 "Pairwise Markov networks" "width:600px;float:center;padding-left:10px;")

이미지 분할에서도 각 슈퍼픽셀을 한 노드로 모델링 하여 pairwise Markov networks로 표현 할 수 있습니다. 



