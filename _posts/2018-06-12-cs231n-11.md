---
title: cs231n 번역 11 Transfer Learning and Fine-tuning Convolutional Neural Networks
excerpt: |
 실제로는, 충분한 큰 데이터 세트를 가지기 어렵기 때문에, 전체 Convolutional 네트워크를 처음부터(무작위 초기화를 통해) 학습시키는 일은 거의 없다.    

feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=849"
image: "https://picsum.photos/2560/600/?image=849"
comment: true
---


#### Transfer Learning

실제로는, 충분한 큰 데이터 세트를 가지기 어렵기 때문에, 전체 Convolutional 네트워크를 처음부터(무작위 초기화를 통해) 학습시키는 일은 거의 없다. 대신, 매우 큰 데이터 세트(예 : ImageNet, 1000 개의 카테고리와 120만 개의 이미지로 구성)에서 ConvNet을 미리 학습(pretrain) 한 다음, 이를 해당 학습에 대한 초기화 또는 고정 피쳐 추출기(fixed feature extractor)로 미리 학습된 이 ConvNet을 사용한다. 세 가지 주요 Transfer Learning 시나리오는 다음과 같다.

- **ConvNet as fixed feature extractor.** ImageNet에서 미리 학습된 ConvNet을 사용하며, 마지막 완전 연결 레이어를 제거한 다음(이 레이어의 출력은 ImageNet의 목적인 1000 개의 클래스 스코어임), ConvNet의 나머지 부분을 새 데이터 세트의 고정 피쳐 추출기로 사용한다. AlexNet을 예로 들면, 모든 이미지에 대해 4096-D 벡터를 얻을 수 있는데 이는 분류기 ​​바로 전 히든 레이어의 활성화 노드와 같다. 이러한 특성을 CNN 코드 라고 부른다. 만약 ImageNet의 ConvNet 학습 과정에서 임계값을 설정 한 경우 (일반적으로 0), 이러한 코드를 ReLUd(즉, 임계 값이 0 인 경우)하는 것이 중요하다. 모든 이미지에 대해 4096-D 코드를 추출한 후 새 데이터 세트에 대한 선형 분류기(예 : 선형 SVM 또는 Softmax 분류기)를 학습하라. 
- **Fine-tuning the ConvNet.** 두 번째 전략은 새로운 데이터 세트의 ConvNet상단의 분류기를 교체하고 재교육하는 것뿐만 아니라, 역전파를 계속함으로써 기 학습된 네트워크의 웨이트 또한 미세 조정(업데이트)하는 것이다. ConvNet의 모든 레이어를 미세 조정하거나 이전 레이어 중 일부를 고정시키고(overfitting의 위험성 때문에) 네트워크의 일부 상위 몇몇 레이어 만 미세 조정할 수도 있다. 이것은 다음과 같은 고찰에 의해 나왔다. ConvNet의 앞부분에 있는 레이어는 많은 작업에 유용한 일반적인 특성(예 : edge detectors or color blob detectors)을 나타내지만, ConvNet의 후반부 레이어는 학습된 DB에 포함된 각 클래스의 세부 특성을 나타낸다.  예를 들어, 많은 개 품종에 대한 ImageNet DB의 경우, ConvNet의 상당 부분은 개 품종을 구별하는 데 특화된 특성을 학습하는데 사용될 것이다. 
- **Pretrained models.** 최근 ConvNets은 ImageNet을 학습하는데 여러 GPU를 사용해서 2 ~ 3 주 정도의 시간이 걸리기 때문에, 다른 사람들이 네트워크를 미세 조정 할 수 있도록, ConvNet 최종 체크 포인트를 공개하는 것이 일반적이다. 예를 들어 Caffe 라이브러리는 학습 된 네트워크 웨이트를 제공하는  Model Zoo가 포함 되어 있다. 

**When and how to fine-tune?** 새로운 데이터 세트에서 수행해야하는 Transfer Learning의 유형을 어떻게 결정할까? 이것을 결정하기 위해서는 몇 가지 요인을 살펴봐야 하지만, 가장 중요한 두 가지 요소는 새로운 데이터 세트의 크기(작거나 큰)와 원본 데이터 세트와의 유사성이 있다.(예 : ImageNet의 경우 일반적인 클래스와는 유사성을 가지지만, 현미경 이미지와는 매우 다르다.). ConvNet 피쳐는 초기 레이어에서는 보다 일반적이며, 후반부 레이어에서는 원래의 데이터 집합에 보다 관련되어 있다는 점을 주의하자. 여기 일반적으로 사용하는 4 가지 주요 시나리오가 있다. 

1. 새로운 데이터 세트는 작으며 원본 데이터 세트와 유사하다. 데이터가 작기 때문에 ConvNet이 잘 학습되지 않는 문제가 있다. 따라서 이 경우 ConvNet을 전체를 미세 조정하는 것은 좋지 않다. 데이터가 원본 데이터와 유사하기 때문에 ConvNet의 상위 수준 피쳐 역시 이 데이터 집합과 관련이 있다고 예상할 수 있다. 따라서 가장 좋은 아이디어는 CNN 코드를 가져와 선형 분류기만 훈련시키는 것이다. 
2. 새 데이터 세트는 크고 원본 데이터 세트와 유사하다. 더 많은 데이터를 보유하고 있기 때문에 전체 네트워크에 대해 미세 조정을 시도한다면 오버피팅 될 것이라 확신할 수 있다. 따라서 일부 레이어만 미세조정한다. 
3. 새 데이터 세트는 작으며, 원본 데이터 세트와 매우 다르다. 데이터가 작기 때문에 선형 분류자만을 학습하는 것이 가장 좋다. 데이터 세트가 매우 다르므로 데이터세트와 연관성이 많은 피쳐를 포함한 레이어와 연결하여 학습하는 것은 좋지 않다. 대신 네트워크 초반부 레이어와 SVM 분류기를 연결하는 것이 더 효과적 일 수 있다.
4. 새 데이터 세트는 크고 원본 데이터 세트와 매우 다르다. 데이터 세트가 매우 크기 때문에 ConvNet을 처음부터 학습 할 여력이 있다고 볼 수 있다. 예상 할 수 있습니다. 그러나 실제로는 미리 학습 된 모델의 가중치로 초기화하는 것이 매우 유용하다. 이 경우 전체 네트워크를 미세 조정할 수있는 충분한 데이터와 신뢰도(오버피팅이 되지 않음)가 있다. 

**Practical advice.** transfer learning을 수행 할 때 유의해야 할 몇 가지 추가 사항이 있다.

- **미리 학습 된 모델의 제약 조건.** 기 학습 된 네트워크를 사용하는 경우 새 데이터 세트에 사용할 수있는 아키텍처 측면에서 약간 제한적일 수 있다. 예를 들어, 미리 학습된 네트워크에서 임의의 Conv 레이어를 가져올 수 없다. 그러나 간단히 이를 변형 할 수 있다. 파라미터 공유로 인해 다른 크기를 가지는 이미지에서도 기 학습 된 네트워크를 쉽게 실행할 수 있다. 이는 순방향 전달 함수가 입력 볼륨 크기와 별개이기 때문에 Conv / Pool 레이어의 경우 분명하다. (단 스트라이드가 "적합"한 경우). FC 레이어의 경우, FC 레이어가 Conv 레이어로 변환 될 수 있기 때문에 여전히 유효하다. 예를 들어 AlexNet에서 첫 번째 FC 레이어 이전의 최종 풀링 볼륨은 [6x6x512]이다. 따라서 이 볼륨과 연결된 FC 레이어는 커널 필터 크기가 6x6이며, 제로패팅 크기가 0인 컨볼루션 레이어와 동일하다
- **학습 속도 .** 새 데이터 집합의 클래스 스코어를 계산하는 새로운 선형 분류기에 있어, (임의로 초기화 된) 웨이트와 비교하여 미세 조정 ConvNet 웨이트의 경우 더 작은 학습 속도를 사용하는 것이 일반적이다. 이것은 ConvNet 가중치가 상대적으로 좋을 것으로 예상 되기 때문에 너무 빨리 그리고 너무 많이 이를 왜곡하지 않기를 바라기 때문이다. 

##### Additional References

- [CNN Features off-the-shelf](http://arxiv.org/abs/1403.6382): an Astounding Baseline for Recognition trains SVMs on features from ImageNet-pretrained ConvNet and reports several state of the art results.
- [DeCAF](http://arxiv.org/abs/1310.1531) reported similar findings in 2013. The framework in this paper (DeCAF) was a Python-based precursor to the C++ Caffe library.
- [How transferable are features in deep neural networks?](http://arxiv.org/abs/1411.1792) studies the transfer learning performance in detail, including some unintuitive findings about layer co-adaptations.
