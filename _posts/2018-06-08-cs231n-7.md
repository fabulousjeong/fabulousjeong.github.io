---
title: cs231n 번역 7 Neural Networks Part 3 Learning and Evaluation
excerpt: |
 이전 섹션에서는 네트워크 구조, 데이터 및 로스 함수 등 신경망의 정적인 부분에 대해 논의했다. 이번 섹션에서는 다이나믹스, 즉 웨이트 파라미터를 학습하고 좋은 하이퍼 파라미터를 찾는 과정에 대해 논의 한다.  

feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=765"
image: "https://picsum.photos/2560/600/?image=765"
comment: true
---


#### Learning
이전 섹션에서는 네트워크 구조, 데이터 및 로스 함수 등 신경망의 정적인 부분에 대해 논의했다. 이번 섹션에서는 다이나믹스, 즉 웨이트 파라미터를 학습하고 좋은 하이퍼 파라미터를 찾는 과정에 대해 논의 한다. 

#####Gradient Checks
이론적으로 그라디언트 체크를 수행하는 것은 analytic(분석적) 그라디언트와 numerical(수치적) 그라디언트를 비교하는 것 만큼 간단하다. 실제로 이 프로세스는 생각 보다 더 복잡하고 오류가 발생하기 쉽다. 주의해야 할 몇 가지 팁, 트릭 및 이슈는 아래와 같다. 

**Use the centered formula.**  numerical 그라디언트 수행 시 finite difference approximation 공식은 다음과 같다.

$$\frac{df(x)}{dx} = \frac{f(x + h) - f(x)}{h} \hspace{0.1in} \text{(bad, do not use)}$$

여기서 $h$는 매우 작은 수이며, 약 1e-5 정도 값을 사용한다. 실제로는 위의 식보다, 아래와 같은 centered difference 공식을 더 많이 사용한다.  

$$\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in} \text{(use instead)}$$

이를 위해서는 로스 함수를 두 번 계산해야하므로 계산비용이 약 2 배 정도 더 발생하지만, 그라디언트 근사의 정확도가 훨씬 더 높다. $f(x + h)$와 $f(x - h)$에 대한 테일러 공식을 보면 처음 공식의 경우 $O(h)$의 오차를 보이는 반면, 두번째 공식의 경우 $O(h^2)$의 오차를 보인다. 

**Use relative error for the comparison.** 수치(numerical) 그라디언트 $f’_n$ 과 분석(analogy) 그라디언트 $f’_a$를 비교하는 방법을 무엇일까? 둘 사이에 호환성이 없을을 어떻게 확인할 수 있을까? 아마 두 그라디언트의 차이 $\mid f’_a - f’_n \mid$나 그것의 제곱을 정의한 다음 다음 특정 값 보다 작은 경우 호환성이 없다고 판단 할 수 있을 것이다. 하지만 이것은 약간의 문제가 있다. 두 그라디언트의 차이가 1e-4인 경우를 생각해보자. 그라디언트 값이 1.0 정도라면 그 차이는 별로 나지 않아 보이므로 적절하게 수치화 되었다고 볼 수 있다. 하지만, 그라이던트값이 1e-5이거나 그것보다 작다면, 1e-4라는 차이는 굉장히 커보인다. 아래 상대 오차를 고려한 더 적합한 식이 있다.     

$$\frac{\mid f'_a - f'_n \mid}{\max(\mid f'_a \mid, \mid f'_n \mid)}$$

위 식은 두 그라디언트의 절대 값에 대한 차이의 비율을 고려한다. 일반적으로 상대 오차 공식에는 둘 중 하나만 분모에 포함되지만,  둘 중 하나가 0 인 경우 0으로 나누는 것(특히 ReLUs의 경우 자주 발생함.)을 방지하기 위해 둘 다 분모에 추가한 다음 최대 값을 적용한다. 그러나 여기서는 둘 모두가 0 인 경우를 명시적으로 확인한 다음 그래디언트 검사를 넘겨야한다. 실제로:

- 상대 오차>1e-2는 일반적으로 그라디언트가 잘못되었다는 것을 의미한다. 
- 1e-2>상대 오차>1e-4 인 경우 약간 적합하지 한다.  
- 1e-4>상대 오차의 경우 꼬임(kinks)이 있는 목적함수에 대해서는 일반적으로 사용 할 만다하다. 그러나 꼬임이없는 경우(예 : tanh 비선형성 및 softmax 사용) 1e-4가 너무 큰 값이다. 
- 1e-7 이하면 괜찮은 값이다. 
또한 네트워크가 깊어 질수록 상대적 오차도 커진다. 따라서 10-layer 네트워크의 입력 데이터를 그래디언트 검사하는 경우 많은 오차가 발생하기 때문에 1e-2의 상대 오차는 괜찮을 수 있다. 반대로, 하나의 미분 가능 함수에 대한 1e-2의 오차는 부정확한 그라디언트를 나타낼 가능성이 있다.

**Use double precision.** 일반적으로 나오는 실수는 single precision floating point을 사용하여 그라디언트 검사를 계산하는 것이다. 이러한 경우 그라디언트가 정확히 구현 되었더라도, 상대 오차가 높게(1e-2만큼 높음) 발생하는 경우가 종종 있다. 경험상 double precision floating point로 전환했을 때 1e-2에서 1e-8까지 ​​상대 오차가 급격히 감소하는 것을 본 적이 있다.

**Stick around active range of floating point.** “[What Every Computer Scientist Should Know About Floating-Point Arithmetic](http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)”를 읽는 것이 좋다. 오차에 대한 보다 주의 깊은 코드를 작성할 수 있기 때문이다. 예를 들어, 신경망에서 배치(batch)를 통해 로스 함수를 정규화하는 것이 일반적이다. 그러나 데이터 샘플 당 그라디언트가 매우 작으면 추가적으로 데이터 샘플 수로 나누면 아주 작은 숫자가 나오게 된다. 그렇기 때문에 항상 수치/분석 그라디언트를 항상 프린트하고 비교하는 값이 극히 작은지 확인한다. (예 : 대략 1e-10보다 작은 경우 주의해야한다.). 로스 함수를 증가시키는 방향으로 조정하여 로스 값을 "더 좋은"범위(이상적으로 플로트 지수가 0 인 1.0 정도)로 가져올 수 있다.

**Kinks in the objective.** 그라디언트 검사 중에 주의 할 부정확성의 원인으로 꼬임(kinks) 문제가 있다. 꼬임은 ReLU($max(0,x)$)나 SVM, Maxout과 같은 뉴런에 의해 발생하는 목적 함수의 미분 불가능한 부분을 가리킨다. x = -1e6일 때 ReLU함수의 그라디언트 검사를 보자. 이 경우 $x < 0$이므로 분석 그라디언트 값은 0이다. 하지만 수치 그라디언트 값은 0이 아닐 수 있다. $h>1e-6$인 경우 $f(x+h)$는 꼬임 부분을 넘어가고 그라디언트 값은 0이 아니게 된다. 일부 잘못된 사례라고 생각 할 수 있지만, 사실 이러한 경우는 매우 빈번하게 발생한다. cifar10에 대한 SVM의 경우 450,000개의 $max(0,x)$ 항을 포함한다. 더욱이 SVM을 포함한 신경망의 경우 그 수는 더 많을 것이다.

**Use only few datapoints.** 위의 꼬임 문제에 대한 한 가지 해결책은 더 적은 데이터 포인트를 사용하여, 꼬임 수를 줄여 미분 범위가 꼬임과 교차 할 가능성을 감소시키는 것이다. 또한, 두세개의 샘플에 대한 그라디언트 검사의 경우에도 거의 정확히 전체 배치에 대한 그라디언트 검사를 반영할 것이다. 데이터 샘플을 거의 사용하지 않아도 그라디언트 검사를보다 빠르고 효율적으로 수행 할 수 있다.

**Be careful with the step size h.** h가 작을수록 더 좋다고 볼 수는 없다. 왜냐하면 h가 매우 작은 경우 숫자 정밀도 문제가 발생할 수 있다. 때로는 그라디언트가 잘 맞지 않는 경우 h를 1e-4 또는 1e-6로 바꾼면 갑자기 그라디언트가 정확해 지기도했다. 이 [위키 백과 문서](http://en.wikipedia.org/wiki/Numerical_differentiation) 에는 x 축의 h 값 과 y 축의 수치 그라디언트 오류를 나타내는 차트가 있다 .

**Gradcheck during a “characteristic” mode of operation.** 그라디언트 검사가 파라미터 공간에서 특정 (일반적으로 무작위) 단일 지점에서 수행된다는 것을 인식하는 것이 중요하다. 그 자점에서 그래디언트 검사가 성공하더라도 그래디언트가 전역 적으로 올바르게 구현되었는지 확실하지 않다. 또한 무작위 초기화는 파라미터의 공간의 가장 "특징적인"점이 아닐 수 있으며, 실제로 그라디언트가 올바르게 구현 된 것으로 보이는 특정상황이 나오는 것 처럼 보이기도 하지만 그렇지 않는 경우도 있다. 예를 들어, 매우 작은 값으로 웨이트 초기화를 하는 경우, SVM은 모든 데이터 포인트에 거의 0을 할당 할 것이고, 그라디언트는 모든 데이터 포인트에서 특정 패턴을 나타낼 것이다. 그래디언트의 잘못된 구현은 여전히 이 패턴을 보이게 할 수 있다. 가장 안전한 방법은 번-인 (burn-in) 시간(로스가 감소하기 시작함)에 그라이던트 검사를 수행하는 것이다. 첫 번째 반복문에서 그라디언트 검사를 수행하는 경우 그라디언트의 잘못된 구현이 드러나지 않을 수도 있다. 

**Don’t let the regularization overwhelm the data.** 로스 함수는 데이터 로스와 정규화 로스 (예 : 가중치에 대한 L2 패널티)의 합이되는 경우가 종종 있다. 알아야할 한 가지 위험은 정규화 로스가 데이터 로스를 압도 할 수 있다는 것다. 이 경우 그라디언트는 주로 정규화 (일반적으로 훨씬 간단한 그래디언트 표현식)에서 나온다. 이렇게하면 데이터 로스 그라디언트의 잘못된 구현이 드러나지 않을 수 있다. 따라서 정규화를 해제하고 데이터 로스만 확인한 다음 정규화 항을 다시 독립적으로 확인하는 것이 좋다. 후자를 수행하는 한 방법은 코드를 수정하여 데이터 로스의 영향을 제거하는 것이다. 또 다른 방법으로 그 효과가 그래디언트 검사에서 무시할 수 있을 만큼 작게되도록 정규화 강도를 높이는 것이다.

**Remember to turn off dropout/augmentations.**  그래디언트 검사를 수행 할 때 드롭 아웃, 임의 데이터 증가 등과 같이 네트워크의 비결정적 효과들을 해제하는 것을 잊지 말아야한다. 그렇지 않으면 수치 그래디언트를 계산할 때 거대한 오류가 발생할 수 있다. 

**Check only few dimensions.** 실제로 그라디언트는 백만 개의 파라미터에 해당하는 크기를 가질 수 있다. 이러한 경우 그래디언트의 일부 값를 확인하고 나머지가 올바른 것으로 가정하는 것이 실용적이다. 

##### Before learning: sanity checks Tips/Tricks
다음은 복잡한 최적화 과정에 뛰어 들기 전에 고려할 수있는 몇 가지 적절한 검사를 살펴보자.

- Look for correct loss at chance performance. 작은 파라미터로 초기화 할 때 로스가 예상되는 값인지 확인하라. 데이터 로스만 확인하는 것이 가장 좋다 (따라서 정규화 강도를 0으로 설정). 예를 들어 Softmax 분류기가있는 CIFAR-10의 경우 초기 손실은 2.302가 될 것으로 예상 할 수 있다. 왜냐하면 각 클래스 (10 개의 클래스가 있기 때문에)에 대해 0.1의 확률을 예상하기 때문이다. Softmax 손실은 올바른 클래스에 대해 negative 로그 확률이므로 : -ln (0.1) = 2.302가 될것이며, Weston Watkins SVM의 경우 마진에 포함되지 않을 것이므로(모든 점수가 거의 제로이기 때문에) 따라서 9의 로스값이 예상된다. 이러한 로스값이 나오지 않는다면 초기화에 문제가있을 수 있다.
- 두 번째 검사로는, 정규화 강도를 높이면 로스값이 증가함을 유의하자. 
- Overfit a tiny subset of data. 마지막으로 가장 중요한 점은 전체 데이터 세트를 학습시키기 전에 데이터의 아주 작은 부분 (예 : 20 개의 샘플)을 학습하고 비용함수의 값이 0이 되도록해야한다는 것이다. 이 실험에서는 정규화를 0으로 설정하는 것이 가장 좋다. 그렇지 않으면 비용함수 결과로 0을 얻을 수 없다. 작은 데이터 세트로 이 건정성 체크를 통과하지 않으면 전체 데이터 세트로 진행할 가치가 없다. 아주 작은 데이터 세트에 대한 검사를 통과 한다하더라도 여전히 잘못된 구현이 있을 수 있다. 예를 들어 데이터 샘플의 피쳐가 일부 버그로인래 무작위 값을 가진다면, 경우 작은 양의 훈련 세트에 대해 오버핏 될 수 있지만 전체 데이터 세트를 적용 시킬때 일반화에 대해 전혀 인식하지 못한다.

##### Babysitting the learning process
신경망 학습 시 여러 유용한 값들을 모니터링해야한다. 아래 그림은 학습 과정은 교육 과정을 나타내며, 다양한 하이퍼 매개 변수 설정에 대한 직관을 얻고, 더 효율적인 학습을 위해 어떻게 변경되어야 하는지를 파악하는 데 활용된다.

아래 그래프의 x 축은 에포크 단위이며, 데이터 셋의 모든 샘플이 몇 번이나 학습되었는지 나타낸다. 반복 횟수는 배치 크기에 따라 달라지기 때문에 반복횟수보다는 에포크를 기준으로 삼는 것이 바람직하다.

###### Loss function

로스 값은 학습 과정 중 추적 할수 있는 유용한 값이며, 이 값은 순방향 전파중 각 배치 단위로 측정 한다. 아래는 시간에 따른 카툰 다이어그램이며, 그래프의 모양은 학습 속도의 영향을 알려준다. 

![](http://cs231n.github.io/assets/nn3/learningrates.jpeg "learningrates" "width:300px;float:center;padding-left:10px;") ![](http://cs231n.github.io/assets/nn3/loss.jpeg "loss" "width:300px;float:center;padding-left:10px;")

**왼쪽** : 다양한 학습 속도의 효과를 묘사 한 다이어그램. 학습 속도 파라미터가 작은 값이면 낮으면 선형적으로 로스가 줄어 들 것이다. 높은 학습 속도 학습하면 보다 기하 급수적으로 보일 것이다. 하지만 학습속도가 높을수록 로스는 더 빨리 줄어들지만 더 나쁜 최종값 (녹색 선)에 머물게 된다. 이는 너무 큰 에너지에 대해 최적화를 수행해야되므로, 최적화 할 파라미터에 혼동을 줄 수 있기 때문이다. **오른쪽** :CIFAR-10 데이터 세트에서 소규모 네트워크를 학습하면서 기록한 시간 경과에 따른 전형적인 로스 함수 값의 예. 이 로스 함수는 합리적인 것처럼 보인다.(학습 속도가 너무 느린 것 처럼 보일 수도 있지만, 이를 단정하기는 어렵다). 또한 배치 크기가 너무 작을 수도 있다.(값이 노이즈 처럼 보이기 때문에).

로스 값의 "흔들림"은 배치 크기와 관련이 있다. 배치 크기가 1 일 때 흔들림이 상대적으로 높다. 배치 크기가 전체 데이터 세트인 경우 모든 그라디언트 업데이트에서 로스 함수는 단조롭게 개선되므로(학습 속도가 너무 높게 설정되지 않는 한) 흔들림이 최소화된다.

어떤 사람들은 로그 도메인에 로스 함수를 그려 넣는 것을 선호한다. 학습 진행 정도는 일반적으로 기하 급수적 인 형태를 취하기 때문에, 그림은 하키 스틱과 같은 모양 보다는 약간 더 해석하기 쉬운 직선으로 나타난다. 또한 여러 교차 유효성 모델을 동일한 로스 그래프에 그려 보면 이들 간의 차이를 더욱 분명히 볼 수 있다. 

 [lossfunctions.tumblr.com](http://lossfunctions.tumblr.com/).여기서 다양한 로스 함수 그래프를 볼 수 있다. 
 
###### Train/Val accuracy

분류기를 학습하는 동안 살펴 볼 두 번째 중요한 값은 검증/훈련 정확도이다. 이 그림은 모델의 오버피팅에 대한 중요한 통찰력을 제공한다.

![](http://cs231n.github.io/assets/nn3/accuracies.jpeg "accuracies" "width:600px;float:center;padding-left:10px;")

훈련과 검증 정확도 사이의 차이는 오버피팅의 정도를 나타낸다. 가능한 두 가지 경우가 왼쪽의 다이어그램에 나와 있다. 청색 검증 오차 곡선은 훈련 정확도와 비교하여 매우 낮은 검증 정확도를 나타내며 오버피팅이 많이 되었다는 것을 나타낸다. 이러한 경우 실제로는 정규화(L2 체중 감소, 탈락 등)를 높이거나 더 많은 데이터를 수집하려고 한다.  다른 가능한 경우는 유효성 검사 정확도가 학습 정확도를 상당히 잘 따라가는 경우다. 이 경우 모델 복잡도가 크지 않음을 나타낸다. 파라미터 수를 늘려 모델을 크게 만들 수 있다.

###### Ratio of weights:updates

살펴 볼 마지막 값은 웨이트 값의 크기에 대한 업데이트 크기의 비율입니다. 참고: 그라디언트값이 아니라 업데이트 값(예 : sgd에서는 그라디언트에 학습 속도를 곱한 값). 모든 파라미터 집합에 대해 이 비율을 독립적으로 평가하고 추적 할 수 있다. 경험적으로 이 비율이 1e-3 근처 여야 한다는 것이다. 이 값보다 낮으면 학습 속도가 너무 낮게 설정 되어 있을 수  있다. 반면 이 값이 크다면 학습 속도가 학습 속도가 너무 높을 수 있다. 다음은 구체적인 예제 코드다.

```python
# assume parameter vector W and its gradient vector dW
param_scale = np.linalg.norm(W.ravel())
update = -learning_rate*dW # simple SGD update
update_scale = np.linalg.norm(update.ravel())
W += update # the actual update
print update_scale / param_scale # want ~1e-3
```

최소 또는 최대 값을 추적하는 대신, 그래디언트 및 그 업데이트의 놈(norm)을 계산하고 추적하는 것을 선호한다. 이러한 측정 항목은 일반적으로 서로 관련되어 있으며 거의 ​​동일한 결과를 제공한다.

###### Activation / Gradient distributions per layer

올바르지 않은 초기화는 학습 프로세스의 속도를 늦추거나 완전히 멈출게 할 수 있다. 다행히 이 문제는 비교적 쉽게 진단 할 수 있다. 한 가지 방법은 네트워크의 모든 레이어에 대한 활성화/그래디언트 막대 그래프를 그리는 것이다. 직관적으로, 이상한 분포가 보이는 것은 좋은 징후가 아니다. 예를 들어 tanh 뉴런의 경우, 뉴런 활성화 함수의 분포가 모두 0으로 출력되거나 -1 또는 1로 포화 되는 것 보다 [-1,1] 전체 범위에있는 것이 바람직하다.

###### First-layer Visualizations

마지막으로 이미지 픽셀을 사용하여 작업 할 때 첫 번째 레이어 함수를 시각적으로 표시하는 것이 유용 할 수 있다.

![](http://cs231n.github.io/assets/nn3/weights.jpeg "weights" "width:280px;float:center;padding-left:10px;") ![](http://cs231n.github.io/assets/nn3/cnnweights.jpg "cnnweights" "width:320px;float:center;padding-left:10px;")

신경망의 첫 번째 레이어에 대한 가시화 된 가중치의 예. 왼쪽 : 노이즈 피쳐들이 보임. 수렴되지 않은 네트워크, 부적절하게 설정된 학습 속도, 매우 낮은 웨이트 정규화 패널티등의 문제가 있을 수 있다. 오른쪽 : 적절하게, 부드럽고, 깨끗하고 다양한 특징을 보인다. 따라서 훈련이 잘 진행되고 있음을 알 수 있다. 

##### Parameter updates

그라디언트가 역전파를 통해 계산되면 이를 사용하여 파라미터를 업데이트한다. 업데이트를 수행하는 방법은 다음과 같다.

딥 네트워크 최적화는 현재 매우 활발한 연구 분야다. 이 섹션에서는 실제로 볼 수있는 몇 가지 일반적인 방법들을 살펴보며, 업데이트에 대한 직관을 간략하게 설명한다. 하지만 여기에 대한 상세한 분석은 강의 범위를 벗어나므로 다루지 않는다. 대신 관심있는 독자를 위한 몇 가지 읽을 거리를 제공한다.

###### SGD and bells and whistles

**Vanilla update.** 가장 간단한 업데이트 방법은 그래디언트의 반대 방향을 따라 파라미터를 변경하는 것이다 (그래디언트는 증가 방향을 나타내며, 반대로 우리는 로스함수가 최소화 되기를 바라기 때문에). 파라미터의 벡터 x와 그라디언트 dx가 있다고 하면, 가장 기본적인 형태의 업데이트 방법은 다음과 같다. 

```python
# Vanilla update
x += - learning_rate * dx
```

여기서 learning_rate은 하이퍼 파라미터로 고정 된 상수다. 충분히 낮은 학습 속도로 전체 데이터 집합에 대해 평가한다면, 로스 함수에 대해 개선을 보장한다. 

**Momentum update** 는 딥 네트워크에서 수렴 속도를 향상시키는 한 방법이다. 이 업데이트는 물리적 관점에서 최적화 문제를 바라본다. 특히 로스은 언덕이 많은 지형의 고도로 해석 될 수 있다. 여기서 위치에너지 $U = mgh$이며 $U \propto h$다. 랜덤으로 매개 변수를 초기화하는 것은 특정 위치의 초기 속도를 0으로 설정하는 것과 같다. 그런 다음 최적화 과정은 파라미터 벡터(예 : 입자)를 언덕에서 움직이는 것과 같은 과정으로 볼 수 있다.
입자에 작용하는 힘은 다음과 같이 포텐셜 에너지의 와 관련이 있기 때문에($F = - \nabla U$), 입자가 받는 힘은 로스함수의 그라디언트의 반대 방향과 같다. 또한 $F=ma$이므로 (음의) 그래디언트는 입자의 가속도에 비례한다. 그라디언트가 위치를 직접 업데이트하는 위의 SGD 업데이트와 다르다. 대신 물리학 관점에서는 그라디언트는 속도를 업데이트 하며, 업데이트된 속도를 통해 위치를 업데이트한다. 

```python
# Momentum update
v = mu * v - learning_rate * dx # integrate velocity
x += v # integrate position
```

여기서  v는 0으로 초기화 된 변수이며, 추가 하이퍼 파라미터 ( mu)가 있다. 불행히도 이 변수는 최적화에서 momentum 으로 불린다. (일반적인 값은 약 0.9 임). 사실, 그 물리적 의미는 마찰 계수와 더 일치한다. 이 변수는 효과적으로 속도를 감쇠(damp)시키고 시스템의 운동 에너지를 줄인다. 만약 그렇지 않으면 입자가 언덕의 바닥에서 계속 움직일 것이다. 교차 유효성을 검사 할 때 이 매개 변수는 일반적으로 [0.5, 0.9, 0.95, 0.99]와 같은 값으로 설정된다. 학습 속도에 대한 어닐링 스케쥴(아래에서 설명 함)과 마찬가지로 최적화는 때때로 학습의 후기 단계에서 모멘텀이 증가하는 경우 약간의 이점을 얻을 수 있다. 일반적으로 약 0.5의 값으로 시작하여 여러 단계에 걸쳐 0.99 정도로 어닐링(annealing)한다. 

*모멘텀 업데이트를 통해 파라미터 벡터는 일정한 그라디언트 방향으로 속도를 업데이트 한다.*

**Nesterov Momentum** 은 최근 인기를 얻고있는 momentum 업데이트의 약간 다른 버전이다. 그것은 볼록 함수에 대해 보다 이론적 수렴 보증을 기반으로 하고 있으며, 실제로 일반 모멘텀 업데이트보다 약간 더 잘 작동한다. 

Nesterov 모멘텀의 핵심 아이디어는 현재 파라미터 벡터가 어떤 위치  x에있을 때, 미래의 대략적인 위치 x + mu * v를 "미리보고" 여기에 대한 그라디언트를 계산하는 것이다. 이 지점은 곧 업데이트할 근처의 지점이며, 따라서 이전 상태의 위치 x 대신에 x + mu * v 의 그라디언트를 계산하는 것이 좋다 .

![](http://cs231n.github.io/assets/nn3/nesterov.jpeg "nesterov" "width:280px;float:center;padding-left:10px;")

Nesterov  모멘텀. 현재 위치 (빨간색 원)에서 그라디언트를 계산하는 대신, 모멘텀에 의해 초록색 화살표 끝으로 위치가 이동 할 것이라는 것을 알고 있다. Nesterov 모멘텀에서는 이 "look-ahead"위치에서 그라데이션을 계산한다.

즉, 약간 어색한 아래와 같은 식으로 나타낸다. 
```python
x_ahead = x + mu * v
# evaluate dx_ahead (the gradient at x_ahead instead of at x)
v = mu * v - learning_rate * dx_ahead
x += v
```

그러나 실제로 사람들은 바닐라 SGD 또는 이전 모멘텀 업데이트와 비슷한  간단한 형태로 업데이트를 계산하는 것을 선호한다.  x_ahead = x + mu * v를 이용하여 x_ahead대신  x로 변수 조정을 해서 업데이트를 아래와 같이 표현할 수 있다. 

```python
v_prev = v # back this up
v = mu * v - learning_rate * dx # velocity update stays the same
x += -mu * v_prev + (1 + mu) * v # position update changes form
```

이 방정식의 출처와 Nesterov의 가속 모멘텀(NAG)의 수학적 공식을 이해하려면 아래 추가 정보를 읽어 보길 바란다. 

- [Advances in optimizing Recurrent Networks](http://arxiv.org/pdf/1212.0901v2.pdf) by Yoshua Bengio, Section 3.5.
- [Ilya Sutskever’s thesis](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf) (pdf) contains a longer exposition of the topic in section 7.2

###### Annealing the learning rate

딥 네트워크를 훈련 할 때, 일반적으로 시간에 따라 학습 속도를 조정하는 것은 도움이 된다. 큰 학습 속도에서 시스템은 너무 많은 운동 에너지를 포함하며, 파라미터 벡터는 무질서하게 바운스되며 로스 함수를 업데이트 하므로, 로스 함수의 더 깊고 좁은 부분에 수렴 할 수 없다는 점을 명심해야한다. 학습 속도를 언제 떨어 뜨릴지는 아는 것은 까다롭다. 천천히 감쇠 시키면 오랜 시간 동안 거의 개선되지 않으며, 초기 혼돈된 상태에서 주위를 돌아 다니는 계산을 하느라 낭비하게된다. 그러나 너무 빨리 감소시키면 시스템이 너무 빨리 냉각되어 최상의 위치에 도달 할 수 없게된다. 학습 속도 감소를 구현하는 세 가지 일반적인 유형은 아래와 같다. 

- Step decay: 몇 에포크마다 몇 가지 요소로 학습 속도를 줄인다. 일반적으로 매 5 epochs의 절반으로, 또는 20 epoch마다 0.1씩 학습 속도를 줄일 수 있을 것이다. 이 값은 문제의 유형과 모델에 크게 의존한다. 실제로 사용되는 경험적 방법 중 하나는 고정 학습 속도로 학습하는 동안 유효성 검사 결과를 보고 유효성 검사 오류가 개선되지 않을 때마다 학습속도를 일정하게 (예 : 0.5) 줄이는 것이다. 
- Exponential decay. 다음과 같은 식을 기반으로 한다. $\alpha = \alpha_0 e^{-k t}$ 여기서 $\alpha_0$와 $k$는 하이퍼 파라미터며, $t$는 반복횟수(또는 에포크)이다. 
- 1/t decay 식은 다음과 같으며 $\alpha = \alpha_0 / (1 + k t )$, 여기서 $\alpha_0$와 $k$는 하이퍼 파라미터, $t$는 반복횟수(또는 에포크)이다. 

실제로, step decay 방법의 하이퍼 파라미터 (감소 비율 및 에포크 단위의 스텝 타이밍)이  하이퍼 파라미터 $k$ 보다 해석하기 쉽기 때문에 약간 더 선호 된다. 마지막으로, 계산량을 감당할 수 있다면, 느리게 감소시키며 충분히 오랜 시간 동안 학습하길 권한다. 

###### Second order methods

딥러닝에서 최적화를 위한 다른 방법은 다음과 같은 [Newton 방법](http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) 기반 업데이트를 반복하는 것이다. 
$$x \leftarrow x - [H f(x)]^{-1} \nabla f(x)$$
여기서 $H f(x)$는 함수의 이차미분에 대한 square matrix 이며, $\nabla f(x)$는 Gradient Descent에서 봤듯이 그라디언트 벡터를 뜻한다. 

직관적으로 Hessian은 로스 함수의 지역적(Local) 곡률을 나타내므로 효율적인 업데이트를 수행 할 수 있다. 특히, 역 헤시안(Hessian)을 곱해 최적화를 하는데, 이때 곡률이 작은 경우 더 큰 스텝을 가지며, 반대로 가파른 곡률의 경우 보다 짧은 스텝을 취한다. 결정적으로, 업데이트 공식에 학습 속도에 대한 하이퍼 파라미터가 없다는 점을 유의하라. 이는 앞서 본 1 차 미분 기반 방법보다 큰 이점으로 작용한다. 

그러나 명시적인 형태로 Hessian을 계산(및 반전)하는 것은 메모리 공간과 계산 시간 모두 매우 비용이 많이 드는 프로세스이기 때문에, 위의 업데이트는 대부분의 딥러닝 애플리케이션에서 실용적이지 않다. 예를 들어, 100 만 개 매개 변수가있는 신경망은 대략 3725기가 바이트의 RAM을 차지하는 크기 (1,000,000 x 1,000,000) 의 Hessian 행렬을 가진다. 따라서, 역 헤시안을 근사화하는 다양한 quasi-Newton 방법이 개발되었다. 이 중에서 가장 많이 사용되는 것은 [L-BFGS](http://en.wikipedia.org/wiki/Limited-memory_BFGS)다. L-BFGS는 시간에 따른 그라디언트를 사용하여 암시적으로 근사값을 만든다.(즉, 전체 행렬은 계산되지 않는다).

그러나 위와 같은 방법으로 메모리 문제를 제거한 후에도 L-BFGS를 바로 사용 할 수 없는 이유는 수백만 가지 샘플을 포함하는 전체 학습 데이터 세트를 계산해야 하기 때문이다. 미니 배치 SGD와 달리, L-BFGS를 미니 배치에 적용하는 것은 더 까다로우며, 아직 연구 되고 있다.

**In practice,** 대규모 딥러닝 및 Convolutional Neural Networks에 L-BFGS 또는 이와 유사한 2차 미분기반의 업데이트를 적용하는 것은 일반적이지 않다. 대신 (Nesterov’s) 모멘텀을 기반으로 한, 다양한 SGD 기반의 방법들이 더 간단하고 쉽게 확장 할 수 있으므로 표준적으로 사용된다. 

추가 참조 :

- [Large Scale Distributed Deep Networks](http://research.google.com/archive/large_deep_networks_nips2012.html)는 Google Brain 팀의 보고서로, 대규모 분산 최적화에서 L-BFGS와 SGD기반 방법들 비교 한다.
- [SFO 알고리즘](http://arxiv.org/abs/1311.2115)은 SGD의 장점과 L-BFGS의 장점의 결합을 시도한다. 

###### Per-parameter adaptive learning rate methods

지금까지 논의한 이전의 모든 방법은 전역적(global)으로 모든 파라미터에 대해 균등하게 학습 속도를 조정했다. 학습 속도를 조정하는 것은 비용이 많이 드는 프로세스이므로 학습 속도를 가변적(adaptive)으로 조정하고, 심지어 각 파라미터 별로 조정하는 방법들이 나오고 있다. 이 방법들 중 대부분 여전히 다른 하이퍼 파라미터 설정이 필요 할지 모른다. 그러나 중요한 점은 단순 학습 속도보다 더 넓은 범위의 하이퍼 파라미터 값들에 대해 잘 동작한다는 것이다. 이 섹션에서는 실제로 사용되는 일반적인 가변 방법을 살펴본다. 

**Adagrad.** 는 [Duchi et al.](http://jmlr.org/papers/v12/duchi11a.html) 제안한 가변 학습 속도 방법이다. 

```python
# Assume the gradient dx and parameter vector x
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
```

변수 cache의 크기는 그라디언트의 크기와 같으며, 각 파라미터 당 제곱 된 그라디언트의 합을 계속 반영한다. 그런 다음 파라미터 업데이트에서 정규화하는 데 사용된다. 높은 그라디언트가 반영 될 웨이트의 경우 실제 반영되는 학습 속도는 감소되며, 작은 업데이트를 받는 웨이트의 경우 상대적으로 학습 속도를 증가시키는 효과를 준다. 재미있게도, 위 식에서 제곱근 연산은 매우 중요하며 이것이 없는 경우 훨씬 더 나쁜 성능을 보인다. 스무딩 항eps(대개 1e-4에서 1e-8의 어딘가에 설정 됨)는 0으로 나뉘지지 않게 만든다. Adagrad의 단점은 Deep Learning에서 cache가 꾸준히 증가하므로 업데이트 값이 단조 감소하여, 학습이 너무 일찍 종료 된다는 점이다. 

**RMSprop.** RMSprop은 매우 효과적인 가변 학습 속도 방법이다. RMSProp 업데이트는 단조 감소 학습 속도시 학습 빨리 수렴하지 않게 하기 위해 Adagrad 메서드를 간단히 수정했다. 특히, 제곱 된 그라디언트의 합 대신 다음과 같은 식을 사용한다. 

```python
cache = decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
```

여기서 decay_rate 하이퍼 매개 변수이며 일반으로 [0.9, 0.99, 0.999]를 사용한다. 위식은 Adagrad처럼 x+=업데이트가 이루어 지지만, cache변수가 "leaky(새는)"것을 나타낸다.  따라서 RMSProp은 그래디언트의 크기 따라 각 가중치의 학습 속도를 조정해 이퀄라이제이션 효과는 주지만, Adagrad와는 달리 업데이트가 단조 감소하지 않는다. 

**Adam.** [Adam](http://arxiv.org/abs/1412.6980) 은 최근에 제안 된 업데이트로 RMSProp과 비슷한 느낌을 준다. 우선 간단한 버전의 업데이트 식는 다음과 같다.

```python
m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)
```

(아마 노이즈가 많은) 그라디언트 벡터 대신 그라디언트의 "부드러운" 버전인 m 이 사용 된다는 점을 제외한다면, RMSProp 업데이트와 정확하게 일치 한다. 논문에서 권장값은 eps = 1e-8, beta1 = 0.9, beta2 = 0.999이다. 실제 아담은 기본 알고리즘으로 권장되며 종종 RMSProp보다 약간 더 잘 작동한다. 하지만 때로는 SGD + Nesterov Momentum를 사용해 파라미터 업데이트를 수행 해 보는 것이 좋을 때도 있다. 완전한 Adam 업데이트에는 바이어스 보정 메커니즘이 포함되어 있습니다.이 메커니즘은 처음 몇 타임 스텝에서 벡터 m,v가 초기화되어 0으로 바이어스되는 것을 보완한다. 바이어스 보정 매커니즘 업데이트는 다음과 같다. :

```python
# t is your iteration counter going from 1 to infinity
m = beta1*m + (1-beta1)*dx
mt = m / (1-beta1**t)
v = beta2*v + (1-beta2)*(dx**2)
vt = v / (1-beta2**t)
x += - learning_rate * mt / (np.sqrt(vt) + eps)
```

업데이트는 이제 반복횟수와 다른 파라미터를 변수로 가진다.  세부 사항을 위해 논문을 보거나, 코스 슬라이드를 참조하라.
Additional References: 

- [Unit Tests for Stochastic Optimization](http://arxiv.org/abs/1312.6055)는 stochastic optimization을 위한 표준 벤치마크를 제안한다.

![](http://cs231n.github.io/assets/nn3/opt2.gif "opt2" "width:300px;float:center;padding-left:10px;") ![](http://cs231n.github.io/assets/nn3/opt1.gif "opt1" "width:300px;float:center;padding-left:10px;")

학습 과정의 역학을 직관적으로 보여주는 애니메이션. 왼쪽 : 로스 표면 및 다양한 최적화 알고리즘의 시간에 따른 최적화 과정 컨투어. momentum 기반 방법에서 보이는 "오버 슈팅 (overshooting)"에 주목하라. 오른쪽: saddle point에 대한 최적화 과정 시각화. SGD는 대칭을 깨기위해 아주 힘든 시간을 보내고 있으며 여전히 맨 위에 붙어 있다. 반대로 RMSprop과 같은 알고리즘은 saddle 방향에 대해 매우 낮은 그라디언트를 가지지만, RMSprop 업데이트의 분모항에의해 이 방향에 대한 실제 학습 속도가 효과적으로 향상되어 RMSProp이 진행된다. 이미지 credit: Alec Radford .

##### Hyperparameter optimization


앞에서 살펴 보았듯이 신경망 학습 과정에는 많은 하이퍼 파라미터 설정이 포함될 수 있다. 신경망의 맥락에서 가장 일반적인 하이퍼 파라미터는 다음과 같습니다.

- 초기 학습 속도(learning rate)
- 학습 속도 감쇠 스케줄 (감쇄 상수 등)
- 정규화 세기 (L2 패널티, 드롭 아웃 세기)

그러나 앞에서 보았듯이, 예를 들어 파라미터 별 가변 학습 방법, 모멘텀 및 스케쥴 설정 등과 같이 상대적으로 덜 민감한 하이퍼 파라미터가 많이 있다. 이 섹션에서는 하이퍼 파라미터 설정을 위한 몇 가지 팁과 트릭을 설명한다. 

**Implementation.** 딥 뉴럴 네트워크는 일반적으로 훈련에 긴 시간이 필요하므로 하이퍼 파라미터를 찾는데 며칠 / 몇주가 걸릴 수 있다. 코드 베이스 디자인에 영향을 미치기 때문에 이를 주의해야한다. 하나의 특정 디자인에서 워커를 주고, 임의의 하이퍼 파라미터를 지속적으로 샘플링하고 최적화를 수행한다. 학습을 하는 동안 워커는 모든 에포크에 대한 validation performance를 업데이트 하고, 모델 체크포인트를 저장한다.  진행 상황을 체크하고 정렬하기 쉽도록 validation performance를 파일 이름에 직접 포함시키는 것이 유용하다. 그런 다음 마스터라고 불리는 두 번째 프로그램을 컴퓨터 클러스터에서 워커를 시작시키거나 종료시키며, 추가로 워커가 작성한 체크포인트을 검사하고 학습 통계 등을 그려볼수 있다. 

**Prefer one validation fold to cross-validation.** 코드 단의 단순화를 위해 대부분의 경우, 여러 개의 폴드가 아닌 적절한 크기의 단일 벨리데이션 세트를 사용한다. 파라미터를 "cross-validation"한다고 말하지만, 대부분의 경우 ​​단일 validation 세트만 사용했다고 가정된다. 

**Hyperparameter ranges.** 로그 스케일에서 하이퍼 파라미터를 탐색하라. 예를 들어 학습 속도의 일반적인 샘플링은 다음과 같다.learning_rate = 10 ** uniform(-6, 1). 즉, 균일한 분포에서 난수를 생성하지만, 10의 거듭 제곱으로 나눈다. 동일한 전략은 정규화 강도를 찾는데도 사용된다. 직관적으로, 이러한 전략을 사용하는 이유는, 학습 속도와 정규화 강도가 훈련 역학에 대한 곱셈 효과를 갖기 때문이다. 예를 들어, 파라미터 업데이트에서 학습 속도에 고정값 0.01을 추가하는 것은 학습 속도가 0.001 일 때는 동적 효과에 큰 영향을 미치지만, 학습 속도가 10인 경우 거의 효과가 없다. 따라서 학습 속도를 범위를 고려할 때 초기값에서 특정 값을 곱하거나 나누는 것이, 특정 값을 더하거나 빼는 것보다 훨씬 자연스럽다. 일부 파라미터는 원래 스케일을 탐색 범위로 가진다. (예 :dropout = uniform(0,1)).

**Prefer random search to grid search.** Bergstra와 Bengio가 [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) 에서 논한 것처럼 , "격자 구조보다 무작위 선택이 매개 변수 최적화에 더 효율적"이다. 알고보면, 구현하기도 더 쉽다.

![](http://cs231n.github.io/assets/nn3/gridsearchbad.jpeg "gridsearchbad" "width:500px;float:center;padding-left:10px;")

Bergstra와 Bengio의  Random Search for Hyper-Parameter Optimization의 핵심, 종종 특정 하이퍼 파라미터가 다른 하이퍼 파라미터보다 훨씬 중요한 경우가 있다. (예 : 위쪽의 하이퍼 매개 변수 대 왼쪽의 하이퍼 파라미터). 그리드 검색이 아닌 무작위 검색을 수행하면 중요한 정보를보다 정확하게 찾을 수 있다. 그리드의 경우 3개 점에대해 탐색이 이뤄지지만, 랜덤의 경우 9개 점에서 탐색이 이뤄짐. 

**Careful with best values on border.** 때로는 적절하지 않은 범위에서 하이퍼파라미터(예 : 학습 속도)를 검색하는 경우가 발생할 수 있다. 예를 들어, 다음과 같은 범위를 사용한다고 가정 해보자. learning_rate = 10 ** uniform(-6, 1). 벨리데이션 결과를 보고 최종 학습 속도가 이 구간의 가장자리에 있는지 다시 한 번 확인하는 것이 중요하다. 그렇다면, 범위 밖에 있는 최적의 하이퍼 파라미터 설정이 누락 될 수 있다.

**Stage your search from coarse to fine.** 실제로는 대략적인 범위 (예 : 10 ** [-6, 1])에서 먼저 검색 한 다음 최상의 결과가 나타나는 위치에 따라 범위를 좁히는 것이 좋다. 또한 많은 초기 값 설정에서 모델을 전혀 학습하지 못하거나 무한대 값의 코스트로 즉시 발산 할 수 있기 때문에 1 에포크 또는 그 이하의 시간 동안 만 학습하면서 하이퍼 파라미터의 초기 값에 대한 대략적인 검색을 수행하는 것이 좋다. 그리고 5 에포크 동안 파라미터 탐색을 수행 하며, 마지막으로 더 많은 에포크 동안 파라미터 탐색을 수행한다.


**Bayesian Hyperparameter Optimization** 는 하이퍼 매개변수를 보다 효율적으로 탐색하려고하는 알고리즘에 대한 연구 영역이다. 핵심 아이디어는 다른 하이퍼 매개 변수에서 성능을 쿼리 할 때 exploration - exploitation 트레이드오프를 적절하게 밸런싱하는 것이다. 여러 라이브러리가 개발되었으며,  Spearmint,  SMAC,  Hyperopt이 유명하다. 보다 깊은 논의는 다음을 참고하라. [here](http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html).

##### Evaluation

###### Model Ensembles

실제로, 신경망의 성능을 조금 향상시키기 위해 할 수 있는 접근법은 여러 모델을 독립적으로 학습시키고, 테스트 에서 모델들의 평균 예측값을 사용한다. 앙상블의 모델 수가 증가함에 따라 성능은 일반적으로 단조 향상된다. 더욱이, 앙상블에서 모델의 다양성을 키우면 더욱 개선할 수 있다. 앙상블을 형성하는 몇 가지 방법을 소개한다. 

- 같은 모델, 다른 초기화 . 벨리데이션을 통해 최상의 하이퍼 파라미터를 찾은 다음, 최적의 하이퍼 파라미터를 사용하지만 무작위 초기화가 된 다른 여러 모델을 학습하라. 이 방법에서 위험성은 오직 초기화에만 있다.
- cross-validation을 통한 상위 모델. cross-validation을 사용하여 최상의 하이퍼 파라미터를 결정한 다음 상위 몇 개의 모델 (예 : 10)을 선택하여 앙상블을 만든다. 이것은 앙상블의 다양성을 향상 시키지만 최선이 아닌 모델을 포함 할 위험이 있다. 실제로 이것은 교차 검증 후에 모델을 추가로 재학습 시킬 필요가 없으므로 수행하기 더 쉽다.
- 단일 모델의 다양한 체크포인트 . 학습에 매우 많은 시간이 걸리는 경우, 시간이 지남에 따라 단일 네트워크의 다른 체크 포인트를 취하고 (예 : 각 에포크 이후) 앙상블을 형성하는 사용하는 것은 때로는 성공적인 성능 향상을 주기도 한다. 분명히, 이 방법은 위의 방법들 보다 다양성이 부족하지만, 실제로 잘 동작하는 경우도 있다. 이 방법의 장점은 계산비용이 매우 저렴하다는 것이다.
- 학습 중 매개 변수의 평균. 이 방법은 이전에 학습한 웨이트 파라미터를 복사하여 메모리에 저장하는 것으로, 거의 항상 추가적인 성능 향상을 가져오며, 매우 싼 계산 비용을 가진다. 저장한 웨이트를 불러옴으로, 전과정을 학습하지 않고 마지막 몇 에포크만 학습한 다음 여러 네트워크 모델을 평균화한다. "평활화 된"버전의 웨이트는 보통 더 나은 벨리데이션 결과를 얻는다. 

모델 앙상블의 한 가지 단점은 테스트 샘플들을 평가하는 데 오랜 시간이 걸린다는 것이다. 여기에 관심이 있다면, Geoff Hinton의 “[Dark Knowledge](https://www.youtube.com/watch?v=EK61htlw8hY)”를 참조하길 바란다. 여기에는 수정 된 목적함수에 ensemble log likelihoods를 통합하여 앙상블을 단일 모델로 "증류(distill)"하는 방법이 나와있다.

##### Summary


뉴럴 네트워크를 학습 시키려면 :

- 작은 데이터 배치로 그라디언트 검사를 수행하고, 오류를 확인하라. 
- sanity 검사로 초기 로스값이 합리적인지, 일부 데이터만 사용하여 학습했을때 100 % 정확도를 달성하는지 확인하라. 
- 학습 과정에서 로스값, 학습/검증 정확도를 모니터링하고, 가능하다면 파라미터 값과 관련된 업데이트의 크기(~ 1e-3 정도가 적당함)을 확인하라. ConvNets의 경우 첫 레이어의 필터 모양을 확인하라. 
- 파라미터 업데이트에는 SGD + Nesterov Momentum 또는 Adam을 사용하기를 권장한다. 
- 학습을 진행하는 동안 학습 속도를 감소 시켜라. 예를 들어 일정 에포크 이후 또는 벨리데이션 검사 시 정확도가 가장 높을 때마다, 학습 속도를 절반으로 줄인다. 
- 무작위 검색(그리드 검색이 아님)으로 좋은 하이퍼 파라미터를 찾아라. 초반엔 대략적인 범위에서 탐색하며, 많은 에포크가 지난후에는 세밀한 범위에서 탐색하라. 
- 모델 앙상블을 통해 성능을 추가로 향상시킬 수 있다. 

##### Additional References

- [SGD tips and tricks](http://research.microsoft.com/pubs/192769/tricks-2012.pdf) from Leon Bottou
- [Efficient BackProp (pdf)](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) from Yann LeCun
- [Practical Recommendations for Gradient-Based Training of Deep Architectures](http://arxiv.org/pdf/1206.5533v2.pdf) from Yoshua Bengio








