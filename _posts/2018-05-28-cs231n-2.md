---
title: cs231n 번역 2 Linear Classification
category: cs231n
excerpt: |
 지난 섹션에서 이미지에 단일 레이블을 할당하는 이미지 분류 문제를 소개했다. 그리고 k-Nearest Neighbor (kNN) Classifier(분류기)도 다뤘다. 분류기는 입력 이미지를 레이블링 된 트레이닝 세트의 이미지와 비교함으로써 적절한 레이블을 붙인다. 앞서 보았듯이 kNN에는 여러 가지 단점이 있다.  


feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=765"
image: "https://picsum.photos/2560/600/?image=765"
comment: true
---


#### Linear Classification

지난 섹션에서 이미지에 단일 레이블을 할당하는 이미지 분류 문제를 소개했다. 그리고 k-Nearest Neighbor (kNN) Classifier(분류기)도 다뤘다. 분류기는 입력 이미지를 레이블링 된 트레이닝 세트의 이미지와 비교함으로써 적절한 레이블을 붙인다. 앞서 보았듯이 kNN에는 여러 가지 단점이 있다.

- 분류기는 테스트 데이터와 비교할 수 있도록 모든 트레이닝 데이터를 저장해야한다. 데이터 세트의 크기는 기가 바이트 이상이 될 수 있으므로 메모리 활용에 매우 비효율적이다. 
- 테스트 이미지를 분류하는 것은 모든 트레이닝 이미지와의 비교가 필요하기 때문에 비용이 많이 든다.

**개요.** 이제 이미지 분류에 대한 보다 나은 접근법에 대해 다루며, 최종적으로 Neural Networks과 Convolutional Neural Networks으로 확장할 것이다. 이 접근법은 두가지 주요 구성요소가 있다. 구성요소로는 데이터를 클래스 score에 매핑 하는 **score 함수**와 예측 score와 ground truth 레이블 간의 일치를 나타내는 **loss 함수**가 있다.  그리고 이 loss 함수를 최소화하는 score 함수의 파라미터에 대한 최적화 문제로 바꾼다.

##### Parameterized mapping from images to label scores


이 접근법에서 첫 번째로 할 일은 이미지의 픽셀 값을 각 클래스의 신뢰도 점수에 매핑하는 스코어 함수를 정의하는 것이다. 우리는 구체적인 예를 들어 접근법을 살펴보자. 이전처럼 이미지의 트레이닝 데이터 세트 $x_i \in R^D$ 가 있다고 가정해보자, 여기서 각 이미지에는 레이블 $y_i$가 할당되어 있다. 여기서 $i=1 \dots N$ 이며 $y_i \in { 1 \dots K }$와 같다. 이는 데이터가 $D$차원의 $N$개 샘플과 $K$가지 카테고리로 이뤄진것을 의미한다.  예를 들어, CIFAR-10은 $D = 32 * 32 * 3 = 3072$픽셀의, $K= 10$개의 클래스(개, 고양이, 자동차 등)가 할당된 $N = 50,000$ 이미지의 트레이닝 세트로 구성되어 있다. 이제 이미지 픽셀을 클래스 점수에 매핑하는 스코어 함수 $f: R^D \mapsto R^K$를 정의해보자.

**선형 분류자.** 가장 단순한 맴핑 함수인 선형 매핑으로부터 출발해보자.

$$f(x_i, W, b) =  W x_i + b$$

위 식에서 이미지$x_i$의 전체 픽셀은 하나의 열[D x 1]에 펼처져(flatten) 있다. 위 함수의 파라미터로는 [K x D] 크기를 가지는 행렬 $W$와 [K x 1]크기의 백터 $b$가 있다. CIFAR-10에서 $x_i$는 [3072 x 1]크기의 배열로 $i$번째 이미지의 모든 픽셀을 나타내며, $W$는 [10 x 3072]의 크기를, $b$는 [10 x 1]의 크기를 가진다. 따라서 이미지를 나타내는 [3072 x 1]크기의 숫자 배열이 함수의 입력이되고, 출력으로 각 클래스 스코어를 나타내는 [10 x1] 크기의 배열이 된다.  파라미터 W는 weight라 불리며, b는 입력과 무관하게 출력에 영향을 주므로 bias라 불린다. 하지만 weight와 파라미터라는 용어를 서로 바꿔서 말하기도 한다. 

주의사항

- $W$의 행은 각각 클래스에 대한 분류기과 같으며, 매트릭스 곱 $Wx_i$에 의해 각 분류기에 대한 평가(evaluating)작업을 효율적으로 수행한다.
- 또한 입력 데이터($x_i$, $y_i$)는 고정이지만, 파라미터 $W$와 $b$는 조정 할 수 있다. 우리의 목표는 계산 된 스코어가 전체 트레이닝 세트의 레이블과 일치하도록하는 것입니다. 이것이 어떻게 수행되는지는 다음에 자세히 설명 하겠지만 직관적으로 올바른 클래스로 평가된 경우 잘못된 클래스 보다 높은 점수를 얻길 원한다.
- 이 접근법의 장점은 트레이닝 데이터가 파라미터 W, b 를 학습하는데만 사용되며, 학습이 완료되면 전체 트레이닝 세트를 삭제하고 학습 된 파라미터 만으로 테스트 샘플을 평가 할 수 있다는 것이다. 이는 새로운 테스트 이미지가 파라미터와의 매트릭스 연산을 통해 간단하게 스코어로 계산되며, 이 스코어에 따라 특정 레이블로 분류되기 때문이다.
- 마지막으로, 매트릭스 곱과 합으로 테스트 이미지를 분류하는 것은 테스트 이미지를 모든 트레이닝 이미지와 비교하는 것보다 훨씬 빠른 계산 속도를 보장한다. 

*Foreshadowing : Convolutional Neural Networks는 이미지 픽셀을 위에 표시된 것과 같은 스코어 함수로 매핑하지만 , 더 복잡한 스코어 함수와 더 많은 매개 변수로 구성되어 있다.* 

##### Interpreting a linear classifier

선형 분류기(linear calssifier)에서 클래스의 점수는 이미지의 모든 색상 채널(R, G, B 3개)에 대한 모든 픽셀 값의 가중치 합(weighted sum)로 계산된다. 이 가중치를 어떤 값으로 설정했는지에 따라 이미지의 특정 위치에서 특정 색상에 대한 선호도(가중치의 부호로 표현)가 결정된다. 예를 들어, 이미지의 외곽에 파란색이 많으면 (물을 나타낼 수 있음) 'ship' 클래스일 더 가능성이 높다고 볼 수 있습니다. "ship"분류기는 파란색 채널 대해 양의 가중치(파랑색 픽셀에 대한 스코어 증가)와 적색/녹색 채널에 대한 음수 가중치 (적색/녹색에 대한 스코어 감소)를 가질 것으로 예상할 수 있다. 

![](http://cs231n.github.io/assets/imagemap.jpg "imagemap" "width:600px;float:center;padding-left:10px;")

이미지를 클래스 스코어에 매핑하는 예. 간략화를 위해 이미지는 색상채널 없이 4픽셀로 구성되어 있고, 3개의 클래스 (빨간색 (고양이), 녹색 (개), 파란색 (선박) 클래스)에 대한 분류 만 수행한다.  (주의: 여기의 색상은 단순히 3 개의 클래스를 나타내며 RGB 채널과 관련이 없다.) 이미지 픽셀을 열로 늘리고 행렬 곱셈을 수행하여 각 클래스의 스코어를 얻는다. 위 예에서 가중치 행렬 W는 제대로 동작하지 않는다. 가중치(W)는 우리의 고양이 이미지에 매우 낮은 고양이 점수를 할당하여,  특히 여기서 입력된 고양이 이미지를 강아지로 판별할 확률이 매우 높다. 

**Analogy of images as high-dimensional points.** 이미지가 고차원의 열 벡터로 표현되므로 각 이미지를 이 공간에서 점으로 나타낼수 있다 (예 : CIFAR-10의 각 이미지는 3072(32x32x3)차원의 픽셀 공간 위에 있는 점이다). 마찬가지로 전체 데이터 세트 역시 (레이블이 지정된) 점의 집합으로 볼 수 있다. 

각 클래스의 스코어를 모든 이미지 픽셀의 가중치 행렬로 정의 했으므로 각 클래스 점수는이 공간에 대한 선형 함수와 같다. 3072 차원의 공간을 시각화 할 수는 없지만, 전체 차원을 단지 2 차원으로 줄인 것을 상상한다면 분류 기의 역할을 시각화 할 수 있다.

![](http://cs231n.github.io/assets/pixelspace.jpeg "pixelspace" "width:600px;float:center;padding-left:10px;")

각 이미지는 이미지 공간의 한 점을 표현하며, 선은 세 개의 분류자를 보여준다. 자동차 분류(빨간색)의 예를 사용하면 빨간색 선은 자동차 클래스의 점수가 0 인 공간의 모든 지점을 표시한다. 빨간색 화살표는 증가 방향을 나타내므로 빨간색 선 오른쪽의 모든 점은 양수(선형 증가) 점수를 가지며 왼쪽 모든 점은 음수(및 선형 감소) 점을 갖습니다. 따라서 빨간선 오른쪽은 자동차 스코어 값이 크며, 왼쪽은 자동차 스코어 값이 음을 가질 것이다. 

위에서 보았듯이 $W$의 각 행은 클래스 중 하나에 대한 분류기와 같다. 이것의 기하학적 의미는 행을 구성하는 weight 중 하나를 변경하면 분류기를 표현하는 선이 회전한다는 것이다. 반면 바이어스를 변경하는 경우 선은 상하좌우로 이동한다. 바이어스가 없는 경우 $x_i = 0$ 일 때 모든 스코어는 0이며, 따라서 모든 선은 원점을 지난다. 

**Interpretation of linear classifiers as template matching.** 가중치 행렬 $W$의 각 행은 매칭되는 각 클래스에 대한 템플릿(프로토 타입 )이라고 해석 할 수 있다. 즉 입력이미지와 아래와 같은 각 클래스에 대한 템플릿 이미지와의 내적을 통한 비교에 기반하여 각 클래스의 스코어를 구할 수 있다. 템플릿 매칭을 하는 과정을 통해 템플릿 이미지가 학습 된다. 이는 유사도 측정에 L1, L2 distance 대신 내적으로 사용한다는 것만 제외하면, 기존의 Nearest Neighbor 분류기와 같은 방식으로 동작한다고 볼 수 있다. 하지만 수천개의 트레이닝 이미지와 비교하는 것이 아니라, 각 클래스당 1개씩있는 학습된 템플릿 이미지와 비교한다. 따라서 기존 방법에 비해 매우 효율적이다.

![](http://cs231n.github.io/assets/templates.jpg "templates" "width:600px;float:center;padding-left:10px;")

Skipping ahead a bit : CIFAR-10 학습을 마친 가중치 행열의 예. 예를 들어, Ship 템플릿에는 파란색 픽셀이 많이 포함되어 있다. 따라서 이 템플릿은 바다에 있는 선박 이미지와 내적 했을 때  높은 스코어가 부여된다. 

Horse 템플릿에는 두 개의 말이 들어있는 것처럼 보인다. 데이터 세트에는 왼쪽을 보고 있는 말의 이미지와 오른쪽보고 있는 말의 이미지 둘 다 있기 때문이다. 선형 분류기는 말의 이 두 가지 모드를 하나의 템플릿에 병합(merge)한다. 비슷하게, car 분류기는 여러 자동차 이미지의 모든 면과 색상을 단일 템플릿 병합 한 것으로 보인다. 특히, 이 템플릿은 빨간색이 두드러 지는 것으로 봐서 CIFAR-10 데이터 세트에 빨간색 자동차가 다른 색상보다 많다는 것을  유추 할 수 있다. 따라서 선형 분류기의 경우 다른 색상의 차에 대해서는 잘 분류 하지 못한다. 하지만, 나중에 배울 신경망(neural network)을 사용하면 이러한 경우에도 잘 분류 할 수 있다. 신경망의 히든(hidden) 레이어에서 특정 자동차 유형 (예 : 녹색 차가 왼쪽을 향하고, 파란색 자동차가 앞을 향하고 있음)을 감지 할 수 있게 뉴런을 학습 할 수 있을 것이며, 다음 층의 뉴런에서 가중치 합계를 통해 이들을 결합해 보다 정확한 자동차 클래스 스코어를 얻을 수 있을 것이다. 

**Bias trick.** 진행하기 앞서, 두 개의 매개 변수 $W, b$를 단순화 하는 방법에 대해 알아보자. 스코어 함수가 아래와 같다는 것을 다시 떠올려 본다. 

$$f(x_i, W, b) =  W x_i + b$$

분리 된 두 파라미터를 모두 다루는 것은 번거러운 일이다. 이를 피하기 위한 일반적인 방법은 두 매개 변수를 하나의 행렬로 합한 다음, 벡터 $x_i$를 1만큼 확장한(bias dimension) 다음 상수 "1"을 할당하는 것이다. 이러한 차원 확장을 통해 아래와 같은 단일 행렬 곱으로 스코어 함수를 단순화 할 수 있다.   

$$f(x_i, W) =  W x_i$$

CIFAR-10에서 $x_i$는 이제 [3072x1] 대신 [3073x1]의 크기(마지막 index의 값은 1)를 가지며, $W$는 [10 x 3072] 가 아닌 [10 x 3073]의 크기를 가진다. 여기서 추가된 열의 값은 bias와 같다. 아래 그림을 통해 다시 이해 해 보자. 

![](http://cs231n.github.io/assets/wb.jpeg "wb" "width:600px;float:center;padding-left:10px;")

바이어스 트릭의 그림. 행렬 곱셈을 수행 한 다음 바이어스 벡터를 추가하는 것(왼쪽 그림)은, 모든 입력 벡터에 상수 1을 갖는 바이어스 차원(노란색)을 추가하고 가중치 행렬을 바이어스 값으로 1열 확장하는 것(오른쪽 그림)과 같다. 그러므로 모든 벡터의 차원을 늘려 데이터를 전처리한다면, 가중치와 바이어스 두 파라미터 대신 단일 가중치 행렬만 학습 시킬 수 있다. 

**이미지 데이터 전처리.** 위의 예제에서 입력 이미지로 Raw 픽셀 값([0 ... 255]의 범위)을 사용했다. 머신러닝 학습에서는 입력 피쳐(features)에 대한 정규화를 항상 수행하는 것이 일반적이다. 이미지의 경우 모든 픽셀 값은 피쳐로 간주 된다. 특히 모든 피쳐에 대해 평균값을 빼서 데이터를 중앙으로 정렬 하는 것이 중요하다. 이미지의 경우 이것은 평균 이미지 계산에 해당딘다. 모든 이미지에서 이미지의 평균값을 빼서 픽셀의 범위가 약 [-127 ... 127]이 되게 한다. 더 일반적인 전처리는 각 입력 피처의 값이 [-1, 1]의 범위가되도록 각 입력 피처의 크기를 조정하는 것이다. 둘 중 제로 평균 센터링이 더 중요하지만, 이것에 대해 gradient descent의 동작방식(dynamics)을 배운 다음 그 이유에 대해 이해 할 수 있다. 

##### Loss function

이전 섹션에서 입력 이미지의 픽셀 값과 파라미터 $W$를 사용하여 각 클래스 스코어를 구하는 스코어 함수를 정의했다. 이 함수에서 입력 데이터($x_i$, $y_i$)는 고정되어 있으며, 오직 가중치($W$)를 조정하여 트레이닝 데이터의 ground truth레이블과 일치하는 클래스 스코어가 되도록 설정해야 한다. 
예를들어 위에서 다룬 cat 예제 이미지와 "cat", "dog"및 "ship"클래스에 대한 스코어를 보면, 여기서 가중치(Weight) 행렬의 값은 좋지 않다는 것을 알 수 있다. 입력 된 고양이 이미지에 대한 cat 스코어는 다른 클래스 (dog: 437.9, ship: 61.95)에 비해 매우 낮게 (-96.8) 나왔다. 우리는 **로스(Loss, 손실)함수** (또는 **비용(cost function) 함수**, **목적(objective) 함수)**를 통해 이러한 결과에 대한 결과와 같은 결과로 불일치 정도(unhappiness)를 측정하려고한다. 직관적으로, 트레이닝 데이터를 분류하는 성능이 낮을 경우 로스 값이 높으며, 잘 수행하는 경우 낮은 값을 가진다. 

###### Multiclass Support Vector Machine loss

로스 함수 정의하는 몇 가지 방법이 있다. 가장 먼저 Multiclass Support Vector Machine (SVM) Loss라는 일반적으로 쓰이는 로스함수에 대해 알아 보자.  SVM 로스는 고정 된 마진($\Delta$)을 기반으로 각 이미지에 대한 올바른 클래스가 잘못된 클래스보다 높은 점수를 갖길 원한다. 위와 같이 로스 함수를 의인화하여 생각하는 것은 이해하는데 도움이 된다. 

더 자세히 알아보자.  이미지 픽셀 $x_i$와 이미지에 대한 정확한 클래스 레이블 인덱스 $y_i$로 되어 있는 i번째 샘플이 있다고 생각해보자. 스코어 함수  $f(x_i, W)$는 $x_i$를 입력 받아 각 클레스에 대한 스코어 값 벡터 $s$를 출력한다. 예를 들어 j번째 클레스의 스코어는 스코어 벡터 $s$의 j번째 값과 같다. :  $s_j = f(x_i, W)_j$ i번째 샘플에 대한 Multiclass Support Vector Machine loss는 아래와 같은 공식으로 쓸 수 있다. 

$$L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)$$

**Example.** 간단한 예를 통해 이 로스 함수가 어떻게 동작하는지 알아 보자. 우리는 세가지 클래스를 다루며 여기에 대한 각 스코어가 다음과 같고 $s=[13, 7, 11]$, 첫번째 클래스가 참($y_i = 0$, 0은 클래스 index를 뜻함, 배열의 경우 일반적으로 index는 0부터 시작한다.)이라고 가정해 보자. 이때 마진을 나타내는 하이퍼파라미터 $\Delta$는 10으로 둔다. 위 식에서 $j \neq y_i$인 두 항(j=1, 2)에 대한 합은 아래와 같이 풀어 쓸 수 있다.

$$L_i = \max(0, -7 - 13 + 10) + \max(0, 11 - 13 + 10)$$

첫번째 항에서 [-7 - 13 + 10]은 음수이며 $max (0, -)$의 결과 0이 나오게 된다. 참인 클래스에 대한 스코어(13)이  거짓인 클래스에 대한 스코어 (-7)보다 마진값(10) 이상 크기 때문에 두 클래스에 대한 로스는 0이 된다. 실제로 차이는 20으로 마진값인 10보다 훨씬 크다. SVM에서 마진 값이상 차이가 나는 경우 $max$ 함수에 의해 0 값으로 고정된다. 두 번째 항은 [11- 13 + 10]을 계산하여 8이 나오게 된다. 즉 참인 클래스가 거짓인 클래스 (13> 11)보다 높은 스코어를 얻었지만 원하는 마진인 10보다 크지 않았기 때문이다. 스코어 차가 2밖에 나지 않았기 때문에, 마진과 차이 만큼인 8이 로스 값으로 나왔다. 요약하자면, SVM 로스함수는 참인 클래스의 스코어가 거짓인 클래스의 스코어 보다 마진($\Delta$) 보다 큰 값을 가지길 원한다. 이 섹션에서 스코어 함수($f(x_i; W) =  W x_i$)는 선형(Linear)이므로 , 다음과 같은 형태로 로스 함수를 정의 할 수 있다.

$$L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)$$

여기서 $w_j$는 행렬 $W$의 j번째 행을 재배치(reshape)하여 열로 나타낸 것과 같다. 하지만 스코어 함수가 더 복잡한 경우 이러한 표현법을 사용 할 필요는 없다. 

이 섹션을 끝내기 전에 언급 할 마지막 용어는 힌지 로스(hinge loss)이며 0에서의 threshold인 $max (0, -)$ 함수를 뜻한다. 종종 제곱(squared) 힌지 로스 SVM (또는 L2-SVM)을 사용하기도 한다. 이때 로스는 제곱항($max(0,-)^2$)에 의해 마진에 대해 더 큰 비중을 둔다. 제곱항이 없는 버전이 더 일반적이지만, 일부 데이터 세트에서 제곱 힌지 로스가 더 잘 동작 하는 경우도 있다. 어떤 힌지 로스를 사용할 지 크로스 벨리데이션(cross-validation)을 통해 결정 할 수 있다.   

*손실 함수는 트레이닝 세트에 대한 예측으로 불일치 정도(unhappiness)을 수치화한다.*

![](http://cs231n.github.io/assets/margin.jpg "margin" "width:600px;float:center;padding-left:10px;")

Multiclass Support Vector Machine은 참인 클래스의 스코어가 다른 클래스의 스코어 보다 적어도 델타의 마진만큼 더 크기를 원한다. 빨간색 영역 (또는 더 큰값: 오른쪽)에  다른 클래스의 스코어가 있으면 로스가 발생한다. 그렇지 않는 경우 로스는 0이 된다. 트레이닝 데이터의 모든 샘플에 대해 이 제약 조건을 동시에 적용시키며, 로스의 합이 가능한 낮은 가중치 행렬을 찾는 것이 학습 목표다.

**Regularization.**  앞에서 다룬 로스 함수에는 한가지 버그가 있다. 데이터 세트와 모든 샘플에 대해 정확하게 분류하는 웨이트 행렬 W가 있다고 가정해보자. 즉 모든 스코어는 마진을 만족하며 모든 샘플 i에 대해 $L_i = 0$이다. 이러한 조건을 만족하는 W는 수없이 많을 것이며, 따라서 W가 유일하지 않다는 점이 문제가 될 수 있다. 쉬운 예로 완벽한 분류기 W가 있을때 W에 스칼라 배수를 취한 $\lambda W$ (여기서 $\Lambda > 1$)역시 모든 샘플에 대해 $L_i = 0$을 만족한다. 스칼라 배수를 취하면 템플릿간의 스코어 역시 균등하게 늘기 때문이다. 가령 W에서 정답 클래스의 스코어와 아닌 클래스의 스코어 간의 차가 15라면, W는 2배 해준 경우 그 차이는 30이 된다.     

이러한 모호성을 줄이기 위해 특정 웨이트셋에 대한 우선 순위를 높일 필요가 있다. 로스 함수에 정규화 페널티(regularization penalty) $R(W)$ 항을 추가하여 위의 효과를 줄 수 있다. 가장 일반적인 정규화 페널티는 웨이트(가중치)가 커지는 것을 방지하기 위한 L2 norm(웨이트를 구성하는 값들을 제곱)이다. 

$$R(W) = \sum_k\sum_l W_{k,l}^2$$

위의 식과 같이 웨이트 매트릭스를 구성하는 각 엘레먼트를 모두 제곱한 다음 더한다. 정규화 함수는 데이터를 사용하지 않으며, 웨이트 매트릭스 만으로 정의된다. 정규화 페널티를 포함하면 전체 Multiclass Support Vector Machine Loss식이 완성된다. 이 식은 데이터로스(모든 샘플에 대한 $L_i$의 평균)와 정규화 로스 두 항으로 구성된다.  즉, 전체 Multiclass Support Vector Machine Loss 식은 다음과 같다.

$$L = \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss} \\\\$$

식을 다음과 같이 풀어 쓸 수 있다. 

$$L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2$$

 여기서 $N$은 트레이닝 샘플의 수를 나타낸다. 보시다시피, 로스 함수에 정규화 페널티를 추가하고, 하이퍼 파라미터 $\lambda$를 추가하였다. 이 하이퍼 파라미터를 설정하는 단순한 방법은 없으며, 보통 교차 유효성 검사(Cross validation)를 통해 결정된다.

 정규화 패널티와 같은 모델의 성능을 높이는 좋은 방법들이 있으며, 이후 섹션에서 다시 다룰 것이다. 예를 들어, L2 패널티를 포함하여 SVM에 max 마진 특성을 줄 수 있다. (자세한 내용은 CS229 강의 노트 참조 ). 이런 페널티 함수의 하이퍼 파리미터를 증가시킴으로서 얻는, 가장 두드러 지는 특성은 일반화를 향상시키는 경향이 있다는 것이다. 왜냐하면 입력이 점수 자체에 큰 영향을 줄 수 없기 때문이다. 예를 들어 입력 $x=[1,1,1,1]$이고 두 웨이트 벡터 $w_1 = [1,0,0,0]$, $w_2 = [0.25,0.25,0.25,0.25]$이라고 하자. 이때 대적에 의한 데이터 로스는 $w_1^Tx = w_2^Tx = 1$로 동일한 반면, $w_1$의 L2 패널티는 1, $w_2$의 L2 패널티는 0.25다. 정규화 로스에 의해 $w_2$의 L2 패널티가 더 우선시 된다. 직관적으로 $w_2$가 더 작은 값들로 구성되어 있으며, 더 넓게 분포되어 있다. 이러한 특성에 의해, L2 패널티를 추가하면 입력 데이터의 특정값이 아닌 전체 값을 고루 반영하는 것을 우선시 하게 된다. 따라서 일반화 정도를 높이며, 오버피팅(overfitting)을 줄이게 된다. 

바이어스는 가중치와 달리 입력에 영향을 주지 못하므로, 동일한 효과를 줄 수 없다.  없습니다. 따라서 바이어스가 아닌 가중치레 대해 정규화하는 것이 일반적으로 사용된다. 하지만 실제 많은 영향을 주지 않는 경우도 있다. 그리고 $W = 0$이 아닌 이상 정규화 페널티는 0이상의 값을 가지므로, 전체 로스함수가 0이 되는 경우도 없다.

**코드 .** 다음은 파이썬으로 구현 된 unvectorized와 half-vectorized 표현의 로스 함수 (정규화가 없는 경우)다. 

```python
def L_i(x, y, W):
  """
  unvectorized version. Compute the multiclass svm loss for a single example (x,y)
  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)
    with an appended bias dimension in the 3073-rd position (i.e. bias trick)
  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)
  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)
  """
  delta = 1.0 # see notes about delta later in this section
  scores = W.dot(x) # scores becomes of size 10 x 1, the scores for each class
  correct_class_score = scores[y]
  D = W.shape[0] # number of classes, e.g. 10
  loss_i = 0.0
  for j in xrange(D): # iterate over all wrong classes
    if j == y:
      # skip for the true class to only loop over incorrect classes
      continue
    # accumulate loss for the i-th example
    loss_i += max(0, scores[j] - correct_class_score + delta)
  return loss_i

def L_i_vectorized(x, y, W):
  """
  A faster half-vectorized implementation. half-vectorized
  refers to the fact that for a single example the implementation contains
  no for loops, but there is still one loop over the examples (outside this function)
  """
  delta = 1.0
  scores = W.dot(x)
  # compute the margins for all classes in one vector operation
  margins = np.maximum(0, scores - scores[y] + delta)
  # on y-th position scores[y] - scores[y] canceled and gave delta. We want
  # to ignore the y-th position and only consider margin on max wrong class
  margins[y] = 0
  loss_i = np.sum(margins)
  return loss_i

def L(X, y, W):
  """
  fully-vectorized implementation :
  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)
  - y is array of integers specifying correct class (e.g. 50,000-D array)
  - W are weights (e.g. 10 x 3073)
  """
  # evaluate loss over all examples in X without using any for loops
  # left as exercise to reader in the assignment
```

이 절에서는 SVM 로스로 트레이닝 데이터에 대한 예측이 참 값과 얼마나 일치하는지 측정하는 한 가지 접근법을 다뤘다. 또한 트레이닝 세트에 대해 바른 예측을 하는 것은 로스를 최소화하는 것과 같다.

*이제 남은 일은 로스를 최소화하는 가중치를 찾는 것 이다.*

##### Practical Considerations

**Setting Delta.** 마진($\Delta$) 하이퍼 파라미터 설정. 마진으로 어떤 값을 설정해야 하는지, 그로스밸리데이션을 사용해야하는지 생각해볼 필요가 있다. 모든 경우에 대해 단순히 $\Delta = 1.0$으로 설정하는 것으로 충분하다. 두 하이퍼 파라미터 $\Delta$ 와 $\lambda$는 서로 상관없어 보이지만, 사실 두 파라미터는 목적함수에서 데이터 로스와 정규화 로스사이의 트레이드오프 관계를 조정한다. 웨이트 매트릭스 $W$를 구성하는 값의 크기는 스코어에 직접적으로 영향을 준다. 값이 작은 경우 스코어 간의 차이(거리)가 적으며, 값이 큰 경우 스코어 간의 차이가 크다. $W$의 크기에 따라 스코어 사이의 차이가 변하므로 스코어 간의 마진(예를 들어 $\Delta = 1.0$ 또는 $\Delta = 100$)은 큰 의미가 없다. 따라서 실제 트레이드오프는 웨이트 값을 얼마나 키울지 정하는 것(regularization strength $\lambda$)이다. 

**Relation to Binary Support Vector Machine.** 본 강의 전에  Binary Support Vector Machines을 접했을 수도 있다. 여기서 i 번째 샘플의 로스함수는 다음과 같이 쓸 수 있다.

$$L_i = C \max(0, 1 - y_i w^Tx_i) + R(W)$$

여기서 $C$는 하이퍼 파라미터이며, $y_i \in \{ -1,1 \}$이다.  binary SVM은 Multiclass Support Vector Machine의 클래스가 2개인 특수한 경우다. 클래스가 2개 밖에 없다면 위와 같이 단순화 할 수 있다. 
$C$는 $\lambda$와 같이 둘사이의 트레이드오프를 조정하며, $C \propto \frac{1}{\lambda}$과 같은 관계에 있다. 

**Aside: Optimization in primal.**  SVM에 대한 사전 지식이 있다면, kernels, duals, SMO 알고리즘 등을 들었을 것이다. 이 수업에서는 (일반적으로 신경망의 경우와 마찬가지로) 제한없는(unconstrained) 목적함수만 다룬다. 이러한 목적함수는 기술적으로 미분불가능한 경우가 많다. (예 : max (x, y) 함수는 x = y 일 때 kink 되므로 ). 하지만 일반적으로 subgradient를 사용하므로, 이것이 실제 큰 문제가 되지 않는다.  

  

**Aside: Other Multiclass SVM formulations.** 이 섹션에서 제시된 Multiclass SVM은 여러 클래스에 걸쳐 SVM을 공식화하는 여러 방법 중 하나다. 일반적으로 사용되는 또 다른 형식은 각 클래스와 다른 모든 클래스에 대해 독립적인 이진 SVM을 학습하는 One-Vs-All (OVA) SVM이다. 이와 유사하지만, 보다 덜 보편적으로 사용되는 All-vs-All (AVA) 방법도 있다. 위 공식은 OVA보다 더 나은 버전인 Weston 및 Watkins 1999 (pdf) 기반이다. (이 버전에서는 데이터 손실을 0으로 만들 수 있지만 OVA는 불가능 함). 마지막으로 Structured SVM도 있다. 이는 참인 클래스의 스코어와 거짓인 클래스 중 가장 높은 스코어간의 마진을 최대화 한다. 이러한 방법 간의 차이점을 다루는 것은 본 수업의 범위를 벗어난다. 위에서 제시된 버전은 실제로 사용하기에 비교적 적합한 방법일 뿐이며, OVA 방법 역시 잘 작동 하는 경우도 있다.

##### Softmax 분류기

VM은 일반적인 두 분류기 중 하나다. 다른 로스함수로 구성된 유명한 분류기는 Softmax 분류기다. 이진 Logistic Regression 분류기에 대해 들어 봤다면, Softmax 분류기는 이를 여러 클래스에 대해 일반화 한 것이다. 출력($f(x_i , W)$)을 다시 계산(교정되지 않았거나 해석하기 어려울 수 있음)하는 SVM과 달리, Softmax 분류기는 좀 더 직관적 인 출력(클래스의 정규화 된 확률) 및 확률론적 해석을 제공한다. Softmax 분류기에서 맵핑함수($f(x_i; W) = W x_i$)는 바뀌지 않는다, 하지만 아래와 같이 각 스코어를 비정규화된 로스 확률(unnormalized log probabilities)로 해석하며, 힌지로스(hinge loss) 대신 크로스앤크로피로스(cross-entropy loss)를 사용한다. 

$$L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}$$

위 식에서 $f_j$는 클래스 스코어 벡터 $f$의 j 인덱스 값을 나타낸다. 이전과 같이 전체 로스는 트레이닝 세트의 각 샘플에 대한 정규화 항$R(W)$을 포함한 $L_i$의 평균과 같다. 함수 $f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$를 **Softmax 함수**라 한다. Softmax 함수는 스코어 백터를 입력 받아 벡터 내 원소의 값들을 0~1사이로, 모든 원소의 합이 1이 되게 한다. Softmax 함수를 포함하는 완전한 크로스 엔트로피 로스는 처음 볼 때 어려워 보이지만, 이해하기는 상대적으로 쉽다.   

**Information theory view** "참" 분포 $p$와 예측 분포 $q$ 사이의 cross-entropy는 아래와 같다. 

$$H(p,q) = - \sum_x p(x) \log q(x)$$

Softmax 분류기는 위 두 분포 간의 cross-entropy를 최소화 한다. 여기서 예측 분포 $q$는 각 클래스의 확률 분포($q = e^{f_{y_i}} / \sum_j e^{f_j}$)이며 $p$는 "참"을 나타내는 분포($p = [0, \ldots 1, \ldots, 0]$, "참"인 클래스에 해당하는 값만 1 나머지는 0)이다. 위 cross-entropy는 Kullback-Leibler divergence 형태로 다음과 같이 다시 쓸 수 있다. 

$$H(p,q) = H(p) + D_{KL}(p||q)$$

따라서 cross-entropy 역시 예측 분포가 참인 분포와 완벽히 일치하는 것이 목적이다. 

**Practical issues: Numeric stability.** 실제 코드상에서 softmax 분류기를 구현하면, 지수 함수의 특성에 의해 중간항 $e^{f_{y_i}}$, $\sum_j e^{f_j}$이 매우 커지는 경우가 있다.  큰 숫자로 나누는 것은 수치적으로 불안정 하기 때문에 정규화하는 것이 중요하다.  Softmax 함수 분자 분모에 $C$를 곱하고, 이를 지수안에 넘기면 아래와 같은 식을 얻는다. 

$$\frac{e^{f_{y_i}}}{\sum_j e^{f_j}} = \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}} = \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}$$

$C$로 아무 값이나 사용해도 된다. 같은 값을 곱했으므로, 결과에는 영향을 미치지 않지만 수치적 안정성을 얻을 수 있다. 일반적으로 $C$값은 $\log C = -\max_j f_j$를 사용한다. 이는 벡터 $f$ 중 가장 큰 값이 0 이되도록 모든 원소를 이동(shift) 시키는 것을 의미한다. 코드로는 아래와 같다. 

```python
f = np.array([123, 456, 789]) # example with 3 classes and each having large scores
p = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup

# instead: first shift the values of f so that the highest number is 0:
f -= np.max(f) # f becomes [-666, -333, 0]
p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answer
```

##### SVM vs. Softmax

아래 그림은 Softmax와 SVM 분류기를 ​구별 하는데 도움을 준다. 

![](http://cs231n.github.io/assets/svmvssoftmax.png "svmvssoftmax" "width:600px;float:center;padding-left:10px;")

한개 데이터 샘플에 대한 SVM과 Softmax 분류기의 차이. 두 경우 모두 매트릭스 곱을 사용하여 동일한 스코어 벡터 f([-2.85, 0.86, 0.28])를 계산한다. 차이점은 f의 스코어에 대한 해석에 있다. SVM의 로스함수는 참 클래스 (파란색의 클래스 2)가 다른 클래스 스코어 보다 크도록 한다. Softmax 분류기는 대신 스코어를 각 클래스의 (비 정규화 된) 로그 확률로 바꾼 다음, 참 클래스의 (정규화 된) 로그 확률이 높기를 바란다.  이 예제에 대한 최종 로스 값은 SVM의 경우 1.58이고 Softmax 분류기의 경우 1.04입니다 (자연 로그를 사용하여 1.04다). 그러나 이 두 수치를 서로 비교할 수는 없다(softmax가 낮으므로 더 좋다고 볼 수 없다.).  이러한 값들은 동일한 분류기 ​​내에서 동일한 데이터로 계산 될때 서로 비교 할 수 있다. 

**Softmax classifier provides “probabilities” for each class.** 모든 클래스에 대해 힌지 로스 함수를 적용하여 각 로스 값을 구하는 SVM과 달리 Softmax 분류기를 사용하면 모든 레이블에 대한 "확률"을 계산한다. 예를 들어 이미지가 주어지면 SVM 분류기는 "cat", "dog"및 "ship"클래스에 대해 다음과 같은 스코어 [12.5, 0.6, -23.0]가 나온다. softmax 분류기는 대신 세 라벨의 확률을 [0.9, 0.09, 0.01]로 계산한다. 이는 각 클래스의 신뢰도(확률)를 나타 낸다고 볼 수 있다. 그러나 "확률"이라는 단어를 사용하는 이유는 확률 분포가 정규화 파라미터 $\lambda$ 값에 따라 확산되거나, 수축하기 때문이다.  예를 들어, 클래스에 대한 비표준(unnormalize) 로그 확률이 ​​[1, -2, 0]이 라고 가정하면,  softmax 함수 결과는 다음과 같다. 

$$[1, -2, 0] \rightarrow [e^1, e^{-2}, e^0] = [2.71, 0.14, 1] \rightarrow [0.7, 0.04, 0.26]$$

표준화(normalize) 된 값을 모두 더하면 1이 된다. 정규화 파라미터 $\lambda$가 커지면 $W$내 원소 값은 작아지게 된다. 웨이트값들이 절반이 되었다고 가정하면 softmax 함수 결과는 다음과 같다. 

$$[0.5, -1, 0] \rightarrow [e^{0.5}, e^{-1}, e^0] = [1.65, 0.37, 1] \rightarrow [0.55, 0.12, 0.33]$$

그 결과 확률 분포가 확산되었다. 따라서 $\lambda$가 매우 커지면 확률 분포는 평탄해지게 될 것이다. 따라서 Softmax 분류기로 계산 된 확률 역시 SVM 처럼 우선 순위를 정할 수 있지만, 값의 차이 보다는 신뢰도(확률)로 해석된다.

**In practice, SVM and Softmax are usually comparable**

SVM과 Softmax의 성능 차이는 일반적으로 매우 작으므로, 어느 분류기가 좋은 가에 대한 상충되는 의견이 있다. Softmax 분류기에 비해 SVM은 지엽(local)적인 성질이 있으며 이는 SVM 분류기의 버그나 특성으로 보기도 한다.  스코어 벡터가 [10, -2, 3]이며, 첫 번째 클래스가 참인 경우를 생각해보자. SVM (예 : margin = 1) 인 경우 참인 클래스가 이미 다른 클래스의 스코어와 비교하여 마진보다 큰 스코어를 가지므로 로스 값은 0이다. SVM에서는 각 점수가 어떤 값을 가지는지 크게 중요하지 않다. [10, -100, -100] 이나 [10, 9, 9] 인 경우 모두 SVM은 마진 1이상 차이 나므로 로스 계산 결과는 0이다. 그러나 Softmax 분류기에서는 이러한 경우 [10, -100, -100]보다 스코어 [10, 9, 9]의 로스 값이 훨씬 높다. 즉, Softmax 분류기에서 계산 결과가 만족(0) 되는 경우는 없다. 참 클래스는 항상 높은 확률을, 잘못된 클래스는 항상 낮은 확률을 가지도록 학습되며 로스는 항상 더 줄어 들 것이다. SVM의 경우 마진이 만족되면 더 이상 세부적인 학습이 진행 되지 않는다. 이것은 장점이 될 수도 있다. 예를 들어 어느 정도 학습된 자동차 분류기에서 "개구리" 샘플이 입력되는 경우 매우 낮은 스코어를 가지므로 로스는 0이 되므로 더 이상 미세한 학습을 진행하지 않으며, 대신 트럭과 자동차를 구분하는데 더 "노력" 할 것이다.

##### Interactive web demo

![](http://cs231n.github.io/assets/classifydemo.jpeg "classifydemo" "width:600px;float:center;padding-left:10px;")

[http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/](http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/)

선형 분류기의 이해를 돕기 위한 웹 데모. 이 데모는 이 섹션에서 설명한 로스 함수를 2D 데이터와 간단한 3 방향 분류를 사용하여 시각화한다. 또한 다음 섹션에서 자세히 다룰 최적화 작업을 수행한다.

##### Summary

요약하자면, 

- 이미지 픽셀에서 클래스 스코어를 구하는 스코어 함수(가중치 W 및 바이어스 b 에 따라 달라지는 선형 함수) 를 정의했다 .
- kNN 분류기와 달리 위 parametric approach의 장점은 파라미터가 학습 된 다음에는 학습 데이터를 삭제할 수 있다는 것이다. 또한 새로운 테스트 이미지에 대한 예측 역시 모든 학습데이터에 대해 비교하는 것이 아닌, 단지 W와의 행렬 곱셈만 하면 되므로 매우 빠르게 수행 할 수 있다. 
- 두 로스 함수 (선형 분류기에 대해 일반적으로 사용되는 SVM과 Softmax)를 정의했다. 이 로스 함수는 주어진 파라미터 세트가 트레이닝 데이터 세트의 Ground truth 레이블과 관련하여 얼마나 잘 맞는지 측정한다. 여기서 로스 함수의 결과 값이 작을 수록 트레이닝 데이터에 대한 예측이 좋은 것을 의미한다. 

이제 이미지의 데이터 세트를 가져 오는 방법 중 하나를 보았고, 각 이미지를 파라미터 세트 기반으로 클래스 스코어에 각각 매핑했다. 그리고 예측의 정확도를 측정하는 데 사용할 수 있는 두 로스 함수를 살펴 봤다. 하지만 최상의 (최저 로스값)을 주는 파라미터를 찾는 방법은 무엇일까? 이 같은 프로세스를 최적화 작업이라 하며 다음 섹션에서 다룰 것이다. 

##### Further Reading

- [Deep Learning using Linear Support Vector Machines](http://arxiv.org/abs/1306.0239) from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.


