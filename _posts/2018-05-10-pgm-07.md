---
title: 07 Independencies in Bayesian Networks
category: ProbabilisticGraphicalModels
excerpt: |
  지난 시간에는 베이지안 네트워크에서 두 노드의 값이 변할때 어떻게 서로 영향을 주는지 직관적인 추론(Reasoning)을 통해 알아봤습니다. 이번 시간에는 어떤 경우에 노드 사이에 서로 영향을 주는지를 보다 정확하게 살펴 보겠습니다. 일단 일반적인 경우의 예부터 보겠습니다.   


feature_text: |
  ## [Coursera] Probabilistic Graphical Models
  Daphne Koller의 Probabilistic Graphical Models 강의 정리

  ref: https://www.coursera.org/learn/probabilistic-graphical-models/home

feature_image: "https://picsum.photos/2560/600/?image=798"
image: "https://picsum.photos/2560/600/?image=798"
comment: true
---


##### Independence and Factorization

그래픽 모델에서 가장 재미있는 부분은 여러 변수에 대한 확률 분포를 팩터의 곱으로 분해(Factorization)하는 것입니다. 이를 수행하기 위해서는 독립성(independence)를 만족해야합니다. 베이지안 네트워크를 통해 분해와 독립성이 서로 어떤 연관이 있는지 살펴보겠습니다.   

![](http://cfile21.uf.tistory.com/image/230E9D4B5891D86E108C81 "Independence" "width:600px;height:100px;float:center;padding-left:10px;")

위 식은 앞선 강의에서 본 독립성에 대한 정의입니다. 두 변수의 확률분포가 각 확률분포의 곱으로 표현됩니다. 조건부 독립의 경우도 비슷하게 표현됩니다.   

![](http://cfile28.uf.tistory.com/image/26355B4B5891D86E2E5DF4 "Independence" "width:600px;height:150px;float:center;padding-left:10px;")

이렇듯 두 변수에 대한 확률분포 P를 분해(Factorization)한다는 것은 두 변수가 서로 독립적인 것을 의미합니다. 지금부터는 그래프 G의 변수의 확률분포에 대한 Factorization이 있을 때, 그래프 내 변수들 사이의 독립성을 어떻게 확인 할 수 있는지 알아보겠습니다.  

![](http://cfile21.uf.tistory.com/image/256FC64B5891D86F33F37E "Factorization" "width:600px;height:250px;float:center;padding-left:10px;")

위 그래프에서 S와 D가 관련성이 있으려면 G를 보고(조건으로 삼고) 있어야 한다는 것을 지난 강의에서 다뤘습니다. 그리고 두 노드 X,Y와 조건(observation) Z가 주어지고 X, Y사이에 active trail이 없는 상황 즉 두 노드가 서로 관련성이 없을때 두 노드가 d-separated되었다고 정의합니다. 그리고 조건 Z가 주어지고 X,Y 사이에 d-separated 될 때, 두 변수에 대한 조건부 독립을 만족합니다.   

![](http://cfile29.uf.tistory.com/image/275B374B5891D87034236B "Factorization" "width:600px;height:250px;float:center;padding-left:10px;")

그렇다면 베이지안 네트워크에서 두 변수가 서로 독립이라는 것은 어떻게 증명할까요? 간단합니다. 그래프 전체에 대한 확률 분포를 구한다음 체인룰을 이용하여 분해합니다. 그리고 두 변수를 제외하고 나머지 변수들을 통합(merge)합니다. 이 때 식이 각 변수에 대한 확률분포의 곱으로 표현된다면 두 변수는 서로 독립입니다. 위에서는 D와 S가 독립임을 증명하고 있습니다. 그리고 D와 S는 독립이므로 d-separated 되었다고 볼 수 있습니다.  

![](http://cfile5.uf.tistory.com/image/2270594B5891D8710614CA "Factorization" "width:600px;height:250px;float:center;padding-left:10px;")

지금부터는 일반적으로 그래프의 모든 노드가 d-separated됨을 보겠습니다. 우선 non-descendants 개념을 정리 하겠습니다. 하위 노드가 있는 경우 non-descendants라고 합니다. 위 그래프에서 Job, Happy는 descendants 나머지는 non-descendants입니다. non-descendants와 d-separated의 관계를 설명하겠습니다. SAT와 Letter를 예로 들겠습니다. Letter와 SAT는 독립인 관계를 만들수 있을까요? 부모를 노드를 통하는 경로 즉 위쪽 경로(G, I)를 먼저 보겠습니다. 우선 경로 상 V구조가 없으므로 둘사이에 관련성이 있습니다. 따라서 독립은 될 수가 없을 것입니다. 하지만 Grade가 주어진다면(조건이 된다면)앞서 살펴 봤듯이 둘 사이는 관련성이 없어지고 조건부독립관계가 됩니다. 이는 부모노드를 통해 연결되는 모든 변수(Coherence, Difficulty, Intelligence...)들에게도 동일하게 적용됩니다. 즉 부모노드를 조건으로 잡으면 부모노드를 통한 모든 연결(Trail)에 대해서는 독립을 보장할 수 있습니다. 반면 자식노드를 통해 연결 되는 경우는 어떨까요? 이 경우에는 V-구조기 때문에 둘사이에 관련성이 끊어 지게 되며 독립성을 보장 받을 수 있습니다. 따라서 다음과 같이 정리할 수 있습니다.
그래프 G에서 non-descendants노드는 모든 상위노드를 조건으로 잡는 경우 독립을 만족합니다. 즉 $(P(L,S\|G)=P(L\|G)P(S\|G)$를 만족하므로 독립입니다.

##### I-map

![](http://cfile22.uf.tistory.com/image/253BFB3A589328FD0252DB "I-map" "width:600px;height:250px;float:center;padding-left:10px;")

그래프의 모든 변수에 대한 확률 분포 P가 독립을 만족하는 경우 그래프 G를 P의 I-map(independency map)이라 정의합니다.

![](http://cfile21.uf.tistory.com/image/23048A3A589328FE2F0DB8 "I-map" "width:600px;height:250px;float:center;padding-left:10px;")

두 확률 분포 $P_1, P_2$가 있습니다. 그리고 여기에 대한 두 그래프가 아래와 같이 있습니다. $G_1$의 경우 두 변수는 완전히 분리되어 있으며, $G_2$의 경우 D는 I의 상위 노드로 연결되어 있습니다. 따라서 $G_1$의 경우 두 변수가 독립이며, $G_2$의 경우는 아니라는 것을 볼 수 있습니다. Factor로 표현한 확률 분포 표를 통해서도 확인 할 수 있습니다. 여기서 $P_1$의 두 변수는 독립이며 $P_2$의 경우에는 아닙니다.

$P_1$은 앞에서 다뤘으므로 $P_2$만 살펴 보겠습니다. $P(i^0, d^0)=0.282$입니다. 반면 $P(i^0)P(d^0)=0.302*0.846=0.255492$이므로 서로 독립이 아님을 볼 수 있습니다.  

![](http://cfile30.uf.tistory.com/image/261E083A589328FE05A70F "I-map" "width:600px;height:250px;float:center;padding-left:10px;")

여기서 한 가지 Theorem이 나올 수 있습니다. 그래프 G의 확률 분포 P가 factorize된다면 G는 P의 I-map입니다.  

![](http://cfile10.uf.tistory.com/image/235A043A589328FF322117 "I-map" "width:600px;height:300px;float:center;padding-left:10px;")

그리고 그 역 역시 성립됩니다. G가 P의 I-map이라면 P를 factorize 할 수 있습니다. 이를 증명해 보겠습니다. 5개 변수에 대한 결합 분포를 일반적인 조건부 확률 분포의 체인 룰로 표현 하면 위와 같습니다. $P(D,I)=P(D)P(I\|D)$임을 떠올려 봅시다. 베이지안 네트워크가 없더라도 이렇게 표현 할 수 있습니다. 이제 이를 위 베이지안 네트워크를 보며 정리 해 보겟습니다. 네트워크 상에서 D와 I는 관련성이 없으므로 $P(I\|D)=P(I)$로 D를 소거 할 수 있습니다. $P(S\|D,I,G)$ 역시 I가 부모 노드이므로 I를 조건으로 잡으면 non-descendants를 다루면서 설명했듯이, S는 D, G와 관련성이 없어지므로 소거 할 수 있습니다. 비슷한 방법을 통해 L역시 정리 할 수 있습니다. 이렇게 정리하면 P를 factorize한 결과와 동일한 식을 얻을 수 있습니다. 따라서 위 Theorem이 참인 것을 증명했습니다.

![](http://cfile4.uf.tistory.com/image/2338DE3A58932900178335 "I-map" "width:600px;height:250px;float:center;padding-left:10px;")

정리하자면, 그래프 구조에서 Factorization과 I-map은 서로 같은 의미를 가집니다. 그 의미는, 확률분포 P가 특정 그래프에 의해 베이지안 네트워크로 표현된다면 우리는 각 변수들 사이의 독립성에 관해 파악할 수 있다는 뜻입니다. 따라서 특정 변수에 미치는 영향을 알 수 있고, 변수의 확률 분포가 변했을 때 다른 변수들에 어떤 영향을 주는지를 파악할 수 있습니다. 이는 결과나 확률 분포의 구조를 예측하는데 많은 도움이 됩니다.  
