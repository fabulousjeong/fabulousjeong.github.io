---
title: cs231n 번역 9 Convolutional Neural Networks Architectures, Convolution / Pooling Layers
excerpt: |
 컨볼루션 신경망 (Convolutional Neural Networks)은 이전 장에서 다룬 기본 신경망과 매우 유사하다. 이 신경망 역시 학습 가능한 웨이트와 바이어스을 가진 뉴런으로 구성된다. 각 뉴런은 몇몇 입력들을 받아, 내적 (dot product)하며, 때로는 비선형 계산을 추가로 수행한다.  

feature_text: |
  ## Stanford CS class CS231n: 

  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=849"
image: "https://picsum.photos/2560/600/?image=849"
comment: true
---


#### Convolutional Neural Networks (CNNs / ConvNets)
컨볼루션 신경망 (Convolutional Neural Networks)은 이전 장에서 다룬 기본 신경망과 매우 유사하다. 이 신경망 역시 학습 가능한 웨이트와 바이어스을 가진 뉴런으로 구성된다. 각 뉴런은 몇몇 입력들을 받아, 내적 (dot product)하며, 때로는 비선형 계산을 추가로 수행한다. 입력단의 원본 이미지 픽셀부터 다른 쪽 끝 출력단의 클래스 점수를 이루는 전체 네트워크는 여전히 미분가능한 하나의 스코어 함수로 표현된다. 그리고 마지막 레이어(Fully-Connected)에 이전과 같이 로스 함수(예 : SVM / Softmax)를 가지고 있으며, 기본 신경망을 학습하기 위해 다룬 모든 팁/트릭 역시 여전히 적용된다. 

그래서 뭐가 바꼈을까? ConvNet 아키텍쳐는 입력이 이미지라고 명시적으로 가정한다. 이를 통해 아키텍처에 특정 속성을 인코딩 할 수 있다. 그러면 전달 함수를 보다 효율적으로 구현하며, 네트워크 파라미터 양을 크게 줄일 수 있다.


##### Architecture Overview

**Recall**: 기본 신경망. 이전 장에서 보았 듯이 신경망은 입력(하나의 벡터)을 받고 연속 된 히든 레이어를 통해 이를 변환한다. 각각의 히든 레이어는 뉴런으로 구성되며, 각 뉴런은 이전 레이어의 모든 뉴런에 완전히 연결되어 있으며, 각 레이어 내 뉴런은 완전히 독립적으로 작동하며 서로간에 연결되어 있지 않다. 마지막 완전 연결(fully-connected) 레이어를 "출력 레이어"라고하며 분류기에서 클래스 점수를 나타낸다.

**Regular Neural Nets**은 모든 이미지에 맞도록 확장되지 않는다.  CIFAR-10에서 이미지는 크기가 32x32x3 (32 와이드, 32 높이, 3 컬러 채널)이므로 기본 뉴런 네트워크의 첫 번째 히든 레이어에있는 하나의 완전 연결 뉴런은 32 * 32 * 3 = 3072의 웨이트 파라미터를 가진다.  이 정도 계산량은 여전히 다루기 쉬워 이지만 이 완전히 연결 구조는 더 큰 이미지로 확장하기 어렵다. 예를 들어, 200x200x3과 같이 조금 더 대중적인 크기의 이미지는 뉴런의 웨이트파라미터 수를 200 * 200 * 3 = 120,000개 가지게 할 것이다. 또한, 그러한 뉴런이 여러개 있을 것이므로 파라미터 수는 급격하게 늘어 날 것이다!! 분명히 이러한 완전 연결은 낭비적이며 엄청난 파라미터수는 오버피팅을 야기할 것이다. 

**뉴런의 3D 볼륨** 콘볼루션 뉴럴 네트워크(Convolutional Neural Networks)는 입력이 이미지로 구성되어 있다는 점과, 보다 합리적인 방식의 아키텍처로 제한한다는 점을 이용한다. 특히, 일반적인 신경망과는 달리, ConvNet의 레이어에는 폭, 높이, 깊이의 3 가지 차원으로 배열 된 뉴런이 있다. (깊이(depth) 라는 단어, 활성화 볼륨의 세 번째 차원을 의미하며, 전체 신경망의 깊이(네트워크의 전체 레이어 수)를 의미하지 않는다.) 예를 들어, CIFAR-10의  입력 볼륨은 입력 이미지며, 그 크기는 32x32x3 (폭, 높이, 깊이)이다. 아래에서 보게 되겠지만, 한 레이어에 있는 뉴런들은 이전과 달이 완전히 연결 되어있지 않으며, 그 레이어의 작은 일부 영역에만 연결된다. 또한 ConvNet 아키텍처가 끝날 때 전체 이미지를 깊이 차원을 따라 배열 된 단일 클래스 스코어 벡터로 축소하므로 CIFAR-10의 최종 출력 레이어는 1x1x10 크기를 가진다. 아래는 시각화 자료이다. 

![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg "neural_net2" "width:250px;float:center;padding-left:10px;")![](http://cs231n.github.io/assets/cnn/cnn.jpeg "cnn" "width:350px;float:center;padding-left:10px;") 

왼쪽 : 기본 3 레이어 신경망. 오른쪽 : ConvNet은 위의 그림과 같이 3 차원 (너비, 높이, 깊이)으로 뉴런을 정렬한다. ConvNet의 모든 레이어는 3D 입력 볼륨을 뉴런 활성화 함수 3D를 반영한 출력 볼륨으로 변환한다. 이 예제에서 빨간색 입력 레이어는 이미지를 보유하므로 너비와 높이가 이미지의 크기가되고 깊이는 3(빨강, 녹색, 파랑 채널)이다.

*ConvNet은 레이어들로 구성된다. 모든 레이어에는 간단한 API가 있으며, 이를 통해 파라미터가 있거나, 없는 미분가능 함수를 통해 입력  볼륨을 출력 3D 볼륨으로 변환한다. *

##### Layers used to build ConvNets

위에서 설명한 것처럼 ConvNet은 연속된 레이어 구조며며 ConvNet의 각 레이어는 한 볼륨을 미분 가능 함수를 통해 다른 볼륨으로 변환한다.  다음과 같은 세 가지 주요 레이어를 사용하여 ConvNet 아키텍처를 구축 한다. **컨벌루션 레이어 , 풀링 레이어, 완전 연결 레이어** (일반 뉴럴 네트워크와 동일). 이 레이어들을 스택하여 전체 ConvNet 아키텍처 를 형성 할 것 이다. 

예제 아키텍처 : 개요 . 아래에서 더 자세히 설명 하겠지만 CIFAR-10 분류를위한 간단한 ConvNet은 [INPUT-CONV-RELU-POOL-FC] 아키텍처를 가진다. 더 자세하게는:

- INPUT [32x32x3]은 이미지의 픽셀 값을 저장하며, 이 경우 폭 32, 높이 32의 이미지와 세 개의 색상 채널 R, G, B가 있다.
- CONV 레이어는 입력의 로컬 영역에 연결된 뉴런의 출력을 계산한다. 각 뉴런은 웨이트와 입력 볼륨과 연결된 작은 영역 사이의 내적을 계산한다. 12 개의 필터를 사용한다면 [32x32x12]와 같은 볼륨을 가진다. 
- RELU 레이어는 다음과 같은 각 요소 별 활성화 함수($max(0,x)$)를 적용한다. 여기서 볼륨의 크기는 변경되지 않는다 ([32x32x12]).
- POOL 레이어는 공간 차원(너비, 높이)을 따라 다운 샘플링 작업을 수행하므로, 따라서 출력은 [16x16x12]와 같은 볼륨이 된다. 
- FC (즉, 완전 연결)레이어는 클래스 스코러를 계산하며, 그 결과로 크기 [1x1x10]의 볼륨을 출력한다. 이는 여기의 10개의 숫자가 CIFAR-10의 10가지 레이블과 같은 클래스 스코어에 해당하기 때문이다. 기본 신경망과 마찬가지로 이름에서 알 수 있듯이 이 레이어의 각 뉴런은 이전 볼륨의 모든 뉴런과 연결된다.

이 방법으로 ConvNets는 원본 이미지 레이어의 픽셀 값을 최종 클래스 스코어들로 변환한다. 일부 레이어는 파라미터를 포함하며 그러지 않은 레이어도 있다. 특히, CONV / FC 레이어는 활성화 입력 볼륨의 뿐만 아니라 파라미터에 대한 변환 함수기도 하다. 반면에 RELU / POOL 레이어는 고정 된 함수이다. CONV / FC 레이어의 파라미터는 그래디언트 디센트로 학습되어, ConvNet에서 계산 한 클래스 스코어가 각 이미지에 대한 트레이닝 세트의 레이블과 일치되도록 만든다. 

요약하자면:

- ConvNet 아키텍처는 입력 이미지 볼륨을 출력 볼륨(클래스 스코어)로 변환하는 가장 간단한 케이스다. 
- 레이어에는 몇 가지 유형이 있다 (예 : CONV / FC / RELU / POOL이 가장 많이 사용된다.)
- 각 레이어는 입력 3D 볼륨을 받으며, 미분 가능한 함수를 통해 출력 3D 볼륨으로 변환한다.
- 각 레이어에는 파라미터가 있을 수도 있고 그렇지 않을 수도 있다. (파라미터 유: CONV / FC, 무: RELU / POOL)
- 각 레이어에는 추가 하이퍼 파라미터가있을 수도 있고 없을 수도 있다 (유: CONV / FC / POOL, 무: RELU)

![](http://cs231n.github.io/assets/cnn/convnet.jpeg "convnet" "width:600px;float:center;padding-left:10px;") 

예제 ConvNet 아키텍처의 활성화. 초기 볼륨은 이미지 픽셀 (왼쪽)을 저장하고 마지막 볼륨은 클래스 점수 (오른쪽)를 저장한다. 위 그림의 각 열은 처리 경로를 따라 활성화되는 각 볼륨을 표현한다. 3D 볼륨을 시각화하는 것은 어렵기 때문에 각 볼륨에 대한 슬라이스를 행으로 배치한다. 마지막 레이어 볼륨은 각 클래스의 점수를 저장하지만 여기서는 상위 5 개 점수 정렬하여 시각화한 다음 각 점수의 레이블을 프린트한다. 전체 [웹 기반 데모](http://cs231n.stanford.edu/)는 강의 웹 사이트의 머리글에 표시되어 있다. 위 아키텍처는 VGG Net의 매우 작은 버전이며 나중에 설명하겠다.

이제 각 레이어와 해당 하이퍼 파라미터 및 해당 연결에 대한 세부 정보를 설명한다. 

##### Convolutional Layer

Conv 레이어는 Convolutional Network의 핵심 블록으로, 대부분의 연산을 수행한다. 

**Overview and intuition without brain stuff.** 먼저 뇌과학이나 신경에 대한 유추 없이 CONV가 어떻게 계산되는기 토론해 보자. CONV 레이어의 파라미터는 연속된 학습 가능한 필터로 구성됩니다. 모든 필터는 공간적으로(폭과 높이를 따라)작으며, 입력 볼륨의 전체 깊이까지 확장됩니다. 예를 들어, ConvNet의 첫 번째 레이어의 일반적인 필터는 크기는 5x5x3 일 수 있다 (폭과 높이가 5 픽셀이고 보통 이미지의 깊이는 색상 채널로 3이므로). 정방향 패스 중에 입력 볼륨의 가로 세로 방향을 따라 각 필터를 슬라이드(더 정확하게, convolve)하며, 필터와 해당 위치의 입력 값들 사이의 내적을 계산한다. 입력 볼륨의 가로 세로 방향으로 대해 필터를 슬라이드하면, 모든 영역에서 해당 필터의 응답을 제공하는 2 차원 활성화(Activation) 맵이 생성된다. 직관적으로, 첫 번째 레이어의 필터에서는 네트워크는 특정 방향의 선 또는 특정 색상의 얼룩을 학습하며, 더 깊은 레이어의 필터들은 벌집 또는 휠 모양 패턴등을 학습한다. 각 CONV 레이어에는 필터 집합(예 : 12 개의 필터)이 있고, 각 인스턴스는 별도의 2 차원 활성화 맵을 생성한다. 이러한 활성화 맵을 깊이 차원을 따라 쌓고 출력 볼륨을 생성한다. 

**The brain view.**  뇌과학이나 신경에 대한 유추를 한다면, 3D 출력 볼륨의 모든 엔트리는 입력의 작은 영역만 보며 파라미터를 공유하는 뉴런의 출력으로 해석 될 수 있다. (모두 동일한 필터를 적용하므로). 이제 뉴런 연결성, 공간에서의 배열 및 파라미터 공유에 대해 자세히 논의한다. 

**Local Connectivity.** 위에서 보았듯이 이미지와 같은 고차원 입력을 다룰 때 이전 볼륨의 모든 뉴런에 연결하는 것은 비현실적이다. 대신에 각 뉴런을 입력 볼륨의 로컬(일부) 영역에만 연결한다. 이 연결의 공간적 범위는 뉴런의 수용(receptive) 필드(커널 필터 크기라고도 불림)라고하는 하이퍼 파라미터다. 깊이 축을 따라 연결되는 범위는 항상 입력 볼륨의 깊이와 같다. 공간(너비와 높이)과 깊이를 처리하는 방법에서 이 차별성을 다시 한번 강조한다. 연결은 공간에서 로컬(너비와 높이를 따라)이지만, 깊이는 항상 입력 볼륨의 전체 깊이를 따른다. 

예제 1 . 예를 들어 입력 볼륨의 크기가 [32x32x3] (예 : RGB CIFAR-10 이미지)라고 가정해 보자. 수용 필드(또는 필터 크기)가 5x5이면 Conv Layer의 각 뉴런은 입력 볼륨의 [5x5x3] 영역에 대한 웨이트를 가지며 총 5 * 5 * 3 = 75 웨이트(+1 바이어스 매개 변수). 깊이 축을 따라 연결된 연결 범위는 입력 볼륨의 깊이와 같아야하므로, 3이다. 

예제 2 . 입력 볼륨의 크기가 [16x16x20]이라고 가정하자. 그런 다음 3x3의 수용 필드 크기 예제를 사용하면 Conv Layer의 모든 뉴런에 총 3 * 3 * 20 = 180 개의 입력 볼륨 연결이 생긴다. 연결성은 공간적으로 (예 : 3x3) 지역적이지만 깉이는 입력(20)과 동일하다.

![](http://cs231n.github.io/assets/cnn/depthcol.jpeg "depthcol" "width:270px;float:center;padding-left:10px;")![](http://cs231n.github.io/assets/nn1/neuron_model.jpeg "neuron_model" "width:330px;float:center;padding-left:10px;")

왼쪽 : 적색의 입력 볼륨 (예 : 32x32x3 CIFAR-10 이미지) 및 첫 번째 컨볼루션 레이어의 뉴런 볼륨의 예. 콘볼 ​루션 레이어의 각 뉴런은 공간적으로 입력 볼륨의 로컬 영역에 연결되지만, 깊이는  전체(예 : 모든 색상 채널)에 연결되어 있다. 참고로 깊이(필터 수)에 따라 여러 개의 뉴런 (이 예제에서는 5 개)이 있으며, 모두 입력의 동일한 영역을 보고 있다. 아래 텍스트의 깊이 열에 대한 설명을 참조하라. 오른쪽 : 뉴런 네트워크 장에서 다룬 동일한 뉴런 그림이다. 입력과 웨이트의 내적과 비선형 성에 대한 계산은 여전이 행해지지만, 연결성은 공간적으로 제한된다. 


**Spatial arrangement.** Conv Layer에있는 각 뉴런의 입력 볼륨에 대한 연결성을 설명했지만, 출력 볼륨에 얼마나 많은 뉴런이 생기는지, 또는 그 배열에 대해서는 아직 논의하지 않았다. 세 가지 하이퍼 파라미터는 출력 볼륨의 크기를 제어한다( 깊이, 보폭 및 제로 패딩) . 아래에서 이것들을 토론한다.

1. 첫째, 출력 볼륨 의 깊이는 파라미터 변수다. 이 값은 사용하려는 필터의 수에 해당하며, 각 입력에서 다른 것을 찾으려고 학습한다. 예를 들어, 첫 번째 컨볼루션 레이어에서 원본 이미지를 입력으로 가져온 경우 깊이 방향의 다양한 뉴런은 다양한 방향 에지 또는 색상 얼룩에 따라 활성화 될 수 있다. 입력란의 동일한 영역의 깊이 열을 보는 뉴런의 집합을 참조한다. (어떤 사람들은 파이버 라는 용어를 선호하기도 한다). 
2. 둘째, 필터를 슬라이드하는 보폭을 지정해야한다. 보폭이 1이면 필터를 한 번에 한 픽셀 씩 이동한다. 보폭이 2 일 때 (또는 드문 경우 3 이상) 필터는 한 번에 2 픽셀 씩 뛰어 넘는다. 이것은 공간적으로 작은 출력 볼륨을 생성한다. 
3. 아래에서 곧 보게 될 것처럼, 때로는 입력 볼륨을 경계선 주위에 0으로 채우는 것이 편리 할 때도 있다. 이 제로 패딩 의 크기 는 하이퍼 파라미터다. 제로 패딩의 좋은 특징은 출력 볼륨의 공간 크기를 제어 할 수 있다는 것이다. (입력 볼륨의 공간 크기를 정확하게 보존하기 위해, 사용할 것이므로 일반적으로 입력 및 출력 너비 높이는 동일하다. 

출력 볼륨의 공간 크기를 계산할 수 있다. 입력 볼륨 크기($W$), Conv 층 뉴런의 수용 필드 크기 ($F$), 적용되는 보폭 ($S$), 가장 자리에 사용 된 제로 패딩 (zero padding)의 양($P$). 다름 식으로 얼마나 많은 뉴런이 나오는지 계산 할 수 있다. $(W - F + 2P)/S + 1$, 예를 들어 7x7입력에, 필터 크기는 3x3, stride는 1 패딩은 0이라면 출력의 크기는 5x5와 같다. stride가 2인 경우 3x3으로 출력된다. 조금 더 시각적인 예를 보자 . 
 
![](http://cs231n.github.io/assets/cnn/stride.jpeg "stride" "width:600px;float:center;padding-left:10px;")

공간적 배열의 그림. 이 예에서는 공간 차원 (x 축)이 하나 뿐이며, F = 3의 수용 필드 크기를 가진다. 입력 크기는 W = 5이며 P = 1의 제로 패딩이 있다. 왼쪽 : 신경 스트라이드 (5 - 3 + 2) / 1 + 1 = 5의 출력을 제공한다. 오른쪽 : 뉴런은 S = 2의 보폭을 사용하여 크기 (5 - 3 + 2)/ 2 + 1 = 3.의 출력을 제공한다. 스트라이드 S = 3은 볼륨 전체에 깔끔하게 맞지 않으므로 사용할 수 없다. 방정식의 관점에서, 이것은 (5 - 3 + 2) = 4가 3으로 나눌 수 없기 때문에 결정될 수 없다. 이 예제에서 뉴런의 웨이트는 (1,0, -1)이며 (가장 오른쪽에 표시), 바이어스는 0이다. 이 웨이트는 모든 노란색 뉴런에서 공유되어 동일하게 적용된다. (아래 매개 변수 공유 참조).

**Use of zero-padding.**  위의 왼쪽 예에서 입력의 차원은 5이고 출력은 입력과 같은 차원임을 주목하자. 이는 커널 크기가 3이고, 제로 패딩을 1로 사용했기 때문이다. 제로 패딩이 사용되지 않은 경우, 출력 볼륨의 차원은 3이되고 이는 입력과 커널에 "딱맞게"는 뉴런의 수와 같다. 일반적으로 제로 패딩을 $P = (F - 1)/2$로 잡고, stride $S=1$ 일 때 입력 볼륨과 출력 볼륨은 동일한 크기를 가진다. 이런식으로 제로 패딩을 사용하는 것은 매우 일반적이며 이에 대한 이유는 아래 ConvNet 아키텍처에 대해 자세한 논의에서 다룰 것이다. 

**Constraints on strides.** 공간 배열 하이퍼 파라미터에는 상호적 제약이 있음을 다시 한번 유의하자. 예를 들어, 입력의 크기 $W=10$가, 제로패딩 $P=0$, 커널필터크기 $F=3$인 경우, Stride값 $S=2$가 될 수 없다. 그 이유는 $(W - F + 2P)/S + 1 = (10 - 3 + 0) / 2 + 1 = 4.5$에 의해 정수가 되지 않으며, 입력에 대해 들어 맞지 않기 때문이다. 따라서 이러한 하이퍼 파라미터 설정은 유효하지 않은 것으로 간주되며, ConvNet 라이브러리는 예외를 던지거나, 제로 패드나 입력을 적절히 조정하여 적합하게 만든다. ConvNet 아키텍처 섹션에서 볼 수 있듯이, 전체 ConvNets이 잘 동작 하도록 ConvNets의 하이퍼 파라미터를 적절하게 조정하는 것은 골치 아픈 일이 될 수 있다. 이 경우 제로 패딩 및 일부 디자인 방법들을 사용하여 보다 수월하게 구성 할 수 있다. 

**Real-world example.** 2012년 ImageNet 우승 아키텍쳐(Krizhevsky 등.)는 [227x227x3]을 입력 이미지 크기 설정하였다. 첫 번째 Convolutional Layer에서는 필드 크기 $F=11$, stride $S=4$, 제로패딩 $P=0$으로 설정 했으며, 따라서 (227 - 11)/4 + 1 = 55가 된다. 그리고 여기서 conv 레이어의 depth $K=96$이므로 출력 볼륨의 크기는 [55x55x96]과 같다. 이 볼륨 55 * 55 * 96 개의 각 뉴런은 입력 볼륨에서 크기 [11x11x3]의 영역에 연결된다. 또한 각 깊이 열에 있는 대응 되는 96 개의 뉴런은 입력의 동일한 [11x11x3] 영역에 연결되지만, 다른 웨이트로 연결된다. 제쳐두고, 실제의 논문에서는 입력 이미지가 224x224라고 나와 있다. 하지만 이는 (224 - 11) / 4 + 1이 정수가 아니기 때문에 분명히 틀린 값이다. 이러한 사실은 ConvNets의 연구에서 많은 사람들을 혼란스럽게하였고, 어떤 이유인지 거의 알려지지 않았다. 다만 3개 여분의 픽셀을 0으로 채웠다고 추측해 볼 수 있다. 

**Parameter Sharing.** 파라미터 공유 방법은 컨볼루션 레이어에서 파라미터 수를 조정하기 위해 사용된다. 위의 예제를 보면 첫 번째 레이어에 55 * 55 * 96 = 290,400개의 뉴런이 있고 각각 11 * 11 * 3 = 363 개의 웨이트와 1 개의 바이어스를 가지는 것을 알 수 있다. 이를 통해 ConvNet의 첫 번째 레이어에서만 290400 * 364 = 105,705,600 개의 파라미터가 생긴다. 분명히 이 값은 매우 크다. 

 하나의 특징이 어떤 공간적 위치 (x, y)에 대해 유용하다면, 다른 위치 (x2, y2)에서 역시 좋은 특성을 보인다고 합당한 가정을 할 수 있으며, 이를 통해 파라미터 수를 극적으로 줄일 수 있다. 즉, 같은 깊이의 뉴런들에 대해 동일한 가중치와 바이어스를 사용하도록 제한한다. 이 파라미터 공유법를 사용하면, 첫 번째 레이어가 이제 96 개의 고유 한 웨이트 세트(각 깊이 슬라이스마다 하나씩)를 가지며, 총 96 * 11 * 11 * 3 = 34,848 개의 고유 웨이트 또는 34,944(예 : +96 바이어스)개의 파라미터를 가진다. 대신 각 깊이 슬라이스의 모든 55 * 55 뉴런이 동일한 파라미터를 사용하게 된다. 실제로 역전파 중, 볼륨의 모든 뉴런은 웨이트에 대한 그래디언트를 계산하지만, 이러한 그래디언트는 각 깊이 슬라이스에 통합되어 하나의 웨이트 세트를 업데이트한다. 
단일 깊이 슬라이스의 모든 뉴런이 동일한 가중치 벡터를 사용하면 CONV 레이어의 순방향 패스는 각 깊이 슬라이스 에서 입력 볼륨과 뉴런 웨이트의 컨볼 루션 으로 계산 될 수 있다 (따라서 Convolutional Layer로 이름지어졌다). 그래서 웨이트 집합을 필터 (또는 커널 )로 지칭하며, 입력과 Convolved된다. 

![](http://cs231n.github.io/assets/cnn/weights.jpeg "weights" "width:600px;float:center;padding-left:10px;")

Krizhevsky et al. 여기에 표시된 96 개의 필터는 크기가 [11x11x3]이고, 각 깊이는 하나의 깊이 슬라이스에서 55 * 55 뉴런에 공유된다. 파라미터 공유에 대한 가정은 비교적 합리적이다. 이미지의 일부 위치에서 수평선을 감지하는 것이 중요 할 경우, 이미지의 변하지 않는 구조로 인해 다른 위치에서도 이러한 성질이 유용해야한다. 따라서 Conv 레이어 출력 볼륨의 55 * 55 개의 별개 위치에서 수평 에지를 감지하기 위해 이러한 필터를 각각 다시 학습 할 필요는 없다. 

때때로 파라미터 공유 가정은 의미가 없을 수도 있다. 특히 ConvNet의 입력 이미지가 특정 중심 구조를 가지고있는 경우에 해당한다. 예를 들어 완전히 다른 특성을 이미지의 한면과 다른면에서 학습해야하는 경우가 있다. 한 가지 실제적인 예는 입력으로 가운데 얼굴이 있는 그림을 들수 있다. 눈이나 머리카락 특유의 특징은 다른 공간적 위치에서 학습 되어야 한다. 이 경우 일반적으로 파라미터 공유라기 보다는, 단순히 로컬 연결(Locally-Connected) 레이어라고 부른다. 

**Locally-Connected Layer.** 위의 내용을 보다 구체적으로 보기위해 코드와 특정 예제를 사용하여 표현할 수 있다. 입력 볼륨  X가 numpy 배열이라고 가정해보자.  그때:

- (x,y) 위치의 깊이 열 (또는 Fibre)는 X[x,y,:]로 접근 할 수 있다. 
- 깊이 슬라이스, 또는 깊이 d의 등가 활성화 맵 역시 X[:,:,d] 로 접근 할 수 있다.

**Conv Layer Example.** 입력 볼륨 X의 크기가 다음과 같다고 가정하자. X.shape: (11,11,4). 그리고 제로 패딩을 사용하지 않는다고 가정하자. $P=0$필터 크기 $F=5$ stride $S=2$일 때, 출력 볼륨의 크기는 (11-5) / 2 + 1 = 4이며 가지며 너비와 높이가 4 인 볼륨이 나온다. 출력 볼륨의 활성화 맵( V)은 다음과 같이 표시된다. 이 예제에서 요소에 대한 계산은 다음과 같다. 

- V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0
- V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0
- V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0
- V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0

numpy에서 * 연산은 배열 사이의 요소 별 곱셈을 나타낸다. 또한 W0웨이트 벡터는 해당 뉴런의 웨이트 벡터이며 b0는 바이어스다. 여기서는 필터 크기가 5이고 입력 부피의 깊이가 4이기 때문에 W0의 크기는 다음과 같이 가정 W0.shape: (5,5,4)된다. 앞에 다룬 일반 신경망에서와 같이 각 점에서 내적을 계산한다. 또한, 동일한 웨이트와 바이어스를 사용(파라미터 공유로 인해)하고 있고 폭을 따라 치수가 2(stride값)씩 증가하는 것을 볼 수 있다. 출력 볼륨의 두 번째 활성화 맵을 생성하려면 다음을 수행해야한다. 

- V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1
- V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1
- V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1
- V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1
- V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 (y축을 따라 이동 하는 예)
- V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 (또는 두 축 모두)

V의 인덱스가 1이며 이는 두번째 활성화 맵임을 뜻한다. 여기서는 이제 다른파라미터( W1)가 사용 되었다. 위 예제에서는 출력 배열의 다른 부분(y 축)을 채우기 위해 Conv Layer가 수행하는 작업을 간략하게 추가했다. 또한 여기에는 표현하지 않았지만, 이러한 활성화 맵은 종종 ReLU와 같은 활성화 함수를 요소별로 적용한다는 점을 상기하자. 

##### Summary, Conv Layer를 요약하면:

- $W_1 \times H_1 \times D_1$의 입력 볼륨 크기 
- 네개의 하이퍼 파라미터 필요:
  필터 수 $K$,
  공간 범위(커널 크기) $F$,
  stride $S$,
  제로 패딩 정도 $P$.
- 출력 볼륨 크기 $W_2 \times H_2 \times D_2$는 아래와 같다. 
  $W_2 = (W_1 - F + 2P)/S + 1$
  $H_2 = (H_1 - F + 2P)/S + 1$
  $D_2=K$
- 파라미터 공유로 각 필터의 웨이트 수는 $F \cdot F \cdot D_1$과 같으며 전체 레이어에서 $(F \cdot F \cdot D_1) \cdot K$개의 웨이트 파라미터와 $K$개의 바이어스 파라미터를 가진다. 
- d 번째 슬라이스(크기가 $W_2 \times H_2$인)는 d번째 칠어와 입력 볼륨을 stride $S$만큼 컨볼루션 연산한 결과에 d 번째 바이어스를 offset한 결과다.
 
일반적으로 $F = 3, S = 1, P = 1$으로 하이퍼 파라미터를 설정한다. 하지만 이러한 하이퍼 파라미터를 가지게 하는 일반적인 규칙이 있다. 아래의 ConvNet 아키텍처 섹션을 참조하라. 

**Convolution Demo.** 아래 그림은 CONV 레이어의 데모를 보여준다. 3D 볼륨은 시각화하기가 어렵기 때문에 각 볼륨(입력 (파란색), 웨이트(빨간색), 출력(녹색))의 각 깊이 슬라이스를 행으로 쌓아 시각화했다. 입력 볼륨의 크기는 $W_1 = 5, H_1 = 5, D_1 = 3$이며,  CONV 레이어 파라미터는 $K = 2, F = 3, S = 2, P = 1$다. 즉 $3 x 3$크기를 가지는 두개의 필터가 stride 2로 컨볼루션 된다. 그러므로 출력 볼륨 크기는 (5 - 3 + 2) / 2 + 1 = 3이다.  또한 $P=1$이 입력 볼륨에 적용되어 바깥 쪽 경계를 0으로 만든다. 아래의 시각화는 출력 액티비티 (녹색)의 각 요소에서 강조 표시된 입력 (파랑)에 필터 (빨간색)를 내적하여 합계 한 다음 결과에 바이어스를 추가하여 반복 계산하는 것을 보여준다. 

![](../assets/imgs/cs231n/9_conv.PNG "weights" "width:600px;float:center;padding-left:10px;")

**Implementation as Matrix Multiplication.**  컨볼루션은 본질적으로 필터와 입력의 로컬 영역 사이에 내적이라는 것을 유의하자. CONV 레이어의 일반적인 구현 방법은 이 사실을 바탕으로 컨벌루션 레이어의 순방향 패스를 다음과 같이 하나의 큰 행렬 곱셈으로 만드는 것이다.

1. 입력 이미지의 로컬 영역은 일반적으로 im2col 이라는 연산을 통해 열로 확장한다. 예를 들어, 입력이 [227x227x3]이고 스트라이드 4에서 11x11x3 필터로 컨볼루션 될 경우, 입력에서 11x11x3 블록의 픽셀을 가져 와서 각 블록을 11 * 11 * 3 = 363 크기의 열 벡터로 확장한다. 이 프로세스를 스트라이드 4로 반복하면 너비와 높이가 (227-11) / 4 + 1 = 55이 되며 따라서, 크기가 [363 x 3025] X_col인 im2col 의 행렬을 만들 수 있다. 열은 확장된 로컬 입력이며 총 55 * 55 = 3025개가 있다. 로컬 입력 영역은 겹치기 때문에 입력 볼륨의 모든 값이 여러 개의 고유 한 열에 복제 된다.
2. CONV 레이어의 웨이트도 비슷하게 행으로 펼쳐집니다. 예를 들어, 크기가 [11x11x3] 인 96 개의 필터가 있으면 W_row크기 [96 x 363]의 행렬이 나온다. 
3. 컨볼루션은 이제 모든 필터와 해당 로컬 입력 위치 사이의 내적을 수행하는 하나의 거대한 행렬 곱셈( np.dot(W_row, X_col))을 계산하는 것과 같다. 이 예에서 이 연산의 출력은 [96 x 3025]이며 각 해당 위치에서 각 필터와의 ​​내적의 결과와 같다.
4. 계산 결과는 최종적으로 출력의 적절한 모양[55x55x96]으로 다시 변형되어야한다.

이 접근법은 입력 볼륨의 일부 값(겹치는 영역)이 여러 번 복제되기 때문에 많은 메모리를 사용할 수 있다는 단점이 있습니다. 그러나 장점으로 Matrix Multiplication을 매우 효율적으로 구현할 수 있다는 것이 있다. (예 : 일반적으로 사용되는 BLAS API). 게다가 동일한 im2col 아이디어를 풀링(Pooling) 작업을 수행하는 데 다시 사용할 수 있다.

**Backpropagation** 컨벌루션 연산에 대한 역방향 패스 (데이터와 가중치 모두)는 또한 컨벌루션이다.(그러나 공간적으로 뒤집힌(flipped) 필터를 사용). 이것은 간단한 1 차원 예제를 통해 쉽게 유도할 수 있다. (여기서는 다루지 않음).



**1x1 convolution.** [Network in Network](http://arxiv.org/abs/1312.4400)에서 처음 등장한 1x1 컨볼루션은 여러 논문에서 사용된다. 신호처리 전공의 사람들은 처음 1x1 컨볼루션을 보면 혼란을 느낀다. 일반적으로 신호는 2 차원이기 때문에 1x1 컨볼 루션은 의미가 없기 때문이다.(각 점마다 스케일링). 그러나 ConvNets에서는 3 차원 볼륨에서 작동한다는 것과 필터는 항상 입력 볼륨의 전체 깊이까지 확장된다는 점을 떠올리면 의미가 없지 않다는 알 수 있다. 예를 들어, 크기 [32x32x3] 입력에 대해 1x1 컨볼루션을 수행하면 효율적으로 3 차원 내적(입력의 깊이가 3이므로)을 수행 할 수 있다.

**Dilated convolutions.** 최근의 개발 된 논문([Fisher Yu와 Vladlen Koltun](https://arxiv.org/abs/1511.07122))에서는 Conv 레이어에 팽창(Dilation) 이라고 불리는 하나의 하이퍼 파라미터가 추가되었다. 지금까지는 공간적으로 이어져 있는 CONV 필터에 대해서만 설명했다. 그러나 각 셀 사이에 간격이 있는 필터를 사용할 수 있다 (Dilation이라고 부름). 예를 들어, 한 차원에서 w크기 3 의 필터 x는 다음과 같은 입력을 계산한다. w[0]*x[0] + w[1]*x[1] + w[2]*x[2] 이것은 팽창 값이 0인 경우다. 팽창 값이 1인 경우, 필터는 대신 w[0]*x[0] + w[1]*x[2] + w[2]*x[4] 즉, 로컬(수용) 입력 영역 사이에 1의 간격이 있다. 일부 설정에서 Dilation을 적용하는 것은 유용할 수 있다. 입력에 대한 공간 정보를 더 적은 레이어로 훨씬 더 적극적으로 병합 할 수 있기 때문이다. 예를 들어, 두 개의 3x3 CONV 레이어를 서로 겹쳐 쌓는다면 두 번째 레이어의 뉴런이 입력의 5x5 패치의 함수임을 볼 수 있다. ( 이 뉴런의 유효 수용필드는 5x5). Dilated 컨볼루션을 사용하면 이러한 수용 필드는 훨씬 더 빠르게 확장 될 것이다. 

##### Pooling Layer

ConvNet 아키텍처에서 연속하는 Conv 레이어 사이에 풀링 레이어를 삽입하는 것은 일반적이다. 그 함수는 공간적(W, H) 크기를 점차적으로 줄여서 네트워크 파라미터와 계산량을 감소시켜 오버 피팅을 제어한다. 풀링 레이어는 입력의 모든 깊이 슬라이스에서 독립적으로 작동하고, 보통 MAX 함수를 통해 공간적으로 크기를 조정한다. 가장 일반적인 형태는 크기가 2x2 인 필터가 적용된 풀링 레이어로, 입력의 깊이 슬라이스를 폭과 높이에 따라 2씩 스트라이드하며 다운 샘플링하여 75%의 활성화노드를 제거한다. 이 경우 모든 MAX 연산은  4 개의 숫자(깊이 슬라이스에서 2x2 영역) 중 가장 큰 값을 취한다. 깊이 치수는 변경되지 않는다. 일반적으로 풀링 레이어는 다음과 같다. 

- 볼륨 크기 $W_1 \times H_1 \times D_1$를 입력으로 받음
- 두 하이퍼 파라미터 필요 
  풀링할 영역 $F$
  스트라이드 $S$
- 출력 볼륨 크기 $W_2 \times H_2 \times D_2$는 다음과 같다.  
  $W_2 = (W_1 - F)/S + 1$
  $H_2 = (H_1 - F)/S + 1$
  $D_2 = D_1$
- 입력에 대한 고정 함수이므로 파라미터는 없다. 
- 일반적으로 풀링 레이어에 제로 패딩을 사용하지는 않는다. 

실제 Max 풀링 레이어는 두 가지 형태가 자주 사용된다. 오러래핑 풀링이라고 불리는 $F = 3, S = 2$인 경우, 보다 일반적인 $F = 2, S = 2$인 경우가 있다. 이것 보다 더 큰 풀링 사이즈를 사용하는 것은 구조를 해칠 우려가 있다. 


**General pooling.** MAX 풀링 외에도, 평균 풀링 또는 L2-Norm 풀링과 같은 다른 함수를 통해 풀링을 수행 할 수도 있다. 평균 풀링은 예전부터으로 자주 사용되었지만, 실제 MAX 풀링이 더 잘 작동하기 때문에 선호도가 떨어졌다. 

![](http://cs231n.github.io/assets/cnn/pool.jpeg "pool" "width:230px;float:center;padding-left:10px;")![](http://cs231n.github.io/assets/cnn/maxpool.jpeg "maxpool" "width:370px;float:center;padding-left:10px;")

풀링 레이어는 입력 볼륨의 각 깊이 슬라이스를 공간적으로 다운 샘플링한다.  왼쪽 : 이 예에서 크기 [224x224x64]의 입력 볼륨은 필터 크기 2, 스트라이드 2로 풀링 되어  출력 볼륨은 [112x112x64]크기를 가진다. 여기서 볼륨 깊이는 유지된다. 오른쪽 : 가장 일반적인 다운 샘플링 연산은 max이며, Max 풀링을 수행하며, 여기서는 스트라이드는 2다. 즉, 각각의 4 개의 숫자 (2x2 영역)에서 최대값을 취한다. 

**Backpropagation.**  backpropagation 장에서 max (x, y) 연산에 대한 역방향 패스는 순방향 패스에서 가장 높은 값을 가진 입력으로 단순히 그라디언트를 전달한다는 것을 떠올려 보자. 따라서 풀링 레이어의 순방향 통과 중에는 최대 활성화 값(종종 스위치 라고도 함)의 인덱스를 추적하여 역전파 동안 그라디언트 전달 하는 것이 일반적인 방법이다. 

**Getting rid of pooling.** 많은 사람들은 풀링 작업을 싫어하며, 풀링 없이 모델을 설계 할 수 있다고 여긴다. 예를 들어, Simplicity for Striving : All Convolutional Net 은 풀링 레이어없이, 연속적인 CONV 레이어로만 구성된 아키텍처를 사용하도록 제안한다. 파라미터 수를 줄이기 위해 CONV 레이어에서보다 큰 스트라이드를 사용하는 것이 좋다. 풀링 레이어를 없애는 것은 또한 VAE (variational autoencoders) 또는 GAN (generative adversarial networks)과 같은 생성 모델을 학습하는데 중요하다. 나중에 나오는 아키텍처는 풀링 레이어가 거의 없을 것이다. 

##### Normalization Layer

많은 유형의 정규화 레이어는 ConvNet 아키텍처에서 사용하기 위해 제안되었으며, 때로는 생물학적 뇌 모델에서 관찰되는 억제 구조(inhibition schemes)를 구현하려는 의도로 사용되기도 한다. 그러나, 실제 이러한 레이어의 효과가 거의 없기 때문에 자주 사용되지는 않는다. 정규화의 다양한 유형들에 대해서는 Alex Krizhevsky의 cuda-convnet 라이브러리 API에 대한 설명을 참조하라. 

##### Fully-connected layer
완전 연결 레이어의 뉴런은 일반 신경 네트워크에서 볼 수 있듯이 이전 레이어의 모든 활성화 노드에 완전이 연결되어 있다. 따라서 그들의 출력 활성화 노드는 행렬 곱셈과 바이어스 오프셋으로 계산 될 수 있다. 자세한 내용은 앞선 신경망 섹션을 참조하라. 

##### Converting FC layers to CONV layers
FC와 CONV 레이어의 유일한 차이점은 CONV 레이어의 뉴런(노드)는0 입력의 로컬 영역에만 연결된다는 것과 CONV 볼륨의 많은 뉴런이 파라미터를 공유한다는 점이다. 그러나 두 레이어의 출력 뉴런들은 여전히 ​​내적을 통해 계산 되므로 기능적 형태는 일치한다. 따라서 FC 레이어와 CONV 레이어를 서로 변환 할 수 있다.

- 모든 CONV 레이어에 대해 동일한 전달 함수을 구현하는 FC 레이어를 구현할 수 있다. 웨이트 행렬은 매우 크며, 대부분 0의 값을 가질 것이다. 입력의 로컬영역과 연결된 특정 블록만 값을 가지는데 파라미터 공유로 인해 많은 블록의 웨이트는 같은 값을 가딘다. 
- 또한, 반대로 모든 FC 레이어를 CONV 레이어로 변환 할 수 있다. 입력 볼륨의 크기가 $7 \times 7 \times 512$이며, $K=4096$인 FC 레이어는 $F = 7, P = 0, S = 1, K = 4096$ 파라미터를 가지는 Conv레이어로 동일하게 표현 할 수 있다. 필터 크기를 입력 볼륨의 크기와 정확히 일치하도록 설정하여 출력은 단순히 $1 \times 1 \times 4096$를 가지며, 단일 깊이 열 만 입력 볼륨에 "맞기" 때문에 위의 FC 레이어와 동일한 결과를 제공한다. 

**FC->CONV conversion.** 위 두 가지 변환 중 FC 레이어를 CONV 레이어로 변환하는 기능은 실제 유용히 사용된다. 224x224x3 이미지를 사용하는 ConvNet 아키텍처에 대해 연속 된 CONV 레이어와 POOL 레이어를 사용하여 입력 이미지를 7x7x512 크기의 활성화 노드 볼륨으로 축소한다. ( 나중에 볼 AlexNet 아키텍처에서는 이러한 작업을 수행한다. 5개의 풀링 레이어는 입력을 공간적으로 2 배씩 다운 샘플링하여 최종 크기가 224/2/2/2/2/2 = 7이되도록한다.) 그 다음 AlexNet은 4096 크기의 두 FC 레이어와 마지막으로 클래스 스코어를 계산하는 1000 개의 뉴런을 가진 최종 FC 레이어를 둔다. 위에서 설명한 방법으로 세 FC 레이어를 각각 CONV 레이어로 변환 할 수 있다.

- [7x7x512] 볼륨을 입력으로 받는 첫 번째 FC 레이어를 필터 크기  $F=7$인 CONV 레이어로 바꾼다. 이는 출력 볼륨 [1x1x4096]을 제공한다. 
- 두 번째 FC 레이어를 필터 크기  $F=1$인 CONV 레이어로 바꾼다. 이는 동일한 크기의 출력 볼륨 [1x1x4096]을 제공한다. 
- 마지막 FC 레이어 역시 필터 크기  $F=1$인 CONV 레이어로 바꾼다. 여기서는 $K=1000$이며, 따라서 출력 볼륨은 [1x1x1000]의 크기를 가진다.

이러한 FC 레이어에서 CONV 레이어로의 변환은 실제적으로 웨이트 행렬의 변형를 유발한다. 이 변환을 통해 단일 순방향 패스에서 큰 이미지의 공간적 위치에서 원본 ConvNet을 매우 효율적으로 "슬라이드"할 수 있다.

예를 들어, 224x224 이미지가 [7x7x512] 크기의 볼륨을 제공하는 위 아키텍쳐에서(32배 축소), 이 아키텍처를 통해 384x384 크기의 이미지를 전달하면, 384/32 = 12 이므로 [12x12x512] 크기의 출력 볼륨이 나온다. 방금 FC 레이어에서 변환 한 다음 3 개의 CONV 레이어를 통하면, (12 - 7) / 1 + 1 = 6이므로 최종 적으로는 [6x6x1000] 크기의 출력을 제공한다. 본래 [1x1x1000] 크기의 단일 벡터 클래스 스코어 대신, 384x384 이미지에서는 6x6 클래스 스코어를 가지는 벡터를 얻는다. 

*384x384 이미지의 224x224 크기로 32 픽셀 스트라이드 크롭한 입력을 각각 독립적으로 ConvNet (FC 레이어 포함)에 전달하여 실행하며, 변환 된 ConvNet을 한 번 실행할 때와 동일한 결과를 얻을 수 있다.*

당연히 변환 된 ConvNet을 한 번 순방향 연산하는 것은 36개 영역(6x6)에 대한  연산을 공유하기 때문에, 원래 ConvNet을 각 36개 위치에서 반복하는 것보다 훨씬 효율적이다. 이 트릭은 실제로 더 나은 성능을 위해 종종 사용된다. 예를 들어, 더 큰 이미지를 입력으로 받는 ConvNet을 사용하여 공간 영역(n x n)에서 클래스 스코어를 얻은 다음 클래스 스코어를 평균내는 것이 일반적이다. 

마지막으로 원본 ConvNet을 사용하고 싶지만 32 픽셀보다 작은 스트라이드 적용하려면 어떻게해야할까? 여러 번 실행하는 것을 통해 이를 수행 할 수 있다. 예를 들어, 16 픽셀의 스트라이드를 사용한다면, 변환 된 ConvNet을 두 번 실행한 볼륨의 결합을 통해 구현 할 수 있다. 첫 번째는 원본 이미지, 그리고 두 번째는 공간적(W, H)으로 16 픽셀만큼 이동한 이미지.

- Net Surgery의 IPython Notebook은 변환을 수행하는 방법을 실제 코드에서 (Caffe를 사용하여) 보여준다. 

##### ConvNet Architectures

Convolutional Networks는 일반적으로 CONV, POOL (달리 명시하지 않는 한 Max pool을 가정 함) 및 FC (완전 연결의 약자) 세 레이어 타입으로만 구성된다. RELU 활성화 함수를 elementwise non-linearity를 ​​적용하는 레이어로 사용한다. 이 절에서는 전체 ConvNets을 형성하기 위해 이러한 레이어를 쌓는 방법을 논의 한다. 

###### Layer Patterns

ConvNet 아키텍처의 가장 일반적인 형태는 몇 개의 CONV-RELU 레이어를 쌓고 POOL 레이어를 그 아래 둔다. 이미지가 공간적으로 충분히 작은 크기로 병합 될 때까지이 패턴을 반복한다. 어느 정도 쌓은 다음, 완전 연결 레이어로 전환하는 것이 일반적이다. 마지막 완전 연결 레이어에는 클래스 스코어와 같은 출력을 생성한다. 즉, 가장 일반적인 ConvNet 아키텍처는 다음과 같은 패턴을 따른다. 

INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC

여기서는 *반복을 나타내며,  POOL?의 물음표는 풀링 레이어를 선택적으로 두는 것을 나타낸다. 여기서 N >= 0(보통 N <= 3), M >= 0, K >= 0(보통 K < 3)의 값을 가진다. 예를 들어, 몇몇 일반적인 ConvNet 아키텍처는 다음과 같은 패턴을 따른다. 

- INPUT -> FC 단순 선형 분류기의 구현. 여기서 N = M = K = 0.
- INPUT -> CONV -> RELU -> FC
- INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC. 여기에서는 각 CONV 레이어당 하나의 POOL 레이어가 있음을 알 수 있다.
- INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC여기에서는 모든 POOL 레이어 앞에 두 개의 CONV 레이어가 겹쳐져 있다. 여러 개의 스택 된 CONV 레이어는 POOL레이어의 파괴적인 공각 축소 작업 전에 입력 볼륨의 더 복잡한 특성을 잡아낼 수 있기 때문에 크고 깊은 네트워크의 경우 일반적으로 사용되는 좋은 아이디어다.

하나의 큰 수용 필드(receptive field, 커널크기)를 가진 CONV 레이어 보다 작은 필터를 가진 CONV의 스택을 선호. 3개의 3x3 CONV 레이어를 쌓는다고 가정 해보다. (물론 그 사이에는 ReLU와 같은 비선형 레이어가 있다). 이 배열에서 첫 번째 CONV 레이어의 각 뉴런은 입력 볼륨의 3x3 영역을 본다. 두 번째 CONV 레이어의 뉴런은 첫 번째 CONV 레이어의 3x3 영역과 연결되므로, 입력 볼륨은 여기서 5x5 영역으로 확장하여 보여진다.  유사하게 세 번째 CONV 레이어의 뉴런은 두 번째 CONV 레이어의 3x3 영역과 연결되므로, 입력 볼륨의 7x7 영역을 본다. 세 3x3 CONV 레이어를 쌓는 대신에 7x7 수용 필드가 있는 단일 CONV 레이어 만 사용한다고 가정해보자. 이 뉴런은 입력 범위의 수용 필드 크기가 공간적으로(7x7)에서 동일하지만 몇 가지 단점이 있다. 첫째, 이 뉴런은 입력에 대해 선형 함수 만 계산할 것이며, 앞선 세 개 스택의 CONV 레이어에서는 비선형성을 포함하고 있기 때문에 여기서 더 많은 표현이 가능하다. 모든 볼륨이 $C$ 채널을 가지고 있다고 가정하면, 단일 7x7 CONV레이어를 사용하는 경우 $C \times (7 \times 7 \times C) = 49 C^2$개의 파라미터를 가지며, 세개의 3x3 CONV 레이어를 쌓는 경우 $3 \times (C \times (3 \times 3 \times C)) = 27 C^2$개의 파라미터만 가진다. 직관적으로, 큰 필터를 가진 하나의 CONV 레이어를 갖는 것과 대조적으로 작은 필터로 CONV 레이어를 쌓으면 더 적은 파라미터로 입력의 특성을 더 잘 표현할 수 있다. 실 사용에서 단점은 backpropagatio에서 모든 CONV 레이어 결과를 저장하기 위해 더 많은 메모리가 필요할 수 있다.

**Recent departures.** 단순히 차례대로 일직선으로 레이어는 쌓는 일반적인 패러다임은 최근 Google의 인셋션 아키텍처 및 Microsoft Research Asia의 현재 (최신) Residual 네트워크에서 깨졌다는 것을 주목해야한다. 이 두 가지 (아래 세부 정보 참조)는 보다 복잡하고 다양한 연결 구조를 가진다. 

**In practice: use whatever works best on ImageNet.**  

아키텍쳐 구성에 여려움을 느낀다면, 90% 이상의 응용 프로그램에서는 이러한 걱정을 할 필요가 없다는 것을 알게되었을때 기뻐할 것이다. 위 말을 "영웅이 되지 말라 "고 요약한다. 어떤 문제를 해결하기 위해 자신 만의 아키텍처를 사용 할 필요는 없다. 그 대신 현재 ImageNet에서 가장 잘 작동하는 아키텍처를 살펴보고 미리 학습 된 모델을 다운로드하여 자신만의 데이터로 미세 조정해야한다. 처음부터 ConvNet을 디자인 하거나, 학습 시킬 필요는 없다. Deep Learning School 에서 이 점을 다시 지적 한 바있다. 

###### Layer Sizing Patterns

위에서는 ConvNet의 각 레이어에 사용 된 일반적인 하이퍼 파라미터에 대해서는 언급하지 않았다. 먼저 아키텍처 크기 설정에 대한 일반적인 경험을 설명한 다음, 표기법에 대해 논해본다. 

**input layer** (즉, 입력 이미지를 포함하는)는 2로 여러번 나누어 져야한다. 일반적인 숫자는 32(예 : CIFAR-10), 64,96 (예 : STL-10) 또는 224 (예 : 일반적인 ImageNet ConvNet), 384 및 512다.

**conv layers** 는 작은 필터 (예를 들면 3 × 3 또는 5 × 5의 대부분)을 사용하며, stride $S=1$이다. 여기서 패딩 값을 설정하여 출력 볼륨이 입력 볼륨과 같은 크기를 가지도록 입력을 0으로 채운다. $F=3$일 때 $P=1$이면 입력과 출력은 같은 크기를 가진다.  $F=5$일 때 $P=2$며, 일반적으로 $P = (F - 1) / 2$일때 입력과 출력의 크기는 같다. 만약 매우 필터사이즈로 매우 큰 값(예, 7x7)을 사용해야 한다면, 보통 입력과 연결된 첫 번째 conv레이어에 설정한다.  

**pool layers**  입력의 공간 차원을 다운 샘플링한다. 가장 일반적인 설정은 2x2 수용 필드($F = 2$)와 stride가 2인($S=2$) 있는 max-pooling을 사용하는 것이다. 이 함수는 입력 볼륨에서 활성화 노드의 75 %를 삭제한다. (폭과 높이 모두 2로 다운 샘플링하기 때문에). 다른 약간 덜 일반적인 설정은 2의 stride를 가진 3x3 수용 필드를 사용하는 것이다. 풀링시 값이 너무 손실되기 때문에 MAX 풀링에서 3보다 큰 수용 필드를 사용하는 일은 매우 드물다. 이 경우 대부분 성능 저하를 가져온다. 

**Reducing sizing headaches.** 위에서 다룬 방법에서 CONV 레이어는 입력의 공간 크기를 보존하고, POOL 레이어에서만 볼륨을 공간적으로 다운 샘플링하기 때문에 위의 방식이 깔끔하다. 사이즈를 조절하는 다른 방법으로 1보다 큰 스트라이드를 사용하거나 CONV 레이어에서 입력을 제로 패드하지 않을 수 있지만, 이 경우 CNN 아키텍처 전체에서 입력 볼륨을 매우 신중하게 추적해야하며 모든 스트라이드와 필터가 작동하는지, 아키텍처가 대칭적으로 잘 연결되어 있는지 확인해야한다. 

**Why use stride of 1 in CONV?**   Stride를 작은 값으로 설정하는 것은 실제로 더 잘 작동한다.  또한 앞서 언급 한 바와 같이 스트라이드를 1로 설정한 다는 것은, 모든 다운 샘플링을 풀링 레이어에 맡기며, CONV 레이어는 입력 볼륨을 깊이 방향으로만 변경한다. 

**Why use padding?** 제로 패딩을 통해 CONV 레이어를 통과한 후에도 공간 크기를 일정하게 유지하는 것도 있지만, 이 외에도 실제로 성능 향상을 가져다 준다. CONV 레이어가 입력을 제로 패드하지 않고 컨볼루션을 수행하는 경우 볼륨의 크기는 각 CONV 레이어를 통과 한 다음 조금 줄어들며, 따라서 테두리의 쪽 영역의 정보는 매우 빨리 사라지게 된다. 

** based on memory constraints.** 위에 제시된 방법에 따라 레이어를 쌓으면, 메모리 양이 매우 빠르게 증가 할 수 있다. 예를 들어, 각각 64 개의 필터가있는 3 개의 3x3 CONV 레이어로 224x224x3 이미지를 필터링하고 1을 채우면 크기 [224x224x64]의 세 활성화 노드 볼륨을 생성한다. 총 약 1 천만 개의 활성화 노드와 72MB의 메모리 (이미지 당, 활성화 및 그라디언트 모두)가 발생한다. GPU는 종종 메모리 병목 현상이 발생하기 때문에 이를 방지하기위해 타협점을 찾아야 할 경우도 있다. 실제로 사람들은 네트워크의 첫 번째 CONV 레이어에서 타협하기를 선호한다. 예를 들어, ZF 네트워크에서는 첫 번째 CONV 레이어에서 필터 크기는 7x7이고 스트라이드는 2를 사용했다. 또 다른 예로, AlexNet은 11x11의 필터 크기와 4의 스트라이드를 사용한다. 

##### Case studies
다음과 같은 이름을 가지는 여러 일반적인 컨볼루션 네트워크 아키텍처가 있다. :

- LeNet . 1990년대 Yann LeCun은 ConvNet의 첫번째 성공적인 응용프로그램들을 개발했으며, 이 중 가장 잘 알려진 것은 우편 번호, 숫자 등을 분석하는데 사용 된 [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) 아키텍처다.
- AlexNet .  Alex Krizhevsky, Ilya Sutskever, Geoff Hinton에 의해 개발된 [AlexNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)은 컴퓨터 비전 분야에서 Conv 네크워크를 대중화 했다. AlexNet은 2012 년에 ImageNet ILSVRC challenge에 제출되었으며 2등과 큰 격차(top 5 error 16%, 준우승 26%)로 우승했다. LeNet과 매우 유사한 아키텍처를 가졌지만 더 깊고 커졌으며 컨볼루션 레이어를 연속을 쌓은 구조를 가지고 있다. (이전에는 항상 각 CONV 레이어 아래 POOL 레이어가 이어지는 것이 일반적이였다).
- ZF Net . ILSVRC 2013 수상자는 Matthew Zeiler와 Rob Fergus의 Convolutional Network 였으며, [ZFNet](http://arxiv.org/abs/1311.2901) ( Zeiler & Fergus Net의 약어) 로 알려져 있다. 특히 아키텍처 중간의 콘볼루션 레이어의 크기를 키우고, 첫 번째 레이어의 스트라이드과 필터 크기를 작게하는 등 하이퍼 파라미터 조정을 통해 AlexNet을 개선했다. 
- GoogLeNet . ILSVRC 2014 수상자는 Google의 Szegedy et. al.가 개발한 Convolutional Network며, 네트워크의 파라미터 수를 획기적으로 줄인 Inception Module의 개발이 주된 공로다. (파라미터 수는 4M, AlexNet의 경우 60M). 또한 이 논문에서는 완전 연결 레이어 대신 평균 풀링을 사해서 많은 파라미터를 줄였다. GoogLeNet에는 최신 [Inception-v4](http://arxiv.org/abs/1602.07261) 등 몇 가지 추가 버전이 있다 .
- VGGNet . ILSVRC 2014의 준우승은 Karen Simonyan과 Andrew Zisserman이 [VGGNet](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)으로 알려진 네트워크며, 네트워크의 깊이가 좋은 성능을 위한 중요한 요소임을 보여줬다. 최종적으로 사용한 네트워크는 16 개의 CONV / FC 레이어를 포함하고 있으며, 처음부터 끝까지 3x3 컨볼루션 및 2x2 풀링 만 수행하는 매우 동질적인 아키텍처가 특징이다. 이 네트워크의 pretrained 모델은 Caffe에서 플러그 앤 플레이에 사용할 수 있다. VGGNet의 단점은 동작하는데 많은 비용이 들고 많은 메모리와 파라미터(140M)를 사용한다는 것이다. 이러한 파라미터의 대부분은 첫번째 완전 연결 레이어에 있으며, 성능 저하없이 이 FC 계층을 제거(Conv 레이어의 파라미터만 사용)하여, 실제 필요한 파라미터의 수를 크게 줄일 수 있다.
- ResNet . Kaiming He et al.에 의해 개발 된 [Residual Network](http://arxiv.org/abs/1512.03385)가 ILSVRC 2015을 우승했다. 이 네트워크의 특징은 skip connections과 많은 Batch Normalization 사용이다. 또한 이 아키텍처는 네트워크의 끝부분의 완전 연결 레이어를 제거하였다. Kaiming의 프레젠테이션(비디오 , 슬라이드)과 토치에서 구현된 이 네트워크 최근 실험을 참조 할 수 있다. ResNets은 현재 컨볼루션 뉴럴 네트워크 (Convolutional Neural Network) 중 가장 최신 모델이며, 실제 기본 선택 모델이다. (2016년 5월 10일 기준). 특히 원래 아키텍처를 조정한 보다 최신 논문도 참조하라. Kaiming He 외. 깊은 잔류 네트워크의 신원 매핑 (2016 년 3 월 발행).

**VGGNet in detail.** VGGNet을 더 자세히 살펴보자. VGGNet은 스트라이드 1과 패드 1로 3x3 컨벌루션을 수행하는 CONV 레이어와, 스트라이드 2 (패딩 없음)로 2x2 최대 풀링을 수행하는 POOL 레이어로 구성된다. 프로세싱의 각 단계 마다 피쳐 크기를 기록하고 피쳐 크기와 총 웨이트 파라미터 수를 추적 할 수 있다.

```python
INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864
POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456
POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0
FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448
FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216
FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000

TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)
TOTAL params: 138M parameters
```
컨볼루션 네트워크에서 흔히 볼 수 있듯이 대부분의 메모리(및 계산 시간)는 초반의 CONV 레이어에서 사용되며, 대부분의 파라미터는 마지막 FC 레이어에 있다. 이 경우, 첫 번째 FC 레이어는 총 140M개 웨이트 파라미터 중 100M 개를 가지고 있다. 

###### Computational Considerations

ConvNet 아키텍처를 구축 할 때 주의해야할 가장 큰 병목현상(bottleneck)은 메모리 병목현상이다. 최신 GPU는 3/4/6GB 메모리 한도를 가지고 있으며, 가장 좋은 GPU는 약 12GB의 메모리를 가지고 있다. 추적해야 할 세 가지 주요 메모리는 아래와 같다. 

- 중간 볼륨 크기: 이것은 ConvNet의 모든 레이어에서 activation(활성화) 노드 및 그라디언트(동일한 크기) 수다. 일반적으로 대부분의 활성화 노드는 ConvNet의 초반 레이어에 있다 (즉, 첫 번째 Conv 레이어). 이것들은 backpropagation에서는 모두 필요하기 때문에 전부 메모리에 저장 되지만, 테스트시에는 현재 활성화 노드만 저장하고, 다음 레이어로 넘어 가면 이전 레이어의 활성화 노드를 삭제함으로써 많은 양을 줄일 수 있다.
- 파라미터 수(크기):  momentum, Adagrad, 또는 RMSProp을 사용하여 backpropagation하는 경우 많은 수의 네트워크 파라미터, 그 것의 그라디언트, 그리고 단계적 캐시는 메모리에 남아 있는다. 따라서 파라미터 벡터가 저장된 메모리 량은 일반적으로 최소한 3 배 정도 곱해야한다.
- 모든 ConvNet 구현시 이미지 데이터 배치 및 augmented 버전과 같은 여러 잡다한 메모리 또한 고려 해야한다.  

저장해야 할 값들의 총량(활성화 노드, 그라디언트 및 기타)을 대략적으로 추정한 다음, 그 수를 GB 단위의 크기로 변환해야한다. 개수를 가져 와서 4를 곱하여(floating point이 4바이트, double precision의 경우 8 바이트) 몇 바이트인지 계산한 다음 이 값을 KB, MB, GB와 같은 메모리 값으로 바꾸기 위해 1024로 여러 번 나눈다. 메모리가 모자라는 경우 일반적으로 사용되는 경험적 방법은 배치의 크기를 줄이는 것이다. 왜냐하면 활성화노드가 대부분의 메모리를 차지하기 때문이다. 

##### Additional Resources

구현과 관련된 추가 리소스 :

- [Soumith benchmarks](https://github.com/soumith/convnet-benchmarks) for CONV performance
- [ConvNetJS CIFAR-10 demo](http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html) 를 통해 ConvNet 아키텍처를 가지고 놀듯 디자인 하며, 결과와 계산을 브라우저에서 실시간으로 볼 수 있다.
- [Caffe](http://caffe.berkeleyvision.org/), 인기 있는 ConvNet library 중 하나. 
- State of the art [ResNets](http://torch.ch/blog/2016/02/04/resnets.html) in Torch7