---
title: [cs231n 번역] 1 Image Classification
category: cs231n
excerpt: |
 본 포스팅은 컴퓨터 비전을 공부하지 않은 사람에게 이미지 분류(Image Classification) 문제 및 데이터 기반 방법론(data-driven approach)를 소개한다. 목차는 아래와 같다.  


feature_text: |
  ## Stanford CS class CS231n: 
  
  Convolutional Neural Networks for Visual Recognition 강의 번역

  ref: [http://cs231n.github.io/](http://cs231n.github.io/ "cs231n")

feature_image: "https://picsum.photos/2560/600/?image=765"
image: "https://picsum.photos/2560/600/?image=765"
comment: true
---

본 포스팅은 컴퓨터 비전을 공부하지 않은 사람에게 이미지 분류(Image Classification) 문제 및 데이터 기반 방법론(data-driven approach)를 소개한다. 목차는 아래와 같다. :

- 이미지 분류, 데이터 기반 방법론, 파이프 라인
- Nearest Neighbor 분류기
- k-Nearest Neighbor
- Validation set, 교차 유효성(Cross validation) 검사, Hyperparameter 조정
- Nearest Neighbor의 장단점
- 개요
- 요약 : 실제 kNN 적용
- 더 읽을거리

#### 이미지 분류

**동기**: 이 섹션에서는 이미지 분류 문제를 소개한다. 이 문제는 입력 이미지를 고정 된 카테고리 집합의 레이블 하나에 매칭하는 작업이다. 이것은 단순하지만 매우 다양한 응용 프로그램에 실용적으로 사용되는 Computer Vision의 핵심 문제 중 하나다. 또한 나중에 볼 수 있듯이 컴퓨터 비전의 여러 문제를(예 : 개체 감지, 분할)을 이미지 분류로 축소 할 수 있다.

**예** . 예를 들어, 아래 이미지에서 이미지 분류 모델은 단일 이미지를 가져 와서 다음 4개 레이블{cat, dog, hat, mug} 과 매칭 될 확률을 지정한다 . 아래 그림에서 볼 수 있듯이 컴퓨터에서 이미지는 하나의 3 차원 숫자 배열로 표시된다. 아래 고양이 이미지는 너비가 248 픽셀이고 높이가 400 픽셀이며 빨강, 녹색, 파랑 (또는 간단히 RGB)의 세 가지 색상 채널이 있다. 따라서 이미지는 248 x 400 x 3, 총 297,600 숫자로 구성된다. 각 숫자는 0 (검정)에서 255 (흰색)까지의 정수다. 우리의 목표는 고양이사진을 표현하는 수 십만개의 숫자를 "고양이" 와 같은 단일 레이블로 바꾸는 것 이다.

![](http://cs231n.github.io/assets/classify.png "cat" "width:600px;float:center;padding-left:10px;")

mage Classification (이미지 분류)의 작업은 주어진 이미지에 대한 단일 레이블 (또는 각 레이블에 대한 확률)을 예측하는 것이다. 이미지 크기는 너비 x 높이 x 3 인 0에서 255까지의 3 차원 배열이다. 3은 빨강, 녹색, 파랑의 세 가지 색상 채널을 나타낸다.

**어려움** 인간이 사진이 무엇을 뜻하는지(예 : 고양이)을 인식하는 작업은 어렵지 않지만, 컴퓨터 비전 알고리즘의 관점에서는 고려해야 할 문제들이 있다. 아래의 목록에서 이미지는 3 차원 밝기 값 배열로 표현됨을 염두해야한다. 

- Viewpoint variation(시점의 다양성). 객체의 단일 인스턴스는 카메라와 위치에 따라 다양한 시점으로 표현된다. 
- Scale variation(크기의 다양성). 레이블은 종종 크기의 변화를 나타낸다. (이미지내에서 크기 뿐만 아니라 실제 크기)
- Deformation(변형). 상당수 입력 대상은 강체가 아니며 다양한 형태로 변형 될 수 있다.
- Occlusion(가림). 관심 대상의 물체를 가릴 수 있다. 때로는 객체의 작은 부분(소수의 픽셀)만 표시 될 수 있다.
- Illumination conditions(조명 조건) . 조명에 따라 픽셀 수준에서 값이 크게 변한다. 
- Background clutter(배경 혼란). 관심 대상이 배경에 섞여 식별하기 어려울 수 있다.
- Intra-class variation(클래스 내 다양성). 관심 클래스는 종종 의자 와 같이 상대적으로 광범위한 특성(형태, 색)을 지닐 수 있다. 이러한 개체에는 여러 가지 특성이 있으며 각 개체는 고유 한 모양을 가진다.

좋은 이미지 분류 모델은 위와 같은 다양성에 강인해야하며, 내부 클래스 간 유사도에 대한 민감도를 지니고 있어야 한다. 

![](http://cs231n.github.io/assets/challenges.jpeg "difficult" "width:600px;float:center;padding-left:10px;")

**데이터 중심 접근 방식** 이미지를 서로 다른 카테고리로 분류하는 알고리즘을 작성하려면 어떻게 해야할까? 예를 들어 숫자 배열을 정렬(Sorting)하는 알고리즘을 작성하는 것과는 달리, 이미지에서 고양이를 식별하는 알고리즘을 작성하는 방법은 명확하지 않다. 따라서 코드에서 알고리즘을 직접 작성하는 대신, 우리의 접근법은 어린이들의 접근법과 다르지 않다. 우리는 컴퓨터에 많은 예제를 제공 할 것이다. 각 클래스를 학습 한 다음이 예제를 보고 각 클래스의 시각적 모양에 대해 학습하는 학습 알고리즘을 개발할 수 있다. 이러한 접근 방식을 데이터 기반 접근 방식 이라고한다. 왜냐하면 먼저 학습 데이터 집합을 축적해야하기 때문이다. 아래에 레이블과 학습데이터(이미지)가 있다. 


![](http://cs231n.github.io/assets/trainset.jpg "data" "width:600px;float:center;padding-left:10px;")

네 가지 시각적 범주에 대한 예제 학습 데이터셋. 실제 우리는 수천 개의 카테고리와 각 카테고리당 수십만 개의 이미지를 가질 수 있다.

**이미지 분류 파이프 라인** 이미지 분류의 작업은 단일 이미지를 나타내는 픽셀 배열을 가져 와서 레이블을 지정하는 것이다. 우리의 완벽한 파이프 라인은 다음과 같이 공식화 될 수 있다 :

- 입력 : 입력은 각각 다른 K 개의 클래스 중 하나로 레이블링 된 N 개의 이미지 세트로 구성된다 . 이 데이터를 학습 데이터 집합(training set)이라고 합니다.
- 학습 : 우리의 목표는 training set을 사용하여 모든 클래스의 어떻게 표현되는 지를 배우는 것이다. 이 단계를  training a classifier, or learning a model과 같이 부른다. 
- 평가 : 분류기의 품질 평가를 위해 이전에 한번도 보지 못한 새로운 이미지 집합에 대한 레이블을 예측하도록 요청한다. 그런 다음 이미지의 실제 레이블을 분류 기준에서 예측 한 것과 비교한다. 직관적으로, 최대한 많은 예측이 정답(ground truth)과 일치하는 것이 우리의 목표다.

#### Nearest Neighbor Classifier
먼저 Nearest Neighbor Classifier 개발해보자. 이 분류기는 Convolutional Neural Networks와는 아무런 관련이 없으며, 실제로 거의 사용되지 않지만 이미지 분류 문제에 대한 접근법에 대한 아이디어를 얻을 수 있다.

**이미지 분류 데이터 세트:** CIFAR-10: CIFAR-10 데이터 세트 인기있는 기본 이미지 분류 데이터 세트 중 하나다. 이 데이터 세트는 60,000개의 32x32픽셀 크기를 가진 작은 이미지로 구성된다. 각 이미지는 10 개의 클래스 중 하나 (예 : "비행기, 자동차, 새 등" )로 분류된다. 이 60,000 개의 이미지는 50,000 개의 학습 이미지 세트와 10,000 개의 테스트 이미지 세트로 구분된다. 아래 그림은 각 10개의 클래스에 해당하는 이미지 10개를 보여준다.

![](http://cs231n.github.io/assets/nn.jpg "cifar" "width:600px;float:center;padding-left:10px;")

왼쪽 : CIFAR-10 데이터 세트 의 예제 이미지 . 오른쪽 : 첫 번째 열은 테스트 이미지를 나타내며, 옆의 이미지는 픽셀 단위 차이(pixel-wise difference)에 따라 학습 데이터 세트에서 뽑은 10개의 이미지를 보여준다.

이제 CIFAR-10 학습 데이터 세트가 50,000 이미지 (레이블마다 5,000개 이미지)로 주어 졌다고 가정하고 나머지 10,000개에 이미지에 대해 레이블을 지정해보자. Nearest Neighbor Classifier는 테스트 이미지를 가져와 트레이닝(학습) 이미지의 모든 개별 이미지와 비교하고 가장 비슷한 트레이닝 이미지의 레이블로 예측한다. 위 그림의 오른쪽에서 10 개의 테스트 이미지에 대한 결과를 볼 수 있다. 10개 중 약 3개에서 동일한 클래스의 이미지가 검색되지만 다른 7 개에서는 그렇지 않다. 예를 들어, 8 열에서 말 머리에 가장 가까운 이미지는 아마도 검은 색 배경이 때문에 빨간 차로 예측 되었다. 결과적으로 말 이미지는 자동차 레이블로 잘못 예측된다.

두 개의 이미지(32x32x3)가 얼마나 비슷한지 비교하는 방법에 대한 세부 사항을 설명하지 않았다. 가장 간단한 접근법 중 하나는 모든 이미지에 대해 픽셀 단위로 비교하는 것이다. 일반적인 방법은 벡터 $I_1$, $I_2$ 로 표현된 두 개의 이미지를 다음과 같이 L1 distance를 통해 비교하는 것이다. 

$$d_1 (I_1, I_2) = \sum_{p} \left| I^p_1 - I^p_2 \right|$$

즉 아래 그림과 같이 모든 픽셀에 대한 차이의 합을 구한다. 

![](http://cs231n.github.io/assets/nneg.jpeg "simple" "width:600px;float:center;padding-left:10px;")

픽셀값 차이를 통해 구한 L1 distance을 사용하여 두 이미지를 비교하는 예(여기서는 색 채널이 한 개) 두 이미지를 요소별로 뺀 다음 모든 차이를 더한다. 두 이미지가 동일하면 결과는 0이된다. 반면 이미지가 매우 다른 경우 결과값이 커진다.

분류기를 코드에서 구현하는 방법에 대해서 살펴 보자. 먼저 CIFAR-10 데이터 셋의 학습 데이터/라벨 및 테스트 데이터/라벨을 4개의 어레이에 각각 저장한다. 아래 코드에서 *Xtr(50,000x32x32x3)*은 트레이닝 세트의 모든 이미지를 저장하며, 1 차원 배열 *Ytr(50,000)*은 해당하는 트레이닝 레이블 (0에서 9까지)을 저장하고있다.

``` python
Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide
# flatten out all images to be one-dimensional
Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072
Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072
```

이제 모든 이미지를 한개 배열에 저장했다. 분류기를 학습하고 평가하는 방법은 다음과 같다.

``` python
nn = NearestNeighbor() # create a Nearest Neighbor classifier class
nn.train(Xtr_rows, Ytr) # train the classifier on the training images and labels
Yte_predict = nn.predict(Xte_rows) # predict labels on the test images
# and now print the classification accuracy, which is the average number
# of examples that are correctly predicted (i.e. label matches)
print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) )
```

일반적으로 평가에서는 올바른 예측의 비율을 측정하는 **정확도(accuracy)**를 사용한다. 우리가 빌드할 분류기는 데이터와 라벨을 입력으로 사용하는 *train(X,y)*함수가 포함된 일반적인 API를 충족한다는 점을 유념하자. API는 내부적으로, 데이터로 부터 레이블을 예측하는 모델을 구축할 수 있어야한다. 그리고 새로운 데이터를 가져 와서 레이블을 예측 하는 predict(X)함수가 있다. 아래는 위 템플릿을 만족하는 L1 distance 기반의 간단한 Nearest Neighbor 분류기의 구현 코드를 보여준다.

``` python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in xrange(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```

위 코드를 실행하면 CIFAR-10의 분류 정확도가 38.6 % 에 불과하다는 것을 알 수 있다 . 이는 무작위로 추측하는 것보다는 높다.(10 개의 클래스가 있기 때문에 10 %의 정확도를 가짐). 그러나 사람(약 94 %로 추정)이나 최신 컨볼루션 뉴런 네트워크(95%) 비교하기에는 매우 낮은 수준이다.  



The choice of distance. 벡터 사이의 거리를 계산하는 다른 많은 방법이 있다. 또 다른 일반적인 방법은 L2 distance를 사용하는 것이다. L2 distance는 기하학적으로 두 벡터 사이의 유클리드 거리를 의미한다.  공식은 아래와 같다. 

$$d_2 (I_1, I_2) = \sqrt{\sum_{p} \left( I^p_1 - I^p_2 \right)^2}$$

이전과 같이 픽셀 단위 차이를 계산한다. 그러나 이번에는 픽셀 값 차이를 제곱한 다음 모두 더하고, 마지막으로 제곱근을 취한다. numpy에서는 다음과 같이 단 한 줄의 코드만 바꾸면된다. distance 계산 코드 :

``` python
distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))
```

위에서는 np.sqrt함수를 사용 했지만, 실제 Nearest Neighbor Classifier 애플리케이션에서는 제곱근이 단조 함수 이기 때문에 제곱근 연산을 생략 할 수 있다. 각 distance 값의 절대 크기는 변하지만 순서는 유지되므로 유사도의 순서는 유지되기 때문이다. L2 distance로 CIFAR-10에서 Nearest Neighbor 분류기를 실행 한 경우 35.4 %의 정확도를 얻을 수 있습니다 (L1 diatance 결과보다 약간 낮음).

**L1 vs L2.** 두 메트릭 간의 차이점을 고려하는 것은 흥미로운 일이다. 특히, L2 diatance는 두 벡터 간의 차이에 관해서 L1 거리보다 관대하지 않다. 즉, L2 diatance는 각 샘플이 중간 값의 차이를 많이 가지는 경우를 하나의 샘플에서 큰 차이가 나는 경우 보다 선호한다. 여기서 L1과 L2 distance는 p-norm의 가장 일반적인 표현법이다. 

#### k - Nearest Neighbor Classifier

위의 정확도를 보듯 예측을 할 때 가장 가까운 이미지의 레이블만 사용하는 것은 바람직하지 못하다. 실제로 **k-Nearest Neighbor Classifier**를 사용하면 더 좋은 결과를 얻을수 있다. 이 아이디어는 매우 간단한데, 트레이닝 세트에서 가장 비슷한 하나의 이미지를 찾는 대신 가장 비슷한 k 개의 이미지를 찾아 테스트 이미지의 각 레이블에 점수를 준다. 특히, k = 1 인 경우 Nearest Neighbor Classifier와 같아진다. 직관적으로, k의 값이 높을수록 분류기는 특이 값에 대한 변동이 작아지는 평활화 효과를 가진다.

![](http://cs231n.github.io/assets/knn.jpeg "k - Nearest" "width:600px;float:center;padding-left:10px;")

2차원 평면위의 점과 3개의 클래스 (빨강, 파랑, 녹색)에 대한 Nearest Neighbor와 5-Nearest Neighbor Classifier의 예. 색칠 된 영역은 L2 distance를 갖는 분류기에 의해 정해진 경계(decision boundary)를 나타낸다. 흰색 영역은 모호하게 분류 된 점을 나타낸다. (즉, 클래스 최소 두 개의 클래스가 같은 점수를 가짐). 5-NN Classifier는 부드럽게 경계가 나눠지며, , NN Classifier의 경우 예측이 잘못된 섬과 같은 영역이 생긴다. 

실제로 대부분의 경우 Nearest Neighbor Classifier보다 k-Nearest Neighbor Classifier를 선호한다. 정확도를 높이려면 k에 어떤 값을 사용하는 것이 좋을까? 다음 섹션에서 알아보자.

#### Validation sets for Hyperparameter tuning

k-Nearest Neighbor Classifier는 k의 값에 대한 설정이 필요하다. 그러면 어떤 값이 가장 좋을까? 또한 L1 norm, L2 norm 및 그외의 많은 distance 함수(예 : dot product) 중에서 어떤 것을 사용할지 선택해야한다. 이러한 선택을 **하이퍼 파라미터**라고 하며, 데이터에서 기반의 머신러닝 알고리즘을 설계 할 때 매우 자주 등장한다. 모델을 디자인 할 때 어떤 값 / 함수를 선택해야하는지는 분명하지 않다.

많은 다른 값들을 넣어 보면서 가장 잘 동작하는 것을 찾을 수도 있다. 이는 괜찮은 방법이며 실제로 그렇게 한다. 그러나 이것은 매우 신중히 시도해야한다. 특히, 우리는 하이퍼 파라미터를 조정할 목적으로 테스트 세트를 사용할 수 없다. 머신러닝 알고리즘을 설계 할 때 테스트 세트를 매우 귀중한 리소스라고 생각해야하며, 이 리소스는 한 번도 사용해선 안 된다. 테스트 세트에서 제대로 작동하도록 하이퍼 파라미터를 조정할 수 있지만, 모델을 배포 할 때 성능이 크게 저하 될 수 있기 때문에 매우 위험하다. 실제 이러한 경우를 테스트 세트에 과적합(overfit)되었다고 말한다. 테스트 세트에서 하이퍼 매개 변수를 튜닝하면 테스트 세트를 트레이닝 세트로 사용하기 때문에 실제로 성능 보다 더 좋게 측정된다. 따라서 모델을 배포 할 때 마지막에 한 번만 테스트 세트를 사용하면, 분류기의 일반적 성능 측정하는 좋은 잦대가 된다. 

  *테스트 세트는 마지막 한 번만 사용하라.*


다행히 테스트 세트를 전혀 건드리지 않고, 하이퍼 매개 변수를 조정하는 올바른 방법이 있다. 이 아이디어는 트레이닝 세트를 약간 더 작은 트레이닝 세트와 검증(validation)세트 둘로 나누는 것이다. 예를 들어 CIFAR-10을 사용하여 학습용으로 49,000 개의 트레이닝 이미지를 사용할 수 있으며 검증(validation)를 위해 1,000 개를 남겨 둘 수 있습니다. 이 밸리데이션 세트는 하이퍼 매개 변수를 조정하는 가짜(fake) 테스트 세트로 사용된다.

CIFAR-10의 경우 다음과 같다.

``` python
# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before
# recall Xtr_rows is 50,000 x 3072 matrix
Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation
Yval = Ytr[:1000]
Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train
Ytr = Ytr[1000:]

# find hyperparameters that work best on the validation set
validation_accuracies = []
for k in [1, 3, 5, 10, 20, 50, 100]:
  
  # use a particular value of k and evaluation on validation data
  nn = NearestNeighbor()
  nn.train(Xtr_rows, Ytr)
  # here we assume a modified NearestNeighbor class that can take a k as input
  Yval_predict = nn.predict(Xval_rows, k = k)
  acc = np.mean(Yval_predict == Yval)
  print 'accuracy: %f' % (acc,)

  # keep track of what works on the validation set
  validation_accuracies.append((k, acc))
```

위 과정을 끝날 때까지 k의 어떤 값이 가장 좋은지를 보여주는 그래프를 그릴 수 있다. 그런 다음 가장 좋은 값을 선택하고 테스트 세트에 대해 한 번만 평가한다.

*트레이닝 세트를 트레이닝 세트와 검증 세트로 나눈다. 검증세트를 사용하여 모든 하이퍼 매개 변수를 조정한다. 마지막에는 테스트 세트를 한 번 실행하고 성능을 측정한다.*

**Cross-validation.** 학습 데이터의 크기(및 검증(validation) 데이터)가 작은 경우에는 Cross-validation 라고하는 하이퍼 파라미터 튜닝에 보다 정교한 기술을 사용하는 경우가 있다 . 위의 예에서 트레이닝 세트에서 매번 무작위로 추출한 1000개 이미지를 검증 세트로 사용하여 노이즈가 덜하게 성능을 측정 할 수 있다. 예를 들어, 5 cross-validation에서 트레이닝 데이터를 5개 동일한 폴드로 분할하고, 트레이닝 데이터로 4개를 사용, 검증을 위해 1 개를 사용할 수 있다. 검증 폴드로 다른 4개 폴드를 중 하나를 선택한 다음 성능을 평가하고 이를 반복함으로써, 폴드 전반에서 성능을 평균화한다.

![](http://cs231n.github.io/assets/cvplot.png "cvplot" "width:600px;float:center;padding-left:10px;")

파라미터 k 에 대한 5 fold cross-validation의 예 . k의 각 값에 대해 4개 fold에서 학습하고 5번째 fold로 평가한다. 따라서 각 k 에 대해 각 fold에서 5가지 정확도를 받는다 (정확도는 y 축이며 각 결과는 점으로 나타내었다). 추세선은 각 k 에 대한 결과의 평균을 통해 그려지며 오차 막대는 표준 편차를 나타낸다. 이 예제의 견우 cross-validation은 약 k = 7의 값일때 가장 잘 작동 함을 보여준다. 5 fold 이상 사용한다면 더 부드러운 곡선을 볼 수 있다.

**In practice.** 하지만 실제 교차 유효성 검사가 계산적으로 비용이 많이들 수 있기 때문에 단일 유효성 검사 분할을 선호하여 교차 유효성 검사를 하지 않는 것을 선호하는 경우가 많다. 실제 학습 데이터에서 트레이닝 데이터로 50 %~90%를 사용하고 나머지를 검증 데이터로 사용한다. 하지만 이는 여러 요소에 따라 달라진다. 예를 들어 하이퍼 파라미터 수가 많으면 검증 데이터를 더 늘리는 것이 좋다. 수 백개 샘플 정도로 검증 데이터 양이 적다면, Cross-validation을 사용하는 것이 더 낫다. 여기서 실제 일반적으로 사용되는 fold의 수는 3, 5, 또는 10개다. 

![](http://cs231n.github.io/assets/crossval.jpeg "crossval" "width:600px;float:center;padding-left:10px;")

**일반적인 데이터 분할.** 트레이닝 및 테스트 세트가 주어진다. 트레이닝 세트는 폴드 (예 : 여기 5 폴드)로 나뉜다. 폴드 1-4가 트레이닝 세트가  되며. 1개 폴드는 (예 : 노란색의 5 번 폴트)는 검증 폴드로 표시되며 하이퍼 파라미터를 조정하는 데 사용된다. cross-validation은 여기서 한 걸음 더 나아가 매 학습시 검증 폴드를 다르게 선택한다. 이를 5 fold cross-validation이라고 한다. 최종적으로 모델이 훈련되고 모든 최적 하이퍼 파라미터가 결정되면, 테스트 데이터(빨간색)를 사용하여 모델을 한 번만 평가한다.

##### Pros and Cons of Nearest Neighbor classifier.

Nearest Neighbor Classifier의 장점과 단점에 대해 고려해 볼만하다. 알고리즘을 구현하고 이해하기가 매우 쉽다는 것은 장점임이 분명하다. 또한, 분류기는 트레이닝 데이터를 저장하고 인덱싱하기만 하면 되기 때문에 트레이닝 시간이 필요하지 않다. 하지만 테스트 데이터를 분류 할 때마다 모든 단일 트레이닝 데이터들과 비교해야하기 때문에 테스트 시간에 많은 계산 비용이 든다. 실제로 테스트 시간이 트레이닝 시간보다 더 많이 걸리기 때문에 테스트 데이터의 측정에 대한 효율성을 더 고려한다. 사실 이 클래스의 후반부에서 다둘 심층 신경 네트워크(deep neural networks)는 이와 정반대로 학습하는데 비용이 많이 들지만, 새로운 테스트 예제를 분류하는 것은 매우 적은 시간이 걸린다. 이러한 현상이 실제로 더 바람직하다.

제쳐두고, Nearest Neighbor Classifier의 계산 복잡도에 대한 부분은 연구자의 몫이며, 데이터 세트에서 가장 가까운 Neighbor Lookup을 가속화 할 수있는 **ANN(Approximate Nearest Neighbor)** 알고리즘과 이에 대한 라이브러리(예 : FLANN)가 존재한다. 일반적으로 kdtree를 작성하거나 k-means 알고리즘을 실행하는 사전 처리/인덱싱 단계를 통해 검색의 정확성과 공간/시간 복잡성을 트리이드 오프(trade off)관계로 놓아 사용할 수 있다. 

Nearest Neighbor Classifier는 일부 설정에서 좋은 선택이 될 수 있지만 (특히 데이터의 크기가 작은 경우), 실용적인 이미지 분류에는 사용하기 적합하지 않다. 이미지가 고차원(즉, 많은 픽셀을 포함 함)이고 두 이미지의 유사도가 직관적이지 않을 수 있기 때문에 문제가 된다. 아래 이미지는 위에서 개발 한 픽셀 기반 L2 유사성이 직관적 유사성과 매우 다른 점을 보여준다.

![](http://cs231n.github.io/assets/samenorm.png "samenorm" "width:600px;float:center;padding-left:10px;")

고차원 데이터 (특히 이미지)에 대한 픽셀 기반 유사도는 매우 직관적이지 않을 수 있다. 원본 이미지 (왼쪽)와 그 옆에있는 세 개의 이미지가 모두 L2 픽셀 기준으로 동등한 유사도를 가진다. 분명히, 픽셀 단위 유사도는 지각적 또는 의미론적 유사성과 전혀 일치하지 않는다.

다음 그림은 역시 이미지를 비교하기 위해 픽셀 거리(distance)를 사용하는 것이 부적절하다는 것을 보여준다. t-SNE 라는 시각화 기법을 사용하여 CIFAR-10 이미지를 가져온 다음 (로컬) 픽셀 단위 거리를 가장 잘 보존 할 수 있도록 이차원에 놓을 수 있다. 이 시각화에서 근처에 표시된 이미지는 위에서 개발 한 L2 픽셀 단위 거리에 따라 매우 유사한 것으로 간주된다.

![](http://cs231n.github.io/assets/pixels_embed_cifar10.jpg "pixels_embed_cifar10" "width:600px;float:center;padding-left:10px;")

t-SNE로 2 차원에 놓은 CIFAR-10 이미지. 이 이미지에서 근처에있는 이미지는 L2 픽셀 거리를 기반으로 유사한 것으로 간주된다. 시맨틱 한 클래스 차이보다는 배경의 영향이 강한 것에 주목하자. 여기를 [클릭](http://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg)해 이 시각화를 더 자세히 볼 수 있다. 

#### Summary

요약하자면:

- Image Classification 문제를 소개했다. 여기에는 하나의 카테고리로 분류 된 일련의 이미지가 있다. 그런 다음 새로운 테스트 이미지에 대해 이러한 카테고리를 예측하고, 예측의 정확성을 측정한다.
- Nearest Neighbor Classifier라는 간단한 분류기를 소개했다. 이 분류기와 연관된 여러 가지 하이퍼 파라미터(예 : k 값 또는 distance 유형)가 있으며 이를 선택하는 확실한 방법은 없음을 확인했다.
- 이 하이퍼 파라미터를 설정하는 올바른 방법은 트레이닝 데이터를 두 세트로 나누는 것이다. 트레이닝 세트와 가짜 테스트 세트로, 이를 검증 세트라고 한다. 다른 하이퍼 파라미터 값을 선택하고 밸리데이션 세트를 통해 최상의 성능을 이끌어내는 값을 구한다. 
- 트레이닝 자료가 부족한 경우 Closs-valication이라는 절차를 통해 어떤 하이퍼 파라미터가 가장 적합한지 예측할 때 노이즈를 줄일 수 있다.
- 최적의 하이퍼 파라미터가 발견되면 이를 선택하고 실제 테스트 세트에 대해 한번만 평가를 수행한다.
- 우리는 Nearest Neighbor가 CIFAR-10에서 약 40 %의 정확도를 얻을 수 있음을 확인했다. 구현은 간단하지만 전체 트레이닝 세트를 저장해야며, 테스트 이미지를 평가하는 데 계산 비용이 많이 든다.
- 마지막으로 L1과 L2 거리를 픽셀 값에 사용하는 것은 거리가 이미지의 의미론적 내용보다 색 분포와 배경에 더 밀접하기 때문에 적절하지 않다.
- 
다음 강의에서는 이러한 문제를 해결하여 90%의 정확도를 제공하며, 학습이 완료되면 트레이닝 세트가 더 이상 필요 없고, 테스트 이미지를 0.001초 내에 평가 할 수 있는 솔루션에 대해 알아보도록 한다.

#### Summary: Applying kNN in practice

실제로 kNN을 적용(이미지가 아니거나, 기준(baseline)으로 사용)하고 싶다면 아래의 절차를 따르길 권장한다. 

- 데이터 사전 처리 : 데이터의 특징 (예 : 이미지의 한 픽셀)이 평균 및 분산이 0이되도록 표준화(Normalize)한다. 이미지의 경우 일반적으로 균질하고 다른 분포가 넓게 나타나지 않아 데이터 정규화의 필요성이 덜 하므로 이 섹션에서는 데이터 정규화를 다루지 않는다.
- 데이터가 매우 고차원 인 경우 PCA( [wiki ref](http://en.wikipedia.org/wiki/Principal_component_analysis) , [CS229ref](http://cs229.stanford.edu/notes/cs229-notes10.pdf) , [blog ref](http://www.bigdataexaminer.com/understanding-dimensionality-reduction-principal-component-analysis-and-singular-value-decomposition/) ) 또는 Random Projections과 같은 차원 감소 알고리즘을 사용하는 것을 고려하라.
- 훈련 데이터를 무작위로 train/val로 나눈다. 일반적으로 데이터의 70-90%가 보통 train으로 나뉜다. 이 설정은 가지고있는 하이퍼 파라미터의 수와 그 영향의 정도에 따라 다릅니다. 추정 할 하이퍼 파라미터가 많은 경우 효과적으로 유효성을 평가하기 위해 밸리데이션 세트를 더 크게 잡아야 한다. 밸리데이션 데이터의 크기가 작은 경우 트레이닝 데이터를 폴드로 분할하고 closs-validation을 수행하는 것이 가장 좋다. 계산시간을 감당할 수 있다면 크로스 밸리데이션을 사용하는 것이 더 안전하다. 폴드가 많을수록 계산 비용은 비싸진다.
- 각 k와(많을 수록 더 좋음)과 많은 다른 거리 유형 (L1 및 L2 등)에 대한 밸리데이션 데이터에 대해 kNN 분류기를 학습시키고 평가한다.
- kNN 분류기의 평가 시간이 너무 길면, Approximate Nearest Neighbor 라이브러리 (예 : [FLANN](http://www.cs.ubc.ca/research/flann/))를 사용하여 검색 속도를 높이는 것이 좋다.
- 최상의 결과를 얻은 하이퍼 파라미터를 기록해 둔다. 트레이닝 세트를 통해 이를 평가해야하는지에 대한 의문이 있다. 데이터의 크기가 커지므로 최적의 하이퍼 파라미터가 변경 될 수 있기 때문이다. 실제로 분류기의 최종 성능을 평가할 때는 밸리데이션 데이터를 사용하지 않고, 단지 하이퍼 파라미터를 추정 할 때만 사용한다. 테스트 세트를 통해 가장 좋은 모델의 성능을 평가하자.. 테스트 세트 정확도를 기록하고 이것이 데이터에대한  kNN 분류기의 성능이 된다. 

Further Reading
다음과 같은 관련된(선택 사항) 몇 가지 링크가 있다.

- [A Few Useful Things to Know about Machine Learning](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf), where especially section 6 is related but the whole paper is a warmly recommended reading.
- [Recognizing and Learning Object Categories](http://people.csail.mit.edu/torralba/shortCourseRLOC/index.html), a short course of object categorization at ICCV 2005.







