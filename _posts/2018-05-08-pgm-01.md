---
title: 01 Introduction and Overview
category: ProbabilisticGraphicalModels
excerpt: |
  확률론적 그래픽 모델(PGM: Probabilistic Graphical Models)을 정의하기 전에 어떤 분야에 주로 사용 되는지를 알아보겠습니다.
feature_text: |
  ## [Coursera] Probabilistic Graphical Models
  Daphne Koller의 Probabilistic Graphical Models 강의 정리

  ref: https://www.coursera.org/learn/probabilistic-graphical-models/home

feature_image: "https://picsum.photos/2560/600/?image=798"
image: "https://picsum.photos/2560/600/?image=798"
comment: true
---

![](http://cfile24.uf.tistory.com/image/21219D3D5874E78D1697E8 "Probabilistic Graphical Models" "width:600px;height:300px;float:center;padding-left:10px;")

확률론적 그래픽 모델(PGM: Probabilistic Graphical Models)을 정의하기 전에 어떤 분야에 주로 사용 되는지를 알아보겠습니다. PGM이 컴퓨터 사이언스, 인공지능에 적용 된 첫 사례중 하나는 의료 진단입니다. 환자와 마주한 의사를 상상해보세요. 의사는 환자를 보며 다양한 정보를 얻습니다. 그리고 요인, 증상, 다양한 결과를 예측합니다. 그리고 환자의 병이 무엇인지, 치료법은 무엇인지 파악합니다. 또 다른 예는 이미지 분할(segmentation)입니다. 수천, 수십만개의 필셀로 이루어진 이미지가 있을 때, 각 픽셀이 무엇에 해당하는지 알고자 합니다. 가령 위와 같은 이미지가 주어졌을때 각 픽셀이 소에 해당하는지 잔디에 해당하는지 파악하는 것입니다. 위 두 문제의 공통점은 많은 변수가 있다는 것과 아무리 정확한 알고리즘을 설계하더라도 도출한 결과에 불확실성이 존재한다는 것입니다.

![](http://cfile7.uf.tistory.com/image/254AF23F5874EC251B0FE1 "Probabilistic Graphical Models" "width:600px;height:300px;float:center;padding-left:10px;")

확률론적 그래픽 모델(Probabilistic Graphical Models)은 위와 같은 문제를 해결하기 위한 프레임 워크입니다. 각 단어가 의미하는 바를 먼저 살펴 보겠습니다.  Models은 일반적으로 자연법칙에 대한 이해를 선언적(declarative)으로 표현한 것입니다. 따라서 주어진 변수가 무엇인지 어떻게 상호작용을 하는지를 컴퓨터를 통해 표현하는 것입니다. 선언적이라는 말은 여기서 독자적과 같은 의미로 쓰입니다. 따라서 모델은 특정 알고리즘과 별개로 존재합니다. 따라서 한 개 모델로부터 여러 알고리즘이 나올 수 있으며, 특정 상황에 맞게 취사 선택하거나 학습을 통해 모델을 더 발전 시킬 수도 있습니다.

 모델에 대해 살펴봤습니다. 그렇다면 확률론(probabilistic)은 어떤 의미를 지닐까요? 확률론은 모델이 많은 양의 불확실성에 대해 다루는데 도움을 줍니다. 이러한 불확실성에는 여러 요인이 있습니다. 첫번째는 우리가 보는 현상에 대한 부분적인 지식만 가지고 있기 때문입니다. 예를 들어 의사는 환자에 대한 모든 증상이나 검사 결과를 측정하지 못하기 때문에 병에 대한 진단에 완전히 확신하지 못합니다. 또한 이러한 검사에 있어 노이즈나 오차가 발생하기 때문에 불확실성이 나타납니다. 가령 혈압을 측정하는 경우 주변의 소음들은 정확한 측정을 방해하는 불확실성의 요인이 될 수 있습니다. 또 다른 이유는 모델이 현상을 완전히 표현하지 못하는 것입니다. 예를 들어 같은 증상이더라도 전혀 다른 병인 경우도 있습니다. 발생 가능한 모든 요인들과 모든 우연성들을 감안하는 굉장히 복잡한 모델을 만드는 것은 불가능 합니다. 따라서 이러한 모델링의 한계로 인해 불확실성이 발생 할 수 밖에 없습니다. 끝으로 이 세계에서 발생하는 현상은 본질적으로 확률성을 담고 있습니다. 물론 양자 차원에서 본다면 이는 당연한 사실입니다. 하지만 우리 주변의 현상처럼 보다 높은 차원에서 보더라도 모델의 한계는 확률성에 기인합니다. 확률 이론은 중요하고 가치있는 것을 가져오는 원칙에 기반하여 불확실성을 처리하는 프레임워크입니다. 따라서 확률론적 모델은 앞에서 나온 선언적이라는 의미도 가집니다. 따라서 나타날 수 있는 여러 상태에 대한 불확실성이나 확률분포 같은 것을 독자적으로 보고 표현 할 수 있습니다. 또한 조건부 확률과 같은 불확실성이나 확률에 대해 처리하는 툴을 제공합니다. 또한 확률은 통계와 밀접한 관계가 있으므로 과거의 데이터를 사용하여 학습 할 수도 있습니다. 따라서 모델의 모든 부분을 일일이 결정할 필요는 없습니다.        

 끝으로 그래픽(graphical)이라는 단어가 있습니다. 이 단어는 컴퓨터 사이언스과 밀접한데, 그 이유는 확률론적 그래픽 모델이 통계, 확률 이론과 컴퓨터 사이언스의 통합이기 때문입니다. 특히 위 아이디어의 컴퓨터 사이언스의 그래프 연결을 이용하여 많은 변수가 포함된 복잡한 시스템을 표현(모델링)합니다. 위의 두 예(위료, 세그멘테이션)에서 일반적으로 모델링에는 많은 수의 변수가 필요하다는 것을 보았습니다. 이러한 많은 변수에서의 확률을 표현하기 위해 확률분포가 필요합니다.  

![](http://cfile2.uf.tistory.com/image/2127144D587971911EFD00 "확률분포" "width:600px;height:200px;float:center;padding-left:10px;")

따라서 이 강의에서는 우리 주변의 현상을 무작위 변수 $x_1~x_n$사이의 집합으로 표현하는데 초점을 맞출 것입니다. 위에서 살펴 본 증상이 있거나 없거나, 연속적인 결과값이나, 레이블링 되어 있는 픽셀, 이 모든것은 무작위 변수입니다. 이 강의에서 할 것은 이러한 무작위 변수들의 확률 분포로부터 어떤 상태에 대한 불확실성을 찾거나, 공통분배(Joint distribution)을 찾는 것입니다. 여기서 중요한 점은 이러한 변수마다 확률 분포가 존재한다는 것입니다. 따라서 변수가 많아 질 수록 발생가능한 상태는 기하급수적으로 늘어 납니다. 가장 간단한 2진(True, False)변수라고 해도 n개가 있다면 표현 가능한 상태는 $2^n$개가 됩니다. 따라서 이렇게 많은 변수를 처리하려면 데이터 구조와, 컴퓨터 사이언스 이론을 사용하여 주어진 모델을 효과적으로 표현하고 조작해야 합니다.    

![](http://cfile3.uf.tistory.com/image/2179D348587972A32A699F "Networks" "width:600px;height:250px;float:center;padding-left:10px;")

그렇다면 그래픽 모델은 무엇일까요? 위에 간단한 두 예가 있습니다. 오른쪽 그래프는 베이지안 네트워크라 불리며 앞으로 몇개 챕터를 통해 다룰 것입니다. 이 네트워크는 방향성이 있으며 위에서 말한 각 변수는 네트워크에서 노드로 표현 됩니다. 위 예는 코스을 수강하고 성적을 받는 상황을 다룹니다. 여기에는 그에 관련 된 변수(과목의 난이도, 학생의 지능, 학생의 점수, SAT점수, 추천서)들이 있습니다. 이러한 노드에서의 변수들은 확률 분포로 표현됩니다. 그리고 흥미로운 점은 이러한 변수들 사이에 의존성(dependency)가 있다는 점입니다. 이러한 의존성을 확률적 연결로 표현됩니다. 또 다른 네트워크는 마르코프 네트워크입니다. 마르코프 네트워크는 오른쪽 그림과 같이 노드 사이의 연결에 방향성이 없습니다.    

![](http://cfile1.uf.tistory.com/image/2314FC45587ADC6007BA41 "Networks" "width:600px;height:250px;float:center;padding-left:10px;")

왼쪽 그림은 실제 질병 진단을 목적으로 설계된 베이지안 네트워크입니다. 480개의 노드와 900개 이상의 엣지로 구성되어 있습니다. 오른쪽 그림처럼 이미지 분할 예는 마르코프 네트워크를 사용합니다. 이 경우 변수는 픽셀 또는 슈퍼픽셀의 레이블을 나타냅니다. 따라서 슈퍼픽셀의 레이블을 노드라 볼 수 있고, 인접한 슈퍼 픽셀 사이를 엣지로 연결할 수 있습니다.  

정리하자면 그래픽 모델링은 이러한 복잡한 현상을 보다 직관적이고 간결한 데이터 구조로 표현합니다. 또한 이 후 강의에서 다루겠지만, 이러한 구조에서 올바른 추론을 하는데 도움을 주는 여러 알고리즘도 사용할 수 있습니다. 또한 그래프 구조는 확률분포를 파라미터로 표현 할 수 있으므로 고차원의 복잡한 확률분포를 몇개의 파라미터 만으로도 정의 할 수 있습니다. 현상으로 부터 추론할 때 복잡한 전문적인 수식을 사용하거나, 머신러닝을 사용하여 데이터로 부터 자동으로 얻어 낼수 있습니다. 이러한 두경우 모두 매개변수의 수를 줄이는 것이 중요합니다. 따라서 아래와 같은 매우 다양한 분야에 사용할 수 있습니다.

![](http://cfile27.uf.tistory.com/image/236E0E35587ADFE9079C8C "Networks" "width:600px;height:300px;float:center;padding-left:10px;")

앞으로 남은 강의에서는 확률론적 그래픽컬 모델을 아래와 같이 세부분으로 나눠 다루겠습니다.

1. 모델의 표현법, 구조를 다룹니다. 방향성/무방향성 그래프 및 시간적/반복적/plate 모델을 다룰 것입니다.
2. 모델로부터 추론하는 법을 다룰 것입니다. 정확한 예측을 하는 방법 및 근사적인 추론을 하는 법을 배울 것입니다. 이 때 근사적인 추론의 경우 트레이드 오프 및 불확실성에 대해서도 다룰 것 입니다.
3. 통계 데이터로부터 만든 모델링을 어떻게 학습하는 지도 배울 것입니다. 모든 변수들에 대한 완전한 데이터를 제공하는 경우와 그렇지 않은 경우에 대해서도 다룰 예정입니다.   
